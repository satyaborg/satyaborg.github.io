{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rf5NATWBI-v"
      },
      "source": [
        "# Finding Needles in a Paper Haystack\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/satyaborg/satyaborg.github.io/blob/main/assets/notebooks/paper-haystack.ipynb)\n",
        "\n",
        "- Code for the [blog post](https://satyaborg.com/posts/research-clustering/) of the same name\n",
        "- Cluster and visualize papers from NeurIPS 2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-cmHRbRSUzR"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLbeXm7jKrEw"
      },
      "source": [
        "## Data acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQGPaCAKPlmA"
      },
      "outputs": [],
      "source": [
        "conf = 'neurips'\n",
        "year = '2021' # change this if you want to retrieve papers for another year\n",
        "base_url = f\"https://proceedings.neurips.cc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coI9hNCkShFr"
      },
      "outputs": [],
      "source": [
        "html = requests.get(f\"{base_url}/paper/{year}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i16X0vESva3"
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(html.text, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkhjIom9USFn",
        "outputId": "eeaf4081-f3fa-495e-bc79-736c55571729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed in 0.10488343238830566 secs\n"
          ]
        }
      ],
      "source": [
        "# this might take a while!\n",
        "papers = []\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for paper in soup.find_all('li'):\n",
        "    try:\n",
        "        title = paper.find_all('a')[0].text\n",
        "        link = paper.find_all('a')[0].get('href')\n",
        "        if title:\n",
        "            papers.append(dict(\n",
        "                title = title,\n",
        "                authors=paper.find_all('i')[0].text,\n",
        "                link=f\"{base_url}/{link}\",\n",
        "                conf=conf,\n",
        "                year=year\n",
        "            ))\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        continue\n",
        "\n",
        "print(f\"Completed in {time.time() - start} secs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "99GSwGn_ehEV",
        "outputId": "c50120a3-d00c-4265-8564-5a2d4ccc3785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2334, 5)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1b3c62fe-16b8-482d-ab97-61ea00dbe6c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>conf</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyond Value-Function Gaps: Improved Instance-...</td>\n",
              "      <td>Christoph Dann, Teodor Vanislavov Marinov, Meh...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Learning One Representation to Optimize All Re...</td>\n",
              "      <td>Ahmed Touati, Yann Ollivier</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Matrix factorisation and the interpretation of...</td>\n",
              "      <td>Nick Whiteley, Annie Gray, Patrick Rubin-Delanchy</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UniDoc: Unified Pretraining Framework for Docu...</td>\n",
              "      <td>Jiuxiang Gu, Jason Kuen, Vlad I Morariu, Hando...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Finding Discriminative Filters for Specific De...</td>\n",
              "      <td>Liangbin Xie, Xintao Wang, Chao Dong, Zhongang...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b3c62fe-16b8-482d-ab97-61ea00dbe6c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b3c62fe-16b8-482d-ab97-61ea00dbe6c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b3c62fe-16b8-482d-ab97-61ea00dbe6c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Beyond Value-Function Gaps: Improved Instance-...   \n",
              "1  Learning One Representation to Optimize All Re...   \n",
              "2  Matrix factorisation and the interpretation of...   \n",
              "3  UniDoc: Unified Pretraining Framework for Docu...   \n",
              "4  Finding Discriminative Filters for Specific De...   \n",
              "\n",
              "                                             authors  \\\n",
              "0  Christoph Dann, Teodor Vanislavov Marinov, Meh...   \n",
              "1                        Ahmed Touati, Yann Ollivier   \n",
              "2  Nick Whiteley, Annie Gray, Patrick Rubin-Delanchy   \n",
              "3  Jiuxiang Gu, Jason Kuen, Vlad I Morariu, Hando...   \n",
              "4  Liangbin Xie, Xintao Wang, Chao Dong, Zhongang...   \n",
              "\n",
              "                                                link     conf  year  \n",
              "0  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021  \n",
              "1  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021  \n",
              "2  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021  \n",
              "3  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021  \n",
              "4  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_papers = pd.DataFrame(papers)\n",
        "print(df_papers.shape)\n",
        "df_papers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXjWPuQQgqn1"
      },
      "source": [
        "Get the abstracts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-MiXd9Ygr_0",
        "outputId": "abb66714-fc00-4308-ebb7-86f7d0b1d89f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed in 281.3236002922058 secs\n"
          ]
        }
      ],
      "source": [
        "abstracts = []\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for paper in papers:\n",
        "    try:\n",
        "        link = paper['link']\n",
        "        paper_details = requests.get(link)\n",
        "        paper_soup = BeautifulSoup(paper_details.text, 'html.parser')\n",
        "        \n",
        "        headings = paper_soup.find_all('h4')\n",
        "        headings_text = [h.text.strip().lower() for h in headings]\n",
        "        i = headings_text.index('abstract') # match h4 with Abstract\n",
        "\n",
        "        # abstract is always 2 siblings down\n",
        "        next = headings[i].next_sibling\n",
        "        next = next.next_sibling\n",
        "\n",
        "        abstract = next.text\n",
        "        abstracts.append(abstract)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e, paper['title'], paper['link'])\n",
        "        abstracts.append(None)\n",
        "        continue\n",
        "\n",
        "print(f\"Completed in {time.time() - start} secs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENDGSIQ7lDmM"
      },
      "source": [
        "Clean the HTML tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGHiqiselHeN"
      },
      "outputs": [],
      "source": [
        "df_papers['abstract'] = abstracts\n",
        "df_papers['abstract'] = df_papers.abstract.apply(lambda x: BeautifulSoup(x, \"lxml\").text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzBkfjXok9v2"
      },
      "source": [
        "Concatenate `title` + `abstract` to form the `body`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GShjbth0fzgs"
      },
      "outputs": [],
      "source": [
        "df_papers['body'] = df_papers.apply(lambda x: f\"{x.title} {x.abstract}\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2677
        },
        "id": "DqR923ERmCP0",
        "outputId": "16770c19-f4d0-40ca-fd43-071b032c5b95"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c70c3cff-6171-412a-87ad-3d9f3566f5cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>conf</th>\n",
              "      <th>year</th>\n",
              "      <th>abstract</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyond Value-Function Gaps: Improved Instance-...</td>\n",
              "      <td>Christoph Dann, Teodor Vanislavov Marinov, Meh...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>We provide improved gap-dependent regret bound...</td>\n",
              "      <td>Beyond Value-Function Gaps: Improved Instance-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Learning One Representation to Optimize All Re...</td>\n",
              "      <td>Ahmed Touati, Yann Ollivier</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>We introduce the forward-backward (FB) represe...</td>\n",
              "      <td>Learning One Representation to Optimize All Re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Matrix factorisation and the interpretation of...</td>\n",
              "      <td>Nick Whiteley, Annie Gray, Patrick Rubin-Delanchy</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>Given a graph or similarity matrix, we conside...</td>\n",
              "      <td>Matrix factorisation and the interpretation of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UniDoc: Unified Pretraining Framework for Docu...</td>\n",
              "      <td>Jiuxiang Gu, Jason Kuen, Vlad I Morariu, Hando...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>Document intelligence automates the extraction...</td>\n",
              "      <td>UniDoc: Unified Pretraining Framework for Docu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Finding Discriminative Filters for Specific De...</td>\n",
              "      <td>Liangbin Xie, Xintao Wang, Chao Dong, Zhongang...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>Recent blind super-resolution (SR) methods typ...</td>\n",
              "      <td>Finding Discriminative Filters for Specific De...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2329</th>\n",
              "      <td>Unlabeled Principal Component Analysis</td>\n",
              "      <td>Yunzhen Yao, Liangzu Peng, Manolis Tsakiris</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>We introduce robust principal component analys...</td>\n",
              "      <td>Unlabeled Principal Component Analysis We intr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2330</th>\n",
              "      <td>Causal-BALD: Deep Bayesian Active Learning of ...</td>\n",
              "      <td>Andrew Jesson, Panagiotis Tigas, Joost van Ame...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>Estimating personalized treatment effects from...</td>\n",
              "      <td>Causal-BALD: Deep Bayesian Active Learning of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2331</th>\n",
              "      <td>Scalable Rule-Based Representation Learning fo...</td>\n",
              "      <td>Zhuo Wang, Wei Zhang, Ning Liu, Jianyong Wang</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>Rule-based models, e.g., decision trees, are w...</td>\n",
              "      <td>Scalable Rule-Based Representation Learning fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2332</th>\n",
              "      <td>Bridging Non Co-occurrence with Unlabeled In-t...</td>\n",
              "      <td>NA DONG, Yongqiang Zhang, Mingli Ding, Gim Hee...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>Deep networks have shown remarkable results in...</td>\n",
              "      <td>Bridging Non Co-occurrence with Unlabeled In-t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2333</th>\n",
              "      <td>A Regression Approach to Learning-Augmented On...</td>\n",
              "      <td>Keerti Anand, Rong Ge, Amit Kumar, Debmalya Pa...</td>\n",
              "      <td>https://proceedings.neurips.cc//paper/2021/has...</td>\n",
              "      <td>neurips</td>\n",
              "      <td>2021</td>\n",
              "      <td>The emerging field of learning-augmented onlin...</td>\n",
              "      <td>A Regression Approach to Learning-Augmented On...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2334 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c70c3cff-6171-412a-87ad-3d9f3566f5cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c70c3cff-6171-412a-87ad-3d9f3566f5cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c70c3cff-6171-412a-87ad-3d9f3566f5cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  title  \\\n",
              "0     Beyond Value-Function Gaps: Improved Instance-...   \n",
              "1     Learning One Representation to Optimize All Re...   \n",
              "2     Matrix factorisation and the interpretation of...   \n",
              "3     UniDoc: Unified Pretraining Framework for Docu...   \n",
              "4     Finding Discriminative Filters for Specific De...   \n",
              "...                                                 ...   \n",
              "2329             Unlabeled Principal Component Analysis   \n",
              "2330  Causal-BALD: Deep Bayesian Active Learning of ...   \n",
              "2331  Scalable Rule-Based Representation Learning fo...   \n",
              "2332  Bridging Non Co-occurrence with Unlabeled In-t...   \n",
              "2333  A Regression Approach to Learning-Augmented On...   \n",
              "\n",
              "                                                authors  \\\n",
              "0     Christoph Dann, Teodor Vanislavov Marinov, Meh...   \n",
              "1                           Ahmed Touati, Yann Ollivier   \n",
              "2     Nick Whiteley, Annie Gray, Patrick Rubin-Delanchy   \n",
              "3     Jiuxiang Gu, Jason Kuen, Vlad I Morariu, Hando...   \n",
              "4     Liangbin Xie, Xintao Wang, Chao Dong, Zhongang...   \n",
              "...                                                 ...   \n",
              "2329        Yunzhen Yao, Liangzu Peng, Manolis Tsakiris   \n",
              "2330  Andrew Jesson, Panagiotis Tigas, Joost van Ame...   \n",
              "2331      Zhuo Wang, Wei Zhang, Ning Liu, Jianyong Wang   \n",
              "2332  NA DONG, Yongqiang Zhang, Mingli Ding, Gim Hee...   \n",
              "2333  Keerti Anand, Rong Ge, Amit Kumar, Debmalya Pa...   \n",
              "\n",
              "                                                   link     conf  year  \\\n",
              "0     https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "1     https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "2     https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "3     https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "4     https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "...                                                 ...      ...   ...   \n",
              "2329  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "2330  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "2331  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "2332  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "2333  https://proceedings.neurips.cc//paper/2021/has...  neurips  2021   \n",
              "\n",
              "                                               abstract  \\\n",
              "0     We provide improved gap-dependent regret bound...   \n",
              "1     We introduce the forward-backward (FB) represe...   \n",
              "2     Given a graph or similarity matrix, we conside...   \n",
              "3     Document intelligence automates the extraction...   \n",
              "4     Recent blind super-resolution (SR) methods typ...   \n",
              "...                                                 ...   \n",
              "2329  We introduce robust principal component analys...   \n",
              "2330  Estimating personalized treatment effects from...   \n",
              "2331  Rule-based models, e.g., decision trees, are w...   \n",
              "2332  Deep networks have shown remarkable results in...   \n",
              "2333  The emerging field of learning-augmented onlin...   \n",
              "\n",
              "                                                   body  \n",
              "0     Beyond Value-Function Gaps: Improved Instance-...  \n",
              "1     Learning One Representation to Optimize All Re...  \n",
              "2     Matrix factorisation and the interpretation of...  \n",
              "3     UniDoc: Unified Pretraining Framework for Docu...  \n",
              "4     Finding Discriminative Filters for Specific De...  \n",
              "...                                                 ...  \n",
              "2329  Unlabeled Principal Component Analysis We intr...  \n",
              "2330  Causal-BALD: Deep Bayesian Active Learning of ...  \n",
              "2331  Scalable Rule-Based Representation Learning fo...  \n",
              "2332  Bridging Non Co-occurrence with Unlabeled In-t...  \n",
              "2333  A Regression Approach to Learning-Augmented On...  \n",
              "\n",
              "[2334 rows x 7 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK-xdzVlmW6-"
      },
      "outputs": [],
      "source": [
        "# optional\n",
        "# df_papers.to_csv('neurips21.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyskyOfCfAup"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A00apH1nm7qB"
      },
      "outputs": [],
      "source": [
        "!pip install bertopic\n",
        "!pip install --upgrade joblib==1.1.0\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBhY6lW_nW3a"
      },
      "outputs": [],
      "source": [
        "docs = df_papers.body.tolist()\n",
        "docs = list(map(lambda x: str(x), docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7d4hwLhoRn8"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "9ef6947951ef45a599e3abf85211c2ae",
            "cca9fb15337e437a8dbe553ce1030ad6",
            "f03960b2ee7f49dc8646a474705e7b04",
            "acabf630c0c94d23ab46b59f2c22db8c",
            "c2d7fdedf355407daac6161eeb81678a",
            "83932dcebddb45788952924e91973e0c",
            "42e34932598d48718931e0bdf8d6d301",
            "ae0bd1ab40fc432897696b8e6fa87ba1",
            "9e0f05dd90f241c4a01989b5aa633245",
            "5c99c984e2e845d987c1f5cab7b5a86e",
            "d18914fa06704258a3eec1343f72cf26",
            "9d02a10bd641488e808bc61109e3593d",
            "9d383c4146c44616b870ac8eb9fe7528",
            "4c5313aeff2540ee984f6900af98fd61",
            "346d018c68284064a0a47d96e6ae8df0",
            "a4c10858a415477399f5be1af7ff77a6",
            "85dd5a41657a4105a3a1ff8a5e886e8e",
            "77f5bed8099c409dbf6cf81e31c55ce3",
            "9fbc901237c04299a1ba5fbba9235533",
            "08cfdf7b551b46b68d2e27301ecc6957",
            "2b9e04cde9d64901aa4875eadd95648f",
            "fe4e8faf666c497eacce58be370fada1",
            "1624a1e098654ff9826b64317d514655",
            "9ef4087d0c7d4ac3b8340b980e53129a",
            "85427bb0771140d9a17e59faad5f7eed",
            "0168148cc5de41b29a769f39a7369664",
            "c5b55aacebdf4ad9a7fa9e0e5c10f74a",
            "2406ffac09a348288076d12610d9b3d8",
            "de1af796a25042b5bece2313812aa9a0",
            "bc238a1cb46648a3bc51298da963e357",
            "6fa781ce55dc4250a0330e65855df652",
            "f3e65d49efc2486f8150a9ea5a042304",
            "9b3aad1a100443578f28f597589e0799",
            "241dd909958446dc8860a8db28db1e76",
            "64a7594ba9454b7ba2339c0a6b491bcd",
            "3a452c5b13164100a51f60908756f0bf",
            "9f039c951c3046f0bc80ed7f1185d8c8",
            "687cb82bace54c938b86cd74344c5aae",
            "0387575127234bdba519008e7b9ce298",
            "6d5a50630d8a4f16b161289059775651",
            "ebac3fa672894a9b915755b1f4661e03",
            "bb23ab6ea6a04e0ebe07bfc862008638",
            "0fd6d93c94144f30b8b4e08e7a393f48",
            "1a7203c5d10147d6a642074769103e91",
            "a5465d3f49e34f1a9b64cd7c51ac7ef4",
            "6b3b27676f9f4160a4a2b010da429631",
            "344817c38316451a9d1e5c93b339646d",
            "7c01e924d53343d4bff9c12202028661",
            "624743ed6c124cdd8d3762ad86d8c04b",
            "764dfe3305744abeabe33684645cb923",
            "220bfc57d89e453099494a30613520a7",
            "f89e84c620d24595a7caf4c3e12a21b7",
            "9a4986ad72064021a96ce0e7b4840454",
            "101fa866880b49bfb39e63326e90e245",
            "5a2a4f984e4d4637a3ddede5daacdb6a",
            "7f6ff3189bd04fdb931596788f572ac7",
            "58504abdc59240d4918710e213fddc08",
            "12328e8125d34598bc3123b2f76dc84c",
            "da7ce8e1b7d246eb87a8524b0c6a2dd6",
            "b2bee46fbebd406cb64b104f621367db",
            "d1dcae6b1d7740ae995fdfdaef19ad98",
            "3af1e7a50fa44199a7d2ec4b3a195d5a",
            "095e1bd7ffc94b6793c084a79c860749",
            "c3e9267132204ac8be4c206fda329710",
            "f68f703f80ad47a7b78c1abfb1d53050",
            "49a7bf9b767b45f39de5cbffca3927a7",
            "0cde5e7b475f400f8e9a74b033af3fac",
            "e5867a598b98473285ec974d686ef4ba",
            "352e2c526547428993c31684c77b1670",
            "565d5fe2bec14f6aa97a34cc4967084c",
            "45bf1d1a795d467cb07776861e3ec059",
            "316e0bcd04524a1bb2ef04fd68ca9ed1",
            "b791ca0db1c3476ea95787d734607ae4",
            "0cbb166bb81a4da9a2570511d28e0d71",
            "dc13a201dc15475ea339a330fd528c2f",
            "8ed706395d894d02b0697d7e496e65f6",
            "bd0fada771d04f44a4b20bf498849219",
            "6ead2ec411514e0ca0695983fc3bb81d",
            "3ac1c67d060347c9bc7a8112ddffade9",
            "6c73284c06e34ddbb792e2def62f17c3",
            "c0e4316985104388a56b8828f08e759e",
            "7d00e548b7034dc68dfa6bb64506fed7",
            "bc20dadd4c284a5282c19cb9c05bd977",
            "1a3fcd7e1afe4e02a261f10381ea4e61",
            "1520c2151ef74184950365a6b8c57dab",
            "7b7c320b81274d43a9e7614c5f5a80dc",
            "a39d92c8779a4148a4752974ae613c49",
            "01c5bad3423443b08c33974f6db87bb4",
            "d271466b464747cfbf9e39cd2f6d2479",
            "d9137795d8ed497c96b064078e7ed0dc",
            "d1cf85b21e8f45ea9e8a2e74a527de40",
            "f785337a98cb4f2491b3fbcd3eeb7873",
            "1fea2a1c8cc6418e851adc6cfa119670",
            "c4e9d59d2ca44db8b419b777f7c38978",
            "883e567c7b0f48a39a4d576749a87510",
            "7f36bb0bcac0437f96f9ba10cdd715c9",
            "cdd71f69a4d74d9c94f12973ce6f1622",
            "01fc4ab4aa764327bb2f1b869887e404",
            "fcb8698410eb49e388f3c1e93917bfed",
            "57ea38b9b1b0431c80b47d6a2dc521c2",
            "f64bceb57a504cc581ae17af0e2e25f6",
            "2f411d75c0bb4e2791588bfc2023da12",
            "a4b6f65c1ee644569c75679323d1a017",
            "cb6917b69250475aaf0a43124f721ac8",
            "1aaa1a470f8845b39ef089268af93d8a",
            "c8d0daac4cef41a7ba9f0da041f460ab",
            "5657445d495c4d779ec667130dff889c",
            "a5cc7361c23b4d38acf6167e22d20d27",
            "9b63439bc87544a6942f5d69d5f1aad7",
            "7744b4f072f74965bfbd6d197c1b0327",
            "688c813998b9475c8ad92055f7f4fff4",
            "9ca8da6f4b50496b9d6e1cb86f51efb6",
            "441c6fcf3eda4775b2896f6f2cb2614a",
            "2981f37ee9164b9ba2d018e918fe7a27",
            "6a431a555b724a618e76e25954ed7c23",
            "36037ee9c1234421aef390b88431379f",
            "36fd8ab4ba7c4ba38b64360b4ad59259",
            "775af11bc8d04f4aa1e58ac7598895bb",
            "995e4d5b79ae4cb796fd92a8ff183a83",
            "3391d26a495745a8b985734727ad4349",
            "702b896f63694995b85e9e37c9bab67d",
            "cf923275ae2f41e3b56ee316b66c230a",
            "7bd0bdca2886472ebc1df745fd89077e",
            "a3f4d89d71b8432295bd7286176ea321",
            "53f6908018294382914ab6da66f2d6f1",
            "03ebd3236e3545ac852402b1599338f8",
            "d92f6f79f0c349f0a133a531377041b4",
            "8394b5cbd4ec4e07aa2575060e3337d4",
            "77f7c8f231504edf973c21a8af827794",
            "e3d4ce1e561046f783fdbec6245f21c3",
            "800a9383deb445a4b8fcc5a06024920d",
            "5b159b2fd42d4e65a074c62ef58198ff",
            "df2f0e7626c74266a77d3c890123ad2d",
            "a3e541ff5d8545c0b4bef6672086b352",
            "a9a75984db764712b660ef6fb23e684c",
            "4d3372d3be6a40deb0904cb7c449191f",
            "a8ea0ce184fc49d880beef3ff63b71d1",
            "3f2267125cad4c0ab0aaefb7bc375fa6",
            "3bb7a765c4024ba8b9a26aa8f57e1865",
            "515fbdf177294a4fafbde1f2ae0d5ecb",
            "1b0e271c3e7a4ab28c9d2d26ff090eb7",
            "22e8596ffa314352a3fbb9ef1ac72791",
            "95d7838270ff4f9ea1fdbd5aca1ba3cc",
            "efda07e8db2f4cfb95a2b0479b383b7a",
            "9d769ef5bd044fc5980ad437f9fd64e3",
            "dea5d9e7712e4f9eac3fb29e6cdd6c81",
            "c13015e8772c475abd9988080b76c61a",
            "e814f8d65cd84b19b0b3e20ec52c911c",
            "5ab7fdc279ae44a388954a854819ea77",
            "5ddd1db8676b44129a274703ca33a640",
            "3ab7a2e6bb5243c6909332d72f6eb822",
            "3bc366905ca443949b6bf38394d1ad9f",
            "71345870190b4b58afa7307d26c69874",
            "b2cc0e8f1ccb4d8b91fc1d6e9ae3fed3"
          ]
        },
        "id": "wmH1q6Rco4hv",
        "outputId": "1a8e33d3-3d60-49a1-afe2-9e6c52a4b2c9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ef6947951ef45a599e3abf85211c2ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d02a10bd641488e808bc61109e3593d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1624a1e098654ff9826b64317d514655",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "241dd909958446dc8860a8db28db1e76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5465d3f49e34f1a9b64cd7c51ac7ef4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f6ff3189bd04fdb931596788f572ac7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cde5e7b475f400f8e9a74b033af3fac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ead2ec411514e0ca0695983fc3bb81d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d271466b464747cfbf9e39cd2f6d2479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57ea38b9b1b0431c80b47d6a2dc521c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "688c813998b9475c8ad92055f7f4fff4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf923275ae2f41e3b56ee316b66c230a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df2f0e7626c74266a77d3c890123ad2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efda07e8db2f4cfb95a2b0479b383b7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8001b5b03c0b4993b2dcb79ba6001bf9",
            "fe081da593934f97a4f2ece04aeeecb8",
            "434d5a8c4cd540c48e063aece1f75b20",
            "9e0f2f11417c432a81d840d327289b4a",
            "e460ad4374784f55ba9bbe05b755c603",
            "ca8c17f0c2a04497b4604acb471fb4b0",
            "95e8845db5d1497698aa56b0a5662625",
            "f92ad7f24a374c14be5792d9a2341e1e",
            "cb7681962c1a452f82a1334e471ffe28",
            "22eab73b52ee403699cb674cde2f915a",
            "a49593a94f904fdb8b78218de071b612"
          ]
        },
        "id": "TQZeyJzTnBMu",
        "outputId": "502d10f7-da01-43a1-989e-7857599e3858"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8001b5b03c0b4993b2dcb79ba6001bf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/73 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embeddings = sentence_model.encode(docs, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl0Kt3tToaD_"
      },
      "outputs": [],
      "source": [
        "# Train BERTopic\n",
        "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
        "topic_model = BERTopic(vectorizer_model=vectorizer_model).fit(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2F-fRh3B_dM",
        "outputId": "35acab0d-a401-4c0f-b008-64f97b2534bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{-1: [('data', 0.009940528789107237),\n",
              "  ('learning', 0.009240378930968872),\n",
              "  ('model', 0.008843291252728142),\n",
              "  ('models', 0.00859652959006869),\n",
              "  ('neural', 0.007054295430212847),\n",
              "  ('training', 0.006598818004227983),\n",
              "  ('methods', 0.006444560054011029),\n",
              "  ('networks', 0.006246437679664433),\n",
              "  ('method', 0.0060055804780751185),\n",
              "  ('propose', 0.005686909835149047)],\n",
              " 0: [('learning', 0.015551546622991217),\n",
              "  ('reinforcement', 0.014286977495735929),\n",
              "  ('reinforcement learning', 0.014256522062384607),\n",
              "  ('policy', 0.014161268634678273),\n",
              "  ('rl', 0.013332452602941592),\n",
              "  ('agents', 0.010305083410798648),\n",
              "  ('algorithm', 0.01014509558938816),\n",
              "  ('regret', 0.009715104669111393),\n",
              "  ('algorithms', 0.009061469336128544),\n",
              "  ('problem', 0.008331993892280962)],\n",
              " 1: [('graph', 0.05848209255457942),\n",
              "  ('gnns', 0.02634758614964423),\n",
              "  ('graphs', 0.022775285586574035),\n",
              "  ('graph neural', 0.02020216910739186),\n",
              "  ('node', 0.01876000048381857),\n",
              "  ('gnn', 0.017337038903555244),\n",
              "  ('networks', 0.015230070840023315),\n",
              "  ('learning', 0.012954535666831456),\n",
              "  ('neural', 0.012691086972623939),\n",
              "  ('neural networks', 0.012432884375667877)],\n",
              " 2: [('adversarial', 0.05192029162885671),\n",
              "  ('robustness', 0.0365739832851077),\n",
              "  ('attacks', 0.028958843518492414),\n",
              "  ('robust', 0.019413426368726665),\n",
              "  ('adversarial robustness', 0.018878271783495017),\n",
              "  ('training', 0.01811260628037629),\n",
              "  ('attack', 0.01764655675829838),\n",
              "  ('perturbations', 0.01668258649850373),\n",
              "  ('adversarial attacks', 0.01370867367151707),\n",
              "  ('adversarial training', 0.013228319964893166)],\n",
              " 3: [('3d', 0.04757441908556868),\n",
              "  ('pose', 0.025031275495805992),\n",
              "  ('reconstruction', 0.020604158111467527),\n",
              "  ('shape', 0.019172925073509935),\n",
              "  ('point', 0.015544226191494748),\n",
              "  ('object', 0.01549388802386288),\n",
              "  ('scene', 0.014219570726659693),\n",
              "  ('surface', 0.01416696430043485),\n",
              "  ('rendering', 0.010796447904700144),\n",
              "  ('mesh', 0.010427689672170672)],\n",
              " 4: [('networks', 0.0259657238931084),\n",
              "  ('neural', 0.023606810223658837),\n",
              "  ('neural networks', 0.019768155942910582),\n",
              "  ('gradient', 0.016302563134166274),\n",
              "  ('training', 0.015857062037232982),\n",
              "  ('network', 0.013978080616470125),\n",
              "  ('deep', 0.013884451090440647),\n",
              "  ('descent', 0.012168770542308836),\n",
              "  ('gradient descent', 0.011944642039963949),\n",
              "  ('generalization', 0.010722729577196253)],\n",
              " 5: [('stochastic', 0.026228926715989722),\n",
              "  ('gradient', 0.02420192746033395),\n",
              "  ('optimization', 0.02411544566901387),\n",
              "  ('descent', 0.01839949689926746),\n",
              "  ('sgd', 0.01765245064588312),\n",
              "  ('convergence', 0.016917431179051704),\n",
              "  ('convex', 0.016508700473421383),\n",
              "  ('nonconvex', 0.016359047727450362),\n",
              "  ('methods', 0.01538212702120801),\n",
              "  ('problems', 0.013002264403313375)],\n",
              " 6: [('generative', 0.028115114191609024),\n",
              "  ('models', 0.020662436962645997),\n",
              "  ('variational', 0.020443437068509675),\n",
              "  ('generative models', 0.016747067544475573),\n",
              "  ('flows', 0.014839643681746196),\n",
              "  ('distributions', 0.014467331970022493),\n",
              "  ('distribution', 0.013952444821007973),\n",
              "  ('density', 0.013373964995005757),\n",
              "  ('normalizing', 0.012259412346805037),\n",
              "  ('data', 0.0120892309855872)],\n",
              " 7: [('causal', 0.06261644949226237),\n",
              "  ('treatment', 0.022614527667376046),\n",
              "  ('effects', 0.016509054862435837),\n",
              "  ('effect', 0.015942655035034163),\n",
              "  ('variables', 0.015834122754850157),\n",
              "  ('data', 0.012924513660385967),\n",
              "  ('interventions', 0.011916218929934403),\n",
              "  ('outcomes', 0.011685629671588059),\n",
              "  ('treatment effect', 0.01117126050611428),\n",
              "  ('observational', 0.010672861764276278)],\n",
              " 8: [('neural', 0.024494620477640096),\n",
              "  ('brain', 0.017948787574589148),\n",
              "  ('networks', 0.015988066894143647),\n",
              "  ('activity', 0.015793491581488753),\n",
              "  ('spiking', 0.01440809928836116),\n",
              "  ('neurons', 0.013443547357552372),\n",
              "  ('network', 0.012629582785317275),\n",
              "  ('dynamics', 0.01239705606611995),\n",
              "  ('biological', 0.010884795354078403),\n",
              "  ('time', 0.010565701188348287)],\n",
              " 9: [('video', 0.03678551464239276),\n",
              "  ('language', 0.019337141676532627),\n",
              "  ('visual', 0.019331917332148348),\n",
              "  ('videos', 0.016291578649800072),\n",
              "  ('multimodal', 0.013968563625499112),\n",
              "  ('temporal', 0.013477632457279894),\n",
              "  ('action', 0.0130377172972512),\n",
              "  ('motion', 0.01119593947386655),\n",
              "  ('transformer', 0.011104501693219351),\n",
              "  ('attention', 0.009969807798252772)],\n",
              " 10: [('vision', 0.031246834712588267),\n",
              "  ('transformer', 0.027032259429116808),\n",
              "  ('transformers', 0.0268691361114833),\n",
              "  ('image', 0.018813103384351968),\n",
              "  ('vision transformers', 0.015430264330617413),\n",
              "  ('attention', 0.014235221053749171),\n",
              "  ('vision transformer', 0.013667836881253196),\n",
              "  ('selfattention', 0.013009455680048583),\n",
              "  ('visual', 0.01072447288241932),\n",
              "  ('features', 0.010701086400427556)],\n",
              " 11: [('privacy', 0.06220239008547991),\n",
              "  ('private', 0.044175261841245636),\n",
              "  ('differential privacy', 0.027206275581476234),\n",
              "  ('differentially', 0.02518809489760233),\n",
              "  ('differentially private', 0.024258286856516504),\n",
              "  ('differential', 0.023674581344790783),\n",
              "  ('data', 0.016617078841518695),\n",
              "  ('dp', 0.015153559996372794),\n",
              "  ('learning', 0.01250417500791456),\n",
              "  ('mechanism', 0.011754004677368481)],\n",
              " 12: [('contrastive', 0.02052105770874744),\n",
              "  ('segmentation', 0.020395892988614377),\n",
              "  ('object', 0.0195711079054579),\n",
              "  ('semantic', 0.018466026152280685),\n",
              "  ('learning', 0.016111176824635393),\n",
              "  ('categories', 0.01350669115904152),\n",
              "  ('detection', 0.0129794004878636),\n",
              "  ('contrastive learning', 0.01278058780409003),\n",
              "  ('selfsupervised', 0.012727359042211197),\n",
              "  ('representations', 0.012285446163453406)],\n",
              " 13: [('image', 0.027603478053410763),\n",
              "  ('gans', 0.02423487112441666),\n",
              "  ('gan', 0.02377811302554969),\n",
              "  ('generation', 0.022606201819370682),\n",
              "  ('generative', 0.01753716407512859),\n",
              "  ('generator', 0.01700650429241209),\n",
              "  ('images', 0.016719833057984034),\n",
              "  ('discriminator', 0.016276659904185305),\n",
              "  ('generative adversarial', 0.015282808722991042),\n",
              "  ('training', 0.014934522345527132)],\n",
              " 14: [('pruning', 0.036236114917739856),\n",
              "  ('sparse', 0.024952368353723407),\n",
              "  ('training', 0.021906129354623282),\n",
              "  ('compression', 0.01959944133913825),\n",
              "  ('ticket', 0.018617588795692166),\n",
              "  ('neural', 0.017774596160338586),\n",
              "  ('sparsity', 0.015952999428798097),\n",
              "  ('networks', 0.0153744729563894),\n",
              "  ('network', 0.01493505904172808),\n",
              "  ('winning', 0.0146557048962405)],\n",
              " 15: [('matrix', 0.03789393143273457),\n",
              "  ('sparse', 0.017465259787987575),\n",
              "  ('pca', 0.016392451129599295),\n",
              "  ('analysis', 0.01540284709869197),\n",
              "  ('recovery', 0.01437198451830392),\n",
              "  ('matrices', 0.014194539597143877),\n",
              "  ('lowrank', 0.014114933535482987),\n",
              "  ('algorithm', 0.013410739683360432),\n",
              "  ('rank', 0.012715542052537275),\n",
              "  ('rate', 0.012603527871348339)],\n",
              " 16: [('text', 0.032159078446691275),\n",
              "  ('language', 0.02575939124807789),\n",
              "  ('models', 0.021080305039027393),\n",
              "  ('generation', 0.020370263490256446),\n",
              "  ('model', 0.018772636841855716),\n",
              "  ('multilingual', 0.017754773084896786),\n",
              "  ('speech', 0.016976510296998402),\n",
              "  ('text generation', 0.01464902857867602),\n",
              "  ('asr', 0.01464902857867602),\n",
              "  ('languages', 0.014587787923110475)],\n",
              " 17: [('calibration', 0.02928277108136733),\n",
              "  ('test', 0.023237742271490756),\n",
              "  ('distribution', 0.021292143551343085),\n",
              "  ('shift', 0.021068328296443162),\n",
              "  ('shifts', 0.016333398406373302),\n",
              "  ('generalization', 0.01514721601832776),\n",
              "  ('ensemble', 0.015132925634117278),\n",
              "  ('ensembles', 0.013262964181413178),\n",
              "  ('distribution shifts', 0.013020486348496254),\n",
              "  ('uncertainty', 0.013012303669706349)],\n",
              " 18: [('metalearning', 0.057995648658989825),\n",
              "  ('tasks', 0.024771900511712828),\n",
              "  ('task', 0.02292194310716467),\n",
              "  ('learning', 0.01952757592012504),\n",
              "  ('meta', 0.01836422949230427),\n",
              "  ('fewshot', 0.01714976451407441),\n",
              "  ('multitask', 0.011442494168615284),\n",
              "  ('generalization', 0.01129291881620393),\n",
              "  ('meta learning', 0.011214693054492235),\n",
              "  ('model', 0.011091699762859085)],\n",
              " 19: [('fairness', 0.04255810550793465),\n",
              "  ('data', 0.01635017025163369),\n",
              "  ('classification', 0.014989547888161894),\n",
              "  ('fair', 0.014450671087615621),\n",
              "  ('loss', 0.013081468259631425),\n",
              "  ('training', 0.011721768514908342),\n",
              "  ('label', 0.011289211346935444),\n",
              "  ('models', 0.010705598828590112),\n",
              "  ('performance', 0.010348930125184327),\n",
              "  ('model', 0.010224613473386834)],\n",
              " 20: [('domain', 0.0930657183153903),\n",
              "  ('adaptation', 0.04932023555255184),\n",
              "  ('source', 0.04850927639429228),\n",
              "  ('target', 0.04769474926161556),\n",
              "  ('domain adaptation', 0.0458565151748611),\n",
              "  ('domains', 0.03231435781752255),\n",
              "  ('target domain', 0.026731201593048075),\n",
              "  ('unsupervised domain', 0.02360466003885552),\n",
              "  ('source domain', 0.020904355146405384),\n",
              "  ('unsupervised', 0.018685492753721375)],\n",
              " 21: [('processes', 0.040030762991673005),\n",
              "  ('gaussian', 0.03898952635328215),\n",
              "  ('gaussian processes', 0.02815174575102886),\n",
              "  ('variational', 0.02718451512461865),\n",
              "  ('inference', 0.025935906740434576),\n",
              "  ('process', 0.018306026484642017),\n",
              "  ('posterior', 0.01661294966575425),\n",
              "  ('methods', 0.012491293239474979),\n",
              "  ('time', 0.012287045396706026),\n",
              "  ('gps', 0.011970262094208883)],\n",
              " 22: [('continual', 0.050544566205715825),\n",
              "  ('continual learning', 0.045319442113858265),\n",
              "  ('forgetting', 0.039874458645183145),\n",
              "  ('tasks', 0.030756797605987818),\n",
              "  ('learning', 0.029775105361876154),\n",
              "  ('catastrophic', 0.027871189667232614),\n",
              "  ('catastrophic forgetting', 0.027562887806751105),\n",
              "  ('cl', 0.02497594707670173),\n",
              "  ('new', 0.019960052595632778),\n",
              "  ('knowledge', 0.01910161440724766)],\n",
              " 23: [('attention', 0.042029649966825344),\n",
              "  ('transformer', 0.03841367875415638),\n",
              "  ('lowrank', 0.01868902017598566),\n",
              "  ('selfattention', 0.018463259712281015),\n",
              "  ('transformers', 0.018020740498500748),\n",
              "  ('language', 0.01755803641520418),\n",
              "  ('models', 0.015266735438405513),\n",
              "  ('positional', 0.014622447326059036),\n",
              "  ('long', 0.01439456409280914),\n",
              "  ('finetuning', 0.014100387061784313)],\n",
              " 24: [('molecular', 0.05249223328591256),\n",
              "  ('molecules', 0.03056869472715803),\n",
              "  ('drug', 0.02160263277873949),\n",
              "  ('graph', 0.019459613424175615),\n",
              "  ('hyperbolic', 0.01598959260501911),\n",
              "  ('protein', 0.015599156022987984),\n",
              "  ('prediction', 0.014536524700173893),\n",
              "  ('distance', 0.012750122432746182),\n",
              "  ('space', 0.01239020503822283),\n",
              "  ('3d', 0.011809168442383904)],\n",
              " 25: [('neural', 0.029168378474432495),\n",
              "  ('differential', 0.02648994948944389),\n",
              "  ('differential equations', 0.022867121720424544),\n",
              "  ('equations', 0.022210237119294825),\n",
              "  ('adjoint', 0.01531797492892567),\n",
              "  ('odes', 0.015042554109268929),\n",
              "  ('method', 0.014050718434782875),\n",
              "  ('ode', 0.013360253125718442),\n",
              "  ('networks', 0.012983726030543985),\n",
              "  ('lshsmile', 0.012507061816197769)],\n",
              " 26: [('clustering', 0.05585063608702952),\n",
              "  ('kmeans', 0.027412340227164045),\n",
              "  ('points', 0.022795582379767487),\n",
              "  ('algorithm', 0.02163014152260051),\n",
              "  ('cluster', 0.021064971664854767),\n",
              "  ('objective', 0.019109919924873545),\n",
              "  ('clusters', 0.017220673039823265),\n",
              "  ('problem', 0.014953076837472627),\n",
              "  ('queries', 0.014145122742545481),\n",
              "  ('coresets', 0.013953473807376025)],\n",
              " 27: [('federated', 0.05560825092002525),\n",
              "  ('federated learning', 0.04330917837365077),\n",
              "  ('clients', 0.04067404172628043),\n",
              "  ('fl', 0.03336199458660196),\n",
              "  ('personalized', 0.029464267257462092),\n",
              "  ('client', 0.024776408184323577),\n",
              "  ('learning', 0.023200419680810453),\n",
              "  ('data', 0.022362395810628335),\n",
              "  ('model', 0.01944236743978317),\n",
              "  ('validation', 0.014136486002663703)],\n",
              " 28: [('rules', 0.031826080948571055),\n",
              "  ('explanations', 0.024274297006709068),\n",
              "  ('shapley', 0.02424676650610115),\n",
              "  ('rule', 0.02253772069515483),\n",
              "  ('shapley values', 0.01926996468583092),\n",
              "  ('features', 0.018950647570873703),\n",
              "  ('model', 0.018763690035306514),\n",
              "  ('feature', 0.018639110398631753),\n",
              "  ('values', 0.014358855586632814),\n",
              "  ('interpretation', 0.014261642829409218)],\n",
              " 29: [('transport', 0.035532374347503996),\n",
              "  ('optimal', 0.030252404541120874),\n",
              "  ('optimal transport', 0.029725335031433518),\n",
              "  ('wasserstein', 0.026832148817459524),\n",
              "  ('barycenter', 0.021145466389686653),\n",
              "  ('riemannian', 0.019560590857558933),\n",
              "  ('gradient', 0.019473510347211783),\n",
              "  ('bounds', 0.017118371459149226),\n",
              "  ('quadrature', 0.01676387712999896),\n",
              "  ('distance', 0.016295827440861013)],\n",
              " 30: [('communication', 0.047237261795344127),\n",
              "  ('decentralized', 0.039987931909075604),\n",
              "  ('averaging', 0.028731358267276148),\n",
              "  ('distributed', 0.025572741037673753),\n",
              "  ('local', 0.02203777117458637),\n",
              "  ('sgd', 0.02190968788724261),\n",
              "  ('federated', 0.021054615272078914),\n",
              "  ('federated learning', 0.02103676923855647),\n",
              "  ('compression', 0.01930237420043876),\n",
              "  ('convergence', 0.018223397838438755)],\n",
              " 31: [('bounds', 0.05710546585446165),\n",
              "  ('risk', 0.037472402542988684),\n",
              "  ('cmi', 0.027736877412695343),\n",
              "  ('surrogate', 0.02751123405421172),\n",
              "  ('spo', 0.02165957800663266),\n",
              "  ('spo loss', 0.01742868799627162),\n",
              "  ('generalization', 0.017342206910923117),\n",
              "  ('bound', 0.01721887357924018),\n",
              "  ('rates', 0.016459053767173368),\n",
              "  ('loss', 0.01553206620230024)],\n",
              " 32: [('nas', 0.05413420437834642),\n",
              "  ('search', 0.036116377457614625),\n",
              "  ('architecture', 0.03213623955621466),\n",
              "  ('architecture search', 0.025878765060940896),\n",
              "  ('performance', 0.02430766397371121),\n",
              "  ('architectures', 0.023463988225628042),\n",
              "  ('neural architecture', 0.02119694257077476),\n",
              "  ('neural', 0.01768652149180342),\n",
              "  ('search nas', 0.016417340196340446),\n",
              "  ('training', 0.015894411303713156)],\n",
              " 33: [('active learning', 0.06317852649803885),\n",
              "  ('active', 0.06154897131715888),\n",
              "  ('acquisition', 0.030856305711226904),\n",
              "  ('label', 0.026374685260076806),\n",
              "  ('algorithm', 0.02450209506937931),\n",
              "  ('teaching', 0.022866539736380427),\n",
              "  ('learning', 0.022635854142429822),\n",
              "  ('setting', 0.019983002942123306),\n",
              "  ('labeling', 0.016720420339879166),\n",
              "  ('instance', 0.015872566630221144)],\n",
              " 34: [('restoration', 0.029428433831335362),\n",
              "  ('denoising', 0.028673565731962163),\n",
              "  ('image', 0.028158890337094768),\n",
              "  ('inverse', 0.02575820620145125),\n",
              "  ('denoisers', 0.024115456121012662),\n",
              "  ('image restoration', 0.021923141928193328),\n",
              "  ('blind', 0.02158244960724936),\n",
              "  ('inverse problems', 0.02032023756907802),\n",
              "  ('problems', 0.018092217759776118),\n",
              "  ('pnp', 0.01653069716014578)],\n",
              " 35: [('bayesian optimization', 0.04812070725754106),\n",
              "  ('optimization', 0.047078489393666934),\n",
              "  ('bayesian', 0.043575314734677406),\n",
              "  ('acquisition', 0.030473815058486405),\n",
              "  ('function', 0.029497828342539705),\n",
              "  ('acquisition function', 0.0292432111602581),\n",
              "  ('bo', 0.022796298558350806),\n",
              "  ('expected improvement', 0.01892544814090238),\n",
              "  ('blackbox', 0.01784018010065211),\n",
              "  ('expected', 0.016844346823831693)],\n",
              " 36: [('mcmc', 0.021282311586481438),\n",
              "  ('gradients', 0.020309038916991064),\n",
              "  ('computation graphs', 0.019569493824985535),\n",
              "  ('differentiable', 0.017673339944580053),\n",
              "  ('stochastic', 0.016856588511247866),\n",
              "  ('models', 0.01590311861262597),\n",
              "  ('sampling', 0.015845916918292572),\n",
              "  ('monte carlo', 0.015818687740613218),\n",
              "  ('carlo', 0.015818687740613218),\n",
              "  ('monte', 0.015739767650071037)],\n",
              " 37: [('program', 0.07877161351395527),\n",
              "  ('programs', 0.06306228403972951),\n",
              "  ('imperative', 0.0330214027523081),\n",
              "  ('synthesis', 0.027887856663016825),\n",
              "  ('execution', 0.026418727362571136),\n",
              "  ('code', 0.0242413987628797),\n",
              "  ('program synthesis', 0.02367424052594511),\n",
              "  ('automl', 0.02158949971718964),\n",
              "  ('dl', 0.020547899059777552),\n",
              "  ('terra', 0.018796220622127373)],\n",
              " 38: [('reasoning', 0.0811291213057659),\n",
              "  ('satnet', 0.024761039557997185),\n",
              "  ('symbolic', 0.02203883172783262),\n",
              "  ('scallop', 0.02165877777392643),\n",
              "  ('logical', 0.020572344799962478),\n",
              "  ('knowledge', 0.018543333609698016),\n",
              "  ('abduction', 0.018477790531587802),\n",
              "  ('neural', 0.01817946196176852),\n",
              "  ('neurosymbolic', 0.016847770072154322),\n",
              "  ('tasks', 0.016467068823353307)]}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topic_model.get_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUo_cP_ZoFgU"
      },
      "outputs": [],
      "source": [
        "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9TG0P5Nyx2Cb"
      },
      "outputs": [],
      "source": [
        "#@title Function override\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from umap import UMAP\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def visualize_documents(topic_model,\n",
        "                        docs: List[str],\n",
        "                        topics: List[int] = None,\n",
        "                        embeddings: np.ndarray = None,\n",
        "                        reduced_embeddings: np.ndarray = None,\n",
        "                        sample: float = None,\n",
        "                        hide_annotations: bool = False,\n",
        "                        hide_document_hover: bool = False,\n",
        "                        hover_text_labels: List[str] = None,\n",
        "                        custom_labels: bool = False,\n",
        "                        width: int = 1200,\n",
        "                        height: int = 750):\n",
        "    \"\"\" Visualize documents and their topics in 2D\n",
        "    Arguments:\n",
        "        topic_model: A fitted BERTopic instance.\n",
        "        docs: The documents you used when calling either `fit` or `fit_transform`\n",
        "        topics: A selection of topics to visualize.\n",
        "                Not to be confused with the topics that you get from `.fit_transform`.\n",
        "                For example, if you want to visualize only topics 1 through 5:\n",
        "                `topics = [1, 2, 3, 4, 5]`.\n",
        "        embeddings: The embeddings of all documents in `docs`.\n",
        "        reduced_embeddings: The 2D reduced embeddings of all documents in `docs`.\n",
        "        sample: The percentage of documents in each topic that you would like to keep.\n",
        "                Value can be between 0 and 1. Setting this value to, for example,\n",
        "                0.1 (10% of documents in each topic) makes it easier to visualize\n",
        "                millions of documents as a subset is chosen.\n",
        "        hide_annotations: Hide the names of the traces on top of each cluster.\n",
        "        hide_document_hover: Hide the content of the documents when hovering over\n",
        "                             specific points. Helps to speed up generation of visualization.\n",
        "        custom_labels: Whether to use custom topic labels that were defined using \n",
        "                       `topic_model.set_topic_labels`.\n",
        "        width: The width of the figure.\n",
        "        height: The height of the figure.\n",
        "    Examples:\n",
        "    To visualize the topics simply run:\n",
        "    ```python\n",
        "    topic_model.visualize_documents(docs)\n",
        "    ```\n",
        "    Do note that this re-calculates the embeddings and reduces them to 2D.\n",
        "    The advised and prefered pipeline for using this function is as follows:\n",
        "    ```python\n",
        "    from sklearn.datasets import fetch_20newsgroups\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    from bertopic import BERTopic\n",
        "    from umap import UMAP\n",
        "    # Prepare embeddings\n",
        "    docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
        "    sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
        "    # Train BERTopic\n",
        "    topic_model = BERTopic().fit(docs, embeddings)\n",
        "    # Reduce dimensionality of embeddings, this step is optional\n",
        "    # reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
        "    # Run the visualization with the original embeddings\n",
        "    topic_model.visualize_documents(docs, embeddings=embeddings)\n",
        "    # Or, if you have reduced the original embeddings already:\n",
        "    topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings)\n",
        "    ```\n",
        "    Or if you want to save the resulting figure:\n",
        "    ```python\n",
        "    fig = topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings)\n",
        "    fig.write_html(\"path/to/file.html\")\n",
        "    ```\n",
        "    <iframe src=\"../../getting_started/visualization/documents.html\"\n",
        "    style=\"width:1000px; height: 800px; border: 0px;\"\"></iframe>\n",
        "    \"\"\"\n",
        "    topic_per_doc = topic_model.topics_\n",
        "\n",
        "    # Sample the data to optimize for visualization and dimensionality reduction\n",
        "    if sample is None or sample > 1:\n",
        "        sample = 1\n",
        "\n",
        "    indices = []\n",
        "    for topic in set(topic_per_doc):\n",
        "        s = np.where(np.array(topic_per_doc) == topic)[0]\n",
        "        size = len(s) if len(s) < 100 else int(len(s) * sample)\n",
        "        indices.extend(np.random.choice(s, size=size, replace=False))\n",
        "    indices = np.array(indices)\n",
        "\n",
        "    df = pd.DataFrame({\"topic\": np.array(topic_per_doc)[indices]})\n",
        "    df[\"doc\"] = [docs[index] for index in indices]\n",
        "    df['doc_label'] = [hover_text_labels[index] for index in indices] # NB: added for hover text\n",
        "    df[\"topic\"] = [topic_per_doc[index] for index in indices]\n",
        "\n",
        "    # Extract embeddings if not already done\n",
        "    if sample is None:\n",
        "        if embeddings is None and reduced_embeddings is None:\n",
        "            embeddings_to_reduce = topic_model._extract_embeddings(df.doc.to_list(), method=\"document\")\n",
        "        else:\n",
        "            embeddings_to_reduce = embeddings\n",
        "    else:\n",
        "        if embeddings is not None:\n",
        "            embeddings_to_reduce = embeddings[indices]\n",
        "        elif embeddings is None and reduced_embeddings is None:\n",
        "            embeddings_to_reduce = topic_model._extract_embeddings(df.doc.to_list(), method=\"document\")\n",
        "\n",
        "    # Reduce input embeddings\n",
        "    if reduced_embeddings is None:\n",
        "        umap_model = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit(embeddings_to_reduce)\n",
        "        embeddings_2d = umap_model.embedding_\n",
        "    elif sample is not None and reduced_embeddings is not None:\n",
        "        embeddings_2d = reduced_embeddings[indices]\n",
        "    elif sample is None and reduced_embeddings is not None:\n",
        "        embeddings_2d = reduced_embeddings\n",
        "\n",
        "    unique_topics = set(topic_per_doc)\n",
        "    if topics is None:\n",
        "        topics = unique_topics\n",
        "\n",
        "    # Combine data\n",
        "    df[\"x\"] = embeddings_2d[:, 0]\n",
        "    df[\"y\"] = embeddings_2d[:, 1]\n",
        "\n",
        "    # Prepare text and names\n",
        "    if topic_model.custom_labels_ is not None and custom_labels:\n",
        "        names = [topic_model.custom_labels_[topic + topic_model._outliers] for topic in unique_topics]\n",
        "    else:\n",
        "        names = [f\"{topic}_\" + \"_\".join([word for word, value in topic_model.get_topic(topic)][:3]) for topic in unique_topics]\n",
        "\n",
        "    # Visualize\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Outliers and non-selected topics\n",
        "    non_selected_topics = set(unique_topics).difference(topics)\n",
        "    if len(non_selected_topics) == 0:\n",
        "        non_selected_topics = [-1]\n",
        "\n",
        "    selection = df.loc[df.topic.isin(non_selected_topics), :]\n",
        "    selection[\"text\"] = \"\"\n",
        "    selection.loc[len(selection), :] = [None, None, None, selection.x.mean(), selection.y.mean(), \"Other documents\"]\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scattergl(\n",
        "            x=selection.x,\n",
        "            y=selection.y,\n",
        "            hovertext=selection.doc_label if not hide_document_hover else None,\n",
        "            hoverinfo=\"text\",\n",
        "            mode='markers+text',\n",
        "            name=\"other\",\n",
        "            showlegend=False,\n",
        "            marker=dict(color='#CFD8DC', size=5, opacity=0.5)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Selected topics\n",
        "    for name, topic in zip(names, unique_topics):\n",
        "        if topic in topics and topic != -1:\n",
        "            selection = df.loc[df.topic == topic, :]\n",
        "            selection[\"text\"] = \"\"\n",
        "\n",
        "            if not hide_annotations:\n",
        "                selection.loc[len(selection), :] = [None, None, None, selection.x.mean(), selection.y.mean(), name]\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Scattergl(\n",
        "                    x=selection.x,\n",
        "                    y=selection.y,\n",
        "                    hovertext=selection.doc_label if not hide_document_hover else None,\n",
        "                    hoverinfo=\"text\",\n",
        "                    text=selection.text,\n",
        "                    mode='markers+text',\n",
        "                    name=name,\n",
        "                    textfont=dict(\n",
        "                        size=12,\n",
        "                    ),\n",
        "                    marker=dict(size=5, opacity=0.5)\n",
        "                )\n",
        "            )\n",
        "\n",
        "    # Add grid in a 'plus' shape\n",
        "    x_range = (df.x.min() - abs((df.x.min()) * .15), df.x.max() + abs((df.x.max()) * .15))\n",
        "    y_range = (df.y.min() - abs((df.y.min()) * .15), df.y.max() + abs((df.y.max()) * .15))\n",
        "    fig.add_shape(type=\"line\",\n",
        "                  x0=sum(x_range) / 2, y0=y_range[0], x1=sum(x_range) / 2, y1=y_range[1],\n",
        "                  line=dict(color=\"#CFD8DC\", width=2))\n",
        "    fig.add_shape(type=\"line\",\n",
        "                  x0=x_range[0], y0=sum(y_range) / 2, x1=x_range[1], y1=sum(y_range) / 2,\n",
        "                  line=dict(color=\"#9E9E9E\", width=2))\n",
        "    fig.add_annotation(x=x_range[0], y=sum(y_range) / 2, text=\"D1\", showarrow=False, yshift=10)\n",
        "    fig.add_annotation(y=y_range[1], x=sum(x_range) / 2, text=\"D2\", showarrow=False, xshift=10)\n",
        "\n",
        "    # Stylize layout\n",
        "    fig.update_layout(\n",
        "        template=\"simple_white\",\n",
        "        title={\n",
        "            'text': \"<b>Documents and Topics\",\n",
        "            'x': 0.5,\n",
        "            'xanchor': 'center',\n",
        "            'yanchor': 'top',\n",
        "            'font': dict(\n",
        "                size=22,\n",
        "                color=\"Black\")\n",
        "        },\n",
        "        width=width,\n",
        "        height=height\n",
        "    )\n",
        "\n",
        "    fig.update_xaxes(visible=False)\n",
        "    fig.update_yaxes(visible=False)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHOxli0Sq-7U"
      },
      "outputs": [],
      "source": [
        "titles = df_papers.title.tolist() # as hover text labels\n",
        "assert len(docs) == len(titles)\n",
        "\n",
        "fig = visualize_documents(topic_model,\n",
        "                        docs=docs,\n",
        "                        reduced_embeddings=reduced_embeddings,\n",
        "                        hover_text_labels=titles,\n",
        "                        width=1500,\n",
        "                        height=900\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "sOCQHn6A1T7d",
        "outputId": "5b45d4e7-5cbe-47b3-803c-0aaa91afcba7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"7f2c621b-4f86-4846-8384-b0431fda35f4\" class=\"plotly-graph-div\" style=\"height:900px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7f2c621b-4f86-4846-8384-b0431fda35f4\")) {                    Plotly.newPlot(                        \"7f2c621b-4f86-4846-8384-b0431fda35f4\",                        [{\"hoverinfo\":\"text\",\"hovertext\":[\"Modeling Heterogeneous Hierarchies with Relation-specific Hyperbolic Cones\",\"Adjusting for Autocorrelated Errors in Neural Networks for Time Series\",\"POODLE: Improving Few-shot Learning via Penalizing Out-of-Distribution Samples\",\"Adapting to function difficulty and growth conditions in private optimization\",\"FL-WBC: Enhancing Robustness against Model Poisoning Attacks in Federated Learning from a Client Perspective\",\"Multiclass Boosting and the Cost of Weak Learning\",\"Practical, Provably-Correct Interactive Learning in the Realizable Setting: The Power of True Believers\",\"Topographic VAEs learn Equivariant Capsules\",\"Deep Learning Through the Lens of Example Difficulty\",\"Semialgebraic Representation of Monotone Deep Equilibrium Models and Applications to Certification\",\"Curriculum Disentangled Recommendation with Noisy Multi-feedback\",\"A Theory of the Distortion-Perception Tradeoff in Wasserstein Space\",\"Exploiting a Zoo of Checkpoints for Unseen Tasks\",\"Deep Neural Networks as Point Estimates for Deep Gaussian Processes\",\"Tractable Regularization of Probabilistic Circuits\",\"Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels\",\"Learning Gaussian Mixtures with Generalized Linear Models: Precise Asymptotics in High-dimensions\",\"Learning curves of generic features maps for realistic datasets with a teacher-student model\",\"Does Knowledge Distillation Really Work?\",\"Ising Model Selection Using $\\\\ell_{1}$-Regularized Linear Regression: A Statistical Mechanics Analysis\",\"Delayed Propagation Transformer: A Universal Computation Engine towards Practical Control in Cyber-Physical Systems\",\"M-FAC: Efficient Matrix-Free Approximations of Second-Order Information\",\"Non-approximate Inference for Collective Graphical Models on Path Graphs via Discrete Difference of Convex Algorithm\",\"Perturb-and-max-product: Sampling and learning in discrete energy-based models\",\"Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds and Benign Overfitting\",\"Scalable Inference in SDEs by Direct Matching of the Fokker\\u2013Planck\\u2013Kolmogorov Equation\",\"Neural Scene Flow Prior\",\"Global-aware Beam Search for Neural Abstractive Summarization\",\"Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates\",\"Scaling up Continuous-Time Markov Chains Helps Resolve Underspecification\",\"On the Sample Complexity of Learning under Geometric Stability\",\"Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization\",\"Exploring Social Posterior Collapse in Variational Autoencoder for Interaction Modeling\",\"Near-optimal Offline and Streaming Algorithms for Learning Non-Linear Dynamical Systems\",\"Comprehensive Knowledge Distillation with Causal Intervention\",\"DOCTOR: A Simple Method for Detecting Misclassification Errors\",\"On the Importance of Gradients for Detecting Distributional Shifts in the Wild\",\"Gradient Inversion with Generative Image Prior\",\"HyperSPNs: Compact and Expressive Probabilistic Circuits\",\"Think Big, Teach Small: Do Language Models Distil Occam\\u2019s Razor?\",\"SOLQ: Segmenting Objects by Learning Queries\",\"R-Drop: Regularized Dropout for Neural Networks\",\"Robustness via Uncertainty-aware Cycle Consistency\",\"Lattice partition recovery with dyadic CART\",\"Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective\",\"Generalized DataWeighting via Class-Level Gradient Manipulation\",\"Learning to Predict Trustworthiness with Steep Slope Loss\",\"Dynamic Sasvi: Strong Safe Screening for Norm-Regularized Least Squares\",\"Minimizing Polarization and Disagreement in Social Networks via Link Recommendation\",\"How Well do Feature Visualizations Support Causal Understanding of CNN Activations?\",\"Detecting Anomalous Event Sequences with Temporal Point Processes\",\"Distributed Zero-Order Optimization under Adversarial Noise\",\"Boosting with Multiple Sources\",\"Deep Extrapolation for Attribute-Enhanced Generation\",\"Meta Two-Sample Testing: Learning Kernels for Testing with Limited Data \",\"Estimating High Order Gradients of the Data Distribution by Denoising\",\"Self-Supervised Learning Disentangled Group Representation as Feature\",\"Debiased Visual Question Answering from Feature and Sample Perspectives\",\"Refined Learning Bounds for Kernel and Approximate $k$-Means\",\"Self-Supervised Learning with Kernel Dependence Maximization\",\"Greedy Approximation Algorithms for Active Sequential Hypothesis Testing\",\"Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease Progression\",\"DP-SSL: Towards Robust Semi-supervised Learning with A Few Labeled Samples\",\"Variational Inference for Continuous-Time Switching Dynamical Systems\",\"Learnability of Linear Thresholds from Label Proportions\",\"List-Decodable Mean Estimation in Nearly-PCA Time\",\"Concentration inequalities under sub-Gaussian and sub-exponential conditions\",\"Visualizing the Emergence of Intermediate Visual Patterns in DNNs\",\"TopicNet: Semantic Graph-Guided Topic Discovery\",\"A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference\",\"Online false discovery rate control for anomaly detection in time series\",\"The Limitations of Large Width in Neural Networks: A Deep Gaussian Process Perspective\",\"Topological Attention for Time Series Forecasting\",\"Precise characterization of the prior predictive distribution of deep ReLU networks\",\"Conformal Time-series Forecasting\",\"COHESIV: Contrastive Object and Hand Embedding Segmentation In Video\",\"Explaining Latent Representations with a Corpus of Examples\",\"Evaluating Gradient Inversion Attacks and Defenses in Federated Learning\",\"Visual Search Asymmetry: Deep Nets and Humans Share Similar Inherent Biases\",\"Learning Fast-Inference Bayesian Networks\",\"Instance-Dependent Partial Label Learning\",\"Sageflow: Robust Federated Learning against Both Stragglers and Adversaries\",\"On Episodes, Prototypical Networks, and Few-Shot Learning\",\"SalKG: Learning From Knowledge Graph Explanations for Commonsense Reasoning\",\"Sparse Uncertainty Representation in Deep Learning with Inducing Weights\",\"Dynamic Inference with Neural Interpreters\",\"What Makes Multi-Modal Learning Better than Single (Provably)\",\"Combining Recurrent, Convolutional, and Continuous-time Models with Linear State Space Layers\",\"Probabilistic Forecasting: A Level-Set Approach\",\"Knowledge-inspired 3D Scene Graph Prediction in Point Cloud\",\"Learning to Learn Dense Gaussian Processes for Few-Shot Learning\",\"Combining Latent Space and Structured Kernels for Bayesian Optimization over Combinatorial Spaces\",\"Efficient hierarchical Bayesian inference for spatio-temporal regression models in neuroimaging\",\"Fast Certified Robust Training with Short Warmup\",\"Best of Both Worlds: Practical and Theoretically Optimal Submodular Maximization in Parallel\",\"Residual Relaxation for Multi-view Representation Learning\",\"Re-ranking for image retrieval and transductive few-shot classification\",\"A No-go Theorem for Robust Acceleration in the Hyperbolic Plane\",\"A Bayesian-Symbolic Approach to Reasoning and Learning in Intuitive Physics\",\"A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning\",\"CAFE: Catastrophic Data Leakage in Vertical Federated Learning\",\"Active Assessment of Prediction Services as Accuracy Surface Over Attribute Combinations\",\"DOBF: A Deobfuscation Pre-Training Objective for Programming Languages\",\"Unbalanced Optimal Transport through Non-negative Penalized Linear Regression\",\"Going Beyond Linear Transformers with Recurrent Fast Weight Programmers\",\"Learning to Assimilate in Chaotic Dynamical Systems\",\"Generalizable Multi-linear Attention Network\",\"FINE Samples for Learning with Noisy Labels\",\"Spectrum-to-Kernel Translation for Accurate Blind Image Super-Resolution\",\"Generalization Error Rates in Kernel Regression: The Crossover from the Noiseless to Noisy Regime\",\"Variational Multi-Task Learning with Gumbel-Softmax Priors\",\"On Interaction Between Augmentations and Corruptions in Natural Corruption Robustness\",\"Statistical Query Lower Bounds for List-Decodable Linear Regression\",\"Pooling by Sliced-Wasserstein Embedding\",\"Newton-LESS: Sparsification without Trade-offs for the Sketched Newton Update\",\"Cockpit: A Practical Debugging Tool for the Training of Deep Neural Networks\",\"Algorithmic stability and generalization of an unsupervised feature selection algorithm\",\"Kernel Functional Optimisation\",\"Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems\",\"A$^2$-Net: Learning Attribute-Aware Hash Codes for Large-Scale Fine-Grained Image Retrieval\",\"DiBS: Differentiable Bayesian Structure Learning\",\"On the Representation of Solutions to Elliptic PDEs in Barron Spaces\",\"Set Prediction in the Latent Space\",\"Rectifying the Shortcut Learning of Background for Few-Shot Learning\",\"LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes\",\"Dynamic Visual Reasoning by Learning Differentiable Physics Models from Video and Language\",\"An Improved Analysis of Gradient Tracking for Decentralized Machine Learning\",\"Grammar-Based Grounded Lexicon Learning\",\"VigDet: Knowledge Informed Neural Temporal Point Process for Coordination Detection on Social Media\",\"Lower Bounds on Metropolized Sampling Methods for Well-Conditioned Distributions\",\"Contrastively Disentangled Sequential  Variational Autoencoder\",\"Learning to Compose Visual Relations\",\"SWAD: Domain Generalization by Seeking Flat Minima\",\"Editing a classifier by rewriting its prediction rules\",\"$\\\\alpha$-IoU: A Family of Power Intersection over Union Losses for Bounding Box Regression\",\"Approximate optimization of convex functions with outlier noise\",\"Probabilistic Entity Representation Model for Reasoning over Knowledge Graphs\",\"Scalars are universal: Equivariant machine learning, structured like classical physics\",\"Similarity and Matching of Neural Network Representations\",\"Partial success in closing the gap between human and machine vision\",\"Qimera: Data-free Quantization with Synthetic Boundary Supporting Samples\",\"Analyzing the Confidentiality of Undistillable Teachers in Knowledge Distillation\",\"Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations\",\"Universal Semi-Supervised Learning\",\"Shared Independent Component Analysis for Multi-Subject Neuroimaging\",\"Integrating Tree Path in Transformer for Code Representation\",\"Lower Bounds and Optimal Algorithms for Smooth and Strongly Convex Decentralized Optimization Over Time-Varying Networks\",\"Support Recovery of Sparse Signals from a Mixture of Linear Measurements\",\"Auditing Black-Box Prediction Models for Data Minimization Compliance\",\"Approximate Decomposable Submodular Function Minimization for Cardinality-Based Components\",\"Improved Learning Rates of a Functional Lasso-type SVM with Sparse Multi-Kernel Representation\",\"Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation\",\"Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence\",\"Particle Dual Averaging: Optimization of Mean Field Neural Network with Global Convergence Rate Analysis\",\"Margin-Independent Online Multiclass Learning via Convex Geometry\",\"Efficient Bayesian network structure learning via local Markov boundary search\",\"A nonparametric method for gradual change problems with statistical guarantees\",\"ReAct: Out-of-distribution Detection With Rectified Activations\",\"End-to-End Weak Supervision\",\"An Axiomatic Theory of Provably-Fair Welfare-Centric Machine Learning\",\"Overinterpretation reveals image classification model pathologies\",\"On Calibration and Out-of-Domain Generalization\",\"HNPE: Leveraging Global Parameters for Neural Posterior Estimation\",\"Learning Semantic Representations to Verify Hardware Designs\",\"BAST: Bayesian Additive Regression Spanning Trees for Complex Constrained Domain\",\"Integrated Latent Heterogeneity and Invariance Learning in Kernel Space\",\"Chasing Sparsity in Vision Transformers: An End-to-End Exploration\",\"Learning Frequency Domain Approximation for Binary Neural Networks\",\"Convolutional Normalization: Improving Deep Convolutional Network Robustness and Training\",\"Analyzing the Generalization Capability of SGLD Using Properties of Gaussian Channels\",\"Associating Objects with Transformers for Video Object Segmentation\",\"Error Compensated Distributed SGD Can Be Accelerated\",\"Uncertainty-Driven Loss for Single Image Super-Resolution\",\"Unbiased Classification through Bias-Contrastive and Bias-Balanced Learning\",\"Taxonomizing local versus global structure in neural network loss landscapes\",\"Fast Tucker Rank Reduction for Non-Negative Tensors Using Mean-Field Approximation\",\"Multi-Label Learning with Pairwise Relevance Ordering\",\"Towards Optimal Strategies for Training Self-Driving Perception Models in Simulation\",\"Representer Point Selection via Local Jacobian Expansion for Post-hoc Classifier Explanation of Deep Neural Networks and Ensemble Models\",\"Complexity Lower Bounds for Nonconvex-Strongly-Concave Min-Max Optimization\",\"Understanding Deflation Process in Over-parametrized Tensor Decomposition\",\"Rot-Pro: Modeling Transitivity by Projection in Knowledge Graph Embedding\",\"HSVA: Hierarchical Semantic-Visual Adaptation for Zero-Shot Learning\",\"Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems\",\"Lossy Compression for Lossless Prediction\",\"On the Validity of Modeling SGD with Stochastic Differential Equations (SDEs)\",\"You Never Cluster Alone\",\"Local Signal Adaptivity: Provable Feature Learning in Neural Networks Beyond Kernels\",\"Deeply Shared Filter Bases for  Parameter-Efficient  Convolutional Neural Networks\",\"Locally Most Powerful Bayesian Test for Out-of-Distribution Detection using Deep Generative Models\",\"Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting\",\"Hyperbolic Busemann Learning with Ideal Prototypes\",\"Scalable Diverse Model Selection for Accessible Transfer Learning\",\"RIM: Reliable Influence-based Active Learning on Graphs\",\"Differentially Private Stochastic Optimization: New Results in Convex and Non-Convex Settings\",\"Learning Debiased and Disentangled Representations for Semantic Segmentation\",\"Differentiable Optimization of Generalized Nondecomposable Functions using Linear Programs\",\"Understanding the Under-Coverage Bias in Uncertainty Estimation\",\"Escaping Saddle Points with Compressed SGD\",\"Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval\",\"Conformal Bayesian Computation\",\"Counterfactual Explanations Can Be Manipulated\",\"Laplace Redux - Effortless Bayesian Deep Learning\",\"Escape saddle points by a simple gradient-descent based algorithm\",\"Object-Centric Representation Learning with Generative Spatial-Temporal Factorization\",\"Multi-View Representation Learning via Total Correlation Objective\",\"Explanation-based Data Augmentation for Image Classification\",\"Robust and Decomposable Average Precision for Image Retrieval\",\"Truncated Marginal Neural Ratio Estimation\",\"Improving Contrastive Learning on Imbalanced Data via Open-World Sampling\",\"Attention Bottlenecks for Multimodal Fusion\",\"Efficient Generalization with Distributionally Robust Learning\",\"SADGA: Structure-Aware Dual Graph Aggregation Network for Text-to-SQL\",\"ParK: Sound and Efficient Kernel Ridge Regression by Feature Space Partitions\",\"Private Non-smooth ERM and SCO in Subquadratic Steps\",\"Learning Debiased Representation via Disentangled Feature Augmentation\",\"SSMF: Shifting Seasonal Matrix Factorization\",\"Understanding the Generalization Benefit of Model Invariance from a Data Perspective\",\"Structure learning in polynomial time: Greedy algorithms, Bregman information, and exponential families\",\"One Loss for All: Deep Hashing with a Single Cosine Similarity based Learning Objective\",\"Rethinking Neural Operations for Diverse Tasks\",\"Learning Stochastic Majority Votes by Minimizing a PAC-Bayes Generalization Bound\",\"Differentiable Learning Under Triage\",\"Overcoming the Convex Barrier for Simplex Inputs\",\"SGD: The Role of Implicit Regularization, Batch-size and Multiple-epochs\",\"SBO-RNN: Reformulating Recurrent Neural Networks via Stochastic Bilevel Optimization\",\"Sliced Mutual Information: A Scalable Measure of Statistical Dependence\",\"Pragmatic Image Compression for Human-in-the-Loop Decision-Making\",\"Tensor Normal Training for Deep Learning Models\",\"Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection\",\"SIMONe: View-Invariant, Temporally-Abstracted Object Representations via Unsupervised Video Decomposition\",\"Linear and Kernel Classification in the Streaming Model: Improved Bounds for Heavy Hitters\",\"Characterizing the risk of fairwashing\",\"Grad2Task: Improved Few-shot Text Classification Using Gradients for Task Representation\",\"Smooth Bilevel Programming for Sparse Regularization\",\"Simple steps are all you need: Frank-Wolfe and generalized self-concordant functions\",\"CBP: backpropagation with constraint on weight precision using a pseudo-Lagrange multiplier method\",\"Combating Noise: Semi-supervised Learning by Region Uncertainty Quantification\",\"Locally Valid and Discriminative Prediction Intervals for Deep Learning Models\",\"Joint Modeling of Visual Objects and Relations for Scene Graph Generation\",\"Learning Generative Vision Transformer with Energy-Based Latent Space for Saliency Prediction\",\"On the Convergence of Prior-Guided Zeroth-Order Optimization Algorithms\",\"Collaborative Uncertainty in Multi-Agent Trajectory Forecasting\",\"The Complexity of Bayesian Network Learning: Revisiting the Superstructure\",\"Constrained Robust Submodular Partitioning\",\"STEP: Out-of-Distribution Detection in the Presence of Limited In-Distribution Labeled Data\",\"Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms\",\"Progressive Feature Interaction Search for Deep Sparse Network\",\"Neural Hybrid Automata: Learning Dynamics With Multiple Modes and Stochastic Transitions\",\"Overlapping Spaces for Compact Graph Representations\",\"An Empirical Investigation of Domain Generalization with Empirical Risk Minimizers\",\"The Role of Global Labels in Few-Shot Classification and How to Infer Them\",\"Large-Scale Wasserstein Gradient Flows\",\"Language models enable zero-shot prediction of the effects of mutations on protein function\",\"Dimensionality Reduction for Wasserstein Barycenter\",\"Testing Probabilistic Circuits\",\"ErrorCompensatedX: error compensation for variance reduced algorithms\",\"Online Learning and Control of Complex Dynamical Systems from Sensory Input\",\"Open-set Label Noise Can Improve Robustness Against Inherent Label Noise\",\" Learning Hard Optimization Problems: A Data Generation Perspective\",\"Label Disentanglement in Partition-based Extreme Multilabel Classification\",\"SketchGen: Generating Constrained CAD Sketches\",\"Even your Teacher Needs Guidance: Ground-Truth Targets Dampen Regularization Imposed by Self-Distillation\",\"Fast and accurate randomized algorithms for low-rank tensor decompositions\",\"Efficient Training of Retrieval Models using Negative Cache\",\"A Geometric Perspective towards Neural Calibration via Sensitivity Decomposition\",\"Dataset Distillation with Infinitely Wide Convolutional Networks\",\"Aligned Structured Sparsity Learning for Efficient Image Super-Resolution\",\"SLOE: A Faster Method for Statistical Inference in High-Dimensional Logistic Regression\",\"An Empirical Study of Adder Neural Networks for Object Detection\",\"Modality-Agnostic Topology Aware Localization\",\"Fast Projection onto the Capped Simplex with Applications to Sparse Regression in Bioinformatics\",\"Unifying Width-Reduced Methods for Quasi-Self-Concordant Optimization\",\"Robustifying Algorithms of Learning Latent Trees with Vector Variables\",\"Roto-translated Local Coordinate Frames For Interacting Dynamical Systems\",\"Sample Complexity of Tree Search Configuration: Cutting Planes and Beyond\",\"Neural Dubber: Dubbing for Videos According to Scripts\",\"Data Sharing and Compression for Cooperative Networked Control\",\"What\\u2019s a good imputation to predict with missing values?\",\"Disentangling Identifiable Features from Noisy Data with Structured Nonlinear ICA\",\"Uniform Sampling over Episode Difficulty\",\"Spatial-Temporal Super-Resolution of Satellite Imagery via Conditional Pixel Synthesis\",\"Understanding Partial Multi-Label Learning via Mutual Information\",\"Introspective Distillation for Robust Question Answering\",\"Structured in Space, Randomized in Time: Leveraging Dropout in RNNs for Efficient Training\",\"Supercharging Imbalanced Data Learning With Energy-based Contrastive Representation Transfer\",\"Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data\",\"Trash or Treasure? An Interactive Dual-Stream Strategy for Single Image Reflection Separation\",\"MobTCast: Leveraging Auxiliary Trajectory Forecasting for Human Mobility Prediction\",\"SyMetric: Measuring the Quality of Learnt Hamiltonian Dynamics Inferred from Vision\",\"CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation\",\"Relative Uncertainty Learning for Facial Expression Recognition\",\"BatchQuant: Quantized-for-all Architecture Search with Robust Quantizer\",\"Make Sure You're Unsure: A Framework for Verifying Probabilistic Specifications\",\"Efficient constrained sampling via the mirror-Langevin algorithm\",\"Topic Modeling Revisited: A Document Graph-based Neural Network Perspective\",\"No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data\",\"RETRIEVE: Coreset Selection for Efficient and Robust Semi-Supervised Learning\",\"Understanding Interlocking Dynamics of Cooperative Rationalization\",\"Learning and Generalization in RNNs\",\"Probabilistic Attention for Interactive Segmentation\",\"Interpolation can hurt robust generalization even when there is no noise\",\"Explaining Hyperparameter Optimization via Partial Dependence Plots\",\"Understanding and Improving Early Stopping for Learning with Noisy Labels\",\"Optimality and Stability in Federated Learning: A Game-theoretic Approach\",\"Searching Parameterized AP Loss for Object Detection\",\"Structured Dropout Variational Inference for Bayesian Neural Networks\",\"Pointwise Bounds for Distribution Estimation under Communication Constraints\",\"Fair Sparse Regression with Clustering: An Invex Relaxation for a Combinatorial Problem\",\"Improving Self-supervised Learning with Automated Unsupervised Outlier Arbitration\",\"Can Less be More? When Increasing-to-Balancing Label Noise Rates Considered Beneficial\",\"S$^3$: Sign-Sparse-Shift Reparametrization for Effective Training of Low-bit Shift Networks\",\"Improving Deep Learning Interpretability by Saliency Guided Training\",\"Non-asymptotic Error Bounds for Bidirectional GANs\",\"Spatial Ensemble: a Novel Model Smoothing Mechanism for Student-Teacher Framework\",\"Learning Signal-Agnostic Manifolds of Neural Fields\",\"Overcoming the curse of dimensionality with Laplacian regularization in semi-supervised learning\",\"Learning Causal Semantic Representation for Out-of-Distribution Prediction\",\"Hyperparameter Optimization Is Deceiving Us, and How to Stop It\",\"A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models\",\"Designing Counterfactual Generators using Deep Model Inversion\",\"Neural Symplectic Form: Learning Hamiltonian Equations on General Coordinate Systems\",\"Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation\",\"A Faster Decentralized Algorithm for Nonconvex Minimax Problems\",\"Model-Based Domain Generalization\",\"Compressive Visual Representations\",\"Revealing and Protecting Labels in Distributed Training\",\"Conformal Prediction using Conditional Histograms\",\"Smoothness Matrices Beat Smoothness Constants: Better  Communication Compression Techniques for Distributed Optimization\",\"NORESQA: A Framework for Speech Quality Assessment using Non-Matching References\",\"FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling\",\"Scaling Vision with Sparse Mixture of Experts\",\"Turing Completeness of Bounded-Precision Recurrent Neural Networks\",\"Credal Self-Supervised Learning\",\"Recurrent Bayesian Classifier Chains for Exact Multi-Label Classification\",\"OpenMatch: Open-Set Semi-supervised Learning with Open-set Consistency Regularization\",\"Do Input Gradients Highlight Discriminative Features? \",\"A Probabilistic State Space Model for Joint Inference from Differential Equations and Data\",\"Reverse-Complement Equivariant Networks for DNA Sequences\",\"On the Out-of-distribution Generalization of Probabilistic Image Modelling\",\"Zero Time Waste: Recycling Predictions in Early Exit Neural Networks\",\"Interactive Label Cleaning with Example-based Explanations\",\"Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces\",\"Distributed Saddle-Point Problems Under Data Similarity\",\"Distribution-free inference for regression: discrete, continuous, and in between\",\"FLEX: Unifying Evaluation for Few-Shot NLP\",\"Localization with Sampling-Argmax\",\"Automatic Symmetry Discovery with Lie Algebra Convolutional Network\",\"Robust Regression Revisited: Acceleration and Improved Estimation Rates\",\"Learning with Holographic Reduced Representations\",\"Asynchronous Stochastic Optimization Robust to Arbitrary Delays\",\"Disentangling the Roles of Curation, Data-Augmentation and the Prior in the Cold Posterior Effect\",\"Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees\",\"Contextual Similarity Aggregation with Self-attention for Visual Re-ranking\",\"Generalization Guarantee of SGD for Pairwise Learning\",\"When Is Unsupervised Disentanglement Possible?\",\"Discrete-Valued Neural Communication\",\"Towards Tight Communication Lower Bounds for Distributed Optimisation\",\"Learning Student-Friendly Teacher Networks for Knowledge Distillation\",\"TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification\",\"Speech Separation Using an Asynchronous Fully Recurrent Convolutional Neural Network\",\"SSAL: Synergizing between Self-Training and Adversarial Learning for Domain Adaptive Object Detection\",\"Mini-Batch Consistent Slot Set Encoder for Scalable Set Encoding\",\"Reusing Combinatorial Structure: Faster Iterative Projections over Submodular Base Polytopes\",\"Teaching via Best-Case Counterexamples in the Learning-with-Equivalence-Queries Paradigm\",\"Physics-Aware Downsampling with Deep Learning for Scalable Flood Modeling\",\"Discovering Dynamic Salient Regions for Spatio-Temporal Graph Neural Networks\",\"Training Certifiably Robust Neural Networks with Efficient Local Lipschitz Bounds\",\"Out-of-Distribution Generalization in Kernel Regression\",\"Landscape analysis of an improved power method for tensor decomposition\",\"Pay Attention to MLPs\",\"Convex Polytope Trees\",\"EF21: A New, Simpler, Theoretically Better, and Practically Faster Error Feedback\",\"Change Point Detection via Multivariate Singular Spectrum Analysis\",\"Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics\",\"MarioNette: Self-Supervised Sprite Learning\",\" NeuroMLR: Robust & Reliable Route Recommendation on Road Networks \",\"Reformulating Zero-shot Action Recognition for Multi-label Actions\",\"Matrix encoding networks for neural combinatorial optimization\",\"Asymptotics of the Bootstrap via Stability with Applications to Inference with Model Selection\",\"Combining Human Predictions with Model Probabilities via Confusion Matrices and Calibration\",\"Heavy Tails in SGD and Compressibility of Overparametrized Neural Networks\",\"Self-Instantiated Recurrent Units with Dynamic Soft Recursion\",\"Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data\",\"Invertible DenseNets with Concatenated LipSwish\",\"A self consistent theory of Gaussian Processes captures feature learning effects in finite CNNs\",\"Dangers of Bayesian Model Averaging under Covariate Shift\",\"Learning interaction rules from multi-animal trajectories via augmented behavioral models\",\"Stability and Deviation Optimal Risk Bounds with Convergence Rate $O(1/n)$\",\"Revisiting Model Stitching to Compare Neural Representations\",\"The Inductive Bias of Quantum Kernels\",\"Probability Paths and the Structure of Predictions over Time\",\"A Kernel-based Test of Independence for Cluster-correlated Data\",\"Closing the loop in medical decision support by understanding clinical decision-making: A case study on organ transplantation\",\"Gaussian Kernel Mixture Network for Single Image Defocus Deblurring\",\"Joint Inference for Neural Network Depth and Dropout Regularization\",\"Exploring the Limits of Out-of-Distribution Detection\",\"Instance-dependent Label-noise Learning under a Structural Causal Model\",\"Approximating the Permanent with Deep Rejection Sampling\",\"Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss\",\"Meta-Learning Sparse Implicit Neural Representations\",\"Well-tuned Simple Nets Excel on Tabular Datasets\",\"On UMAP's True Loss Function\",\"Unsupervised Learning of Compositional Energy Concepts\",\"Fast Approximation of the Sliced-Wasserstein Distance Using Concentration of Random Projections\",\"Grounding inductive biases in natural images: invariance stems from variations in data\",\"Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking\",\"Federated-EM with heterogeneity mitigation and variance reduction\",\"Federated Split Task-Agnostic  Vision Transformer for COVID-19 CXR Diagnosis\",\"True Few-Shot Learning with Language Models\",\"Sampling  with Trusthworthy Constraints:  A Variational Gradient Framework   \",\"An Image is Worth More Than a Thousand Words: Towards Disentanglement in The Wild\",\"ABC: Auxiliary Balanced Classifier for Class-imbalanced Semi-supervised Learning\",\"Mirror Langevin Monte Carlo: the Case Under Isoperimetry\",\"Scalable Quasi-Bayesian Inference for Instrumental Variable Regression\",\"An Infinite-Feature Extension for Bayesian ReLU Nets That Fixes Their Asymptotic Overconfidence\",\"Human-Adversarial Visual Question Answering\",\"Towards Robust and Reliable Algorithmic Recourse\",\"Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty Quantification\",\"Why Do Better Loss Functions Lead to Less Transferable Features?\",\"A Theoretical Analysis of Fine-tuning with Linear Teachers\",\"Coresets for Classification \\u2013 Simplified and Strengthened\",\"Sparse Deep Learning: A New Framework Immune to Local Traps and Miscalibration\",\"MIRACLE: Causally-Aware Imputation via Learning Missing Data Mechanisms\",\"MixSeq: Connecting Macroscopic Time Series Forecasting with Microscopic Time Series Data\",\"Deep Learning on a Data Diet: Finding Important Examples Early in Training\",\"A Highly-Efficient Group Elastic Net Algorithm with an Application to Function-On-Scalar Regression\",\"Periodic Activation Functions Induce Stationarity\",\"Fast Axiomatic Attribution for Neural Networks\",\"AugMax: Adversarial Composition of Random Augmentations for Robust Training\",\"Joint inference and input optimization in equilibrium networks\",\"The Effect of the Intrinsic Dimension on the Generalization of Quadratic Classifiers\",\"Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth Games: Convergence Analysis under Expected Co-coercivity\",\"Simple Stochastic and Online Gradient Descent Algorithms for Pairwise Learning\",\"Towards Context-Agnostic Learning Using Synthetic Data\",\"Reverse engineering recurrent neural networks with Jacobian switching linear dynamical systems\",\"Ultrahyperbolic Neural Networks\",\"Hash Layers For Large Sparse Models\",\"Nonparametric estimation of continuous DPPs with kernel methods\",\"ImageBART: Bidirectional Context with Multinomial Diffusion for Autoregressive Image Synthesis\",\"Do Different Tracking Tasks Require Different Appearance Models?\",\"On the Stochastic Stability of Deep Markov Models\",\"A Computationally Efficient Method for Learning Exponential Family Distributions\",\"Demystifying and Generalizing BinaryConnect\",\"Differentiable Unsupervised Feature Selection based on a Gated Laplacian\",\"Improving Conditional Coverage via Orthogonal Quantile Regression\",\"Look at the Variance! Efficient Black-box Explanations with Sobol-based Sensitivity Analysis\",\"SQALER: Scaling Question Answering by Decoupling Multi-Hop and Logical Reasoning\",\"Self-Supervised Multi-Object Tracking with Cross-input Consistency\",\"Reliable Estimation of KL Divergence using a Discriminator in Reproducing Kernel Hilbert Space\",\"Partition-Based Formulations for Mixed-Integer Optimization of Trained ReLU Neural Networks\",\"De-randomizing MCMC dynamics with the diffusion Stein operator\",\"Optimal Rates for Random Order Online Optimization\",\"Grounding Representation Similarity Through Statistical Testing\",\"Revisiting Deep Learning Models for Tabular Data\",\"Large-Scale Learning with Fourier Features and Tensor Decompositions\",\"Improved Regularization and Robustness for Fine-tuning in Neural Networks\",\"When in Doubt: Neural Non-Parametric Uncertainty Quantification for Epidemic Forecasting\",\"From Canonical Correlation Analysis to Self-supervised Graph Neural Networks\",\"Support vector machines and linear regression coincide with very high-dimensional features\",\"Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning\",\"General Nonlinearities in SO(2)-Equivariant CNNs\",\"Learning Riemannian metric for disease progression modeling\",\"Probabilistic Transformer For Time Series Analysis\",\"Lower and Upper Bounds on the Pseudo-Dimension of Tensor Network Models\",\"An Exact Characterization of the Generalization Error for the Gibbs Algorithm\",\"Can multi-label classification networks know what they don\\u2019t know?\",\"On Joint Learning for Solving Placement and Routing in Chip Design\",\"T-LoHo: A Bayesian Regularization Model for Structured Sparsity and Smoothness on Graphs\",\"Towards Stable and Robust AdderNets\",\"PTR: A Benchmark for Part-based Conceptual, Relational, and Physical Reasoning\",\"Machine learning structure preserving brackets for forecasting irreversible processes\",\"Efficient Truncated Linear Regression with Unknown Noise Variance\",\"Kernel Identification Through Transformers\",\"A Continuous Mapping For Augmentation Design\",\"Scalable Neural Data Server: A Data Recommender for Transfer Learning\",\"A Multi-Implicit Neural Representation for Fonts\",\"Systematic Generalization with Edge Transformers\",\"LEADS: Learning Dynamical Systems that Generalize Across Environments\",\"Hamiltonian Dynamics with Non-Newtonian Momentum for Rapid Sampling\",\"Profiling Pareto Front With Multi-Objective Stein Variational  Gradient Descent\",\"Passive attention in artificial neural networks predicts human visual selectivity\",\"NEO: Non Equilibrium Sampling on the Orbits of a Deterministic Transform\",\"Beyond the Signs: Nonparametric Tensor Completion via Sign Series\",\"The future is log-Gaussian: ResNets and their infinite-depth-and-width limit at initialization\",\"GRIN: Generative Relation and Intention Network for Multi-agent Trajectory Prediction\",\"Encoding Robustness to Image Style via Adversarial Feature Perturbations\",\"Understanding How Encoder-Decoder Architectures Attend\",\"Realistic evaluation of transductive few-shot learning\",\"Tree in Tree: from Decision Trees to Decision Graphs\",\"Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning\",\"ResNEsts and DenseNEsts: Block-based DNN Models with Improved Representation Guarantees\",\"An online passive-aggressive algorithm for difference-of-squares classification\",\"When does Contrastive Learning Preserve Adversarial Robustness from Pretraining to Finetuning?\",\"Determinantal point processes based on orthogonal polynomials for sampling minibatches in SGD\",\"ConE: Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs\",\"On the interplay between data structure and loss function in classification problems\",\"Task-Agnostic Undesirable Feature Deactivation Using Out-of-Distribution Data\",\"Stochastic Anderson Mixing for Nonconvex Stochastic Optimization\",\"Locality defeats the curse of dimensionality in convolutional teacher-student scenarios\",\"Risk Bounds for Over-parameterized Maximum Margin Classification on Sub-Gaussian Mixtures\",\"Novel Upper Bounds for the Constrained Most Probable Explanation Task\",\"Handling Long-tailed Feature Distribution in AdderNets\",\"Latent Matters: Learning Deep State-Space Models\",\"Coupled Gradient Estimators for Discrete Latent Variables\",\"Influence Patterns for Explaining Information Flow in BERT\",\"Faster Algorithms and Constant Lower Bounds for the Worst-Case Expected Error\",\"Asymptotics of representation learning in finite Bayesian neural networks\",\"Provably Strict Generalisation Benefit for Invariance in Kernel Methods\",\"Leveraging Recursive Gumbel-Max Trick for Approximate Inference in Combinatorial Spaces\",\"Weak-shot Fine-grained Classification via Similarity Transfer\",\"How Does it Sound?\",\"Exact marginal prior distributions of finite Bayesian neural networks\",\"Adaptive wavelet distillation from neural networks through interpretations\",\"Scalable Bayesian GPFA with automatic relevance determination and discrete noise models\",\"Adaptive Conformal Inference Under Distribution Shift\",\"Generalization Bounds for Graph Embedding Using Negative Sampling: Linear vs Hyperbolic\",\"VoiceMixer: Adversarial Voice Style Mixup\",\"One Explanation is Not Enough: Structured Attention Graphs for Image Classification\",\"Are Transformers more robust than CNNs? \",\"Neural Production Systems\",\"Generalized Shape Metrics on Neural Representations\",\"Repulsive Deep Ensembles are Bayesian\",\"Learning to Generate Visual Questions with Noisy Supervision\",\"Neural Tangent Kernel Maximum Mean Discrepancy\",\"Learning Disentangled Behavior Embeddings\",\"Universal Rate-Distortion-Perception Representations for Lossy Compression\",\"Parameter Prediction for Unseen Deep Architectures\",\"Learning Stable Deep Dynamics Models for Partially Observed or Delayed Dynamical Systems\",\"Relative Flatness and Generalization\",\"Computer-Aided Design as Language\",\"Breaking the Linear Iteration Cost Barrier for Some Well-known Conditional Gradient Methods Using MaxIP Data-structures\",\"Benign Overfitting in Multiclass Classification: All Roads Lead to Interpolation\",\"Scaling Neural Tangent Kernels via Sketching and Random Features\",null],\"marker\":{\"color\":\"#CFD8DC\",\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"other\",\"showlegend\":false,\"x\":[1.1311689615249634,5.109217166900635,2.739851236343384,7.807290077209473,9.058367729187012,5.347772598266602,5.843851566314697,2.676520824432373,4.29402494430542,4.265904426574707,3.939002513885498,3.2645103931427,1.0299521684646606,5.0941972732543945,5.702193737030029,4.956375598907471,6.002960205078125,5.728016376495361,2.956685781478882,7.022940158843994,7.062082767486572,7.0724945068359375,6.330214977264404,5.772490501403809,6.175528049468994,5.441679954528809,4.609582901000977,1.3429080247879028,7.734919548034668,6.680483341217041,5.953150749206543,4.137401580810547,4.979643821716309,7.421046733856201,2.9576003551483154,4.744693756103516,3.169520854949951,9.105840682983398,5.701910018920898,1.1619125604629517,2.144221067428589,4.2746500968933105,2.591667652130127,6.956888198852539,4.768601894378662,5.096777439117432,4.656540393829346,6.766177654266357,2.267792224884033,2.7286148071289062,7.927644729614258,8.011780738830566,5.352906703948975,0.9533764719963074,5.3849077224731445,3.386977434158325,2.2172515392303467,1.2780276536941528,6.330073356628418,2.260965585708618,7.689724445343018,5.340146541595459,3.4766788482666016,5.08523416519165,5.714929103851318,7.45030403137207,6.940486907958984,2.360121726989746,0.7411795258522034,5.749966621398926,7.94977331161499,4.920543193817139,4.524708271026611,4.954254627227783,5.123256206512451,1.0005927085876465,2.68558406829834,9.089367866516113,2.67510986328125,6.057877063751221,5.260149955749512,8.992563247680664,2.9405105113983154,1.5518206357955933,4.282273292541504,1.3909245729446411,1.6083011627197266,3.81364107131958,5.0172929763793945,1.601827621459961,5.132998943328857,5.711397171020508,4.393105983734131,4.310646057128906,7.58010196685791,1.2724595069885254,2.6803719997406006,6.338608264923096,4.669315814971924,4.038572788238525,9.049917221069336,4.964235782623291,1.0350431203842163,6.824244976043701,1.7846424579620361,4.782721519470215,1.648808240890503,4.829266548156738,2.7543773651123047,6.130644798278809,4.953845500946045,2.8421545028686523,7.42306661605835,1.9218978881835938,7.151935577392578,4.178524494171143,4.624284267425537,5.253386497497559,2.758282423019409,2.5135257244110107,6.250053882598877,4.701894760131836,1.8883978128433228,2.755178451538086,2.581416368484497,1.4703450202941895,8.020421981811523,1.0645512342453003,4.982609272003174,5.642148494720459,3.9866230487823486,1.6382653713226318,4.047746181488037,4.775781631469727,2.8154842853546143,7.64202356338501,1.1240484714508057,3.305710792541504,3.630354166030884,2.7962257862091064,3.7713623046875,2.9631049633026123,1.7509859800338745,3.4787840843200684,4.268575668334961,1.0670890808105469,8.006606101989746,6.997884273529053,8.324889183044434,6.887720108032227,6.021377086639404,1.6772130727767944,2.8521993160247803,6.131423473358154,5.654167652130127,2.2008190155029297,7.9190568923950195,3.1473422050476074,4.955063819885254,5.319822788238525,3.1224074363708496,4.218243598937988,4.351200580596924,1.2276250123977661,6.087690353393555,5.092743396759033,2.641160726547241,4.036321640014648,3.095815420150757,6.322433948516846,1.3121198415756226,8.1209135055542,2.662290573120117,4.300768852233887,4.791525840759277,7.548089504241943,5.410881996154785,2.6148908138275146,4.498777866363525,7.703393936157227,7.552611351013184,1.1334811449050903,2.6535613536834717,6.72554349899292,2.96160626411438,5.154019832611084,4.2553839683532715,3.34122633934021,3.180974245071411,3.1624419689178467,5.121089458465576,1.5425457954406738,4.067088603973389,2.167721748352051,7.9085588455200195,2.4485387802124023,6.675323963165283,5.352982997894287,7.895488739013672,1.1148020029067993,5.318486213684082,4.949313163757324,4.976670265197754,7.6359639167785645,1.6735049486160278,4.35213041305542,2.7484939098358154,2.9252593517303467,5.084453105926514,4.744656562805176,1.5351899862289429,6.765267848968506,1.1260850429534912,6.0315446853637695,7.771018028259277,2.6013338565826416,5.140848636627197,4.1996259689331055,2.185030698776245,2.53206729888916,2.8808650970458984,6.45864725112915,5.059814929962158,4.255870342254639,6.777684211730957,4.466747760772705,5.778861045837402,2.94321346282959,7.031576633453369,4.784635066986084,1.5899909734725952,5.9038920402526855,4.938453674316406,1.0182081460952759,6.76270866394043,7.1940741539001465,4.152530670166016,2.3380613327026367,5.2539262771606445,1.640428900718689,2.8878495693206787,7.9635114669799805,5.031403064727783,2.2693865299224854,7.8650665283203125,3.477922201156616,7.603102207183838,3.4836440086364746,5.384579658508301,1.562576174736023,4.035767555236816,2.9258456230163574,5.768925189971924,0.964426577091217,6.25123405456543,5.756176471710205,8.17868423461914,4.2383222579956055,4.7548508644104,6.917409896850586,5.431967735290527,1.8044105768203735,3.027233362197876,7.536503791809082,1.601844310760498,2.903730869293213,3.188267946243286,2.8813014030456543,5.533234119415283,2.7929725646972656,4.116683006286621,6.437665939331055,7.104506492614746,6.3153533935546875,1.4129197597503662,7.801432132720947,1.81075918674469,7.036504745483398,4.5321197509765625,4.284929275512695,2.912670373916626,2.5976552963256836,5.424785614013672,1.2378973960876465,4.222803592681885,4.891110420227051,2.9579896926879883,3.118884801864624,5.001194000244141,4.252457618713379,4.595133304595947,2.6787991523742676,3.7730250358581543,5.673098087310791,6.050915241241455,0.7610649466514587,8.917421340942383,3.47586989402771,4.060112953186035,4.353786945343018,2.011220932006836,6.230256080627441,5.214906215667725,3.8234314918518066,8.823009490966797,2.8521647453308105,4.959053039550781,7.7773261070251465,6.824269771575928,2.358550548553467,5.065415859222412,3.9847252368927,2.7418580055236816,3.554800271987915,5.599276065826416,4.102766513824463,4.653706073760986,4.9905500411987305,5.534957408905029,4.1651225090026855,2.65511417388916,4.270219326019287,1.0494720935821533,8.17902946472168,4.075811386108398,2.872163772583008,9.05228328704834,5.322495937347412,8.173413276672363,1.7275261878967285,3.47914719581604,2.595215320587158,3.8404107093811035,2.4317612648010254,5.350013732910156,3.4936165809631348,4.299483299255371,5.330390453338623,2.7284393310546875,3.087506055831909,3.7753138542175293,4.869175910949707,6.924380779266357,7.898573398590088,5.335205078125,1.0636565685272217,2.5179309844970703,3.3142571449279785,6.753950595855713,1.4595845937728882,7.821323394775391,4.972754001617432,7.267460823059082,2.3786215782165527,7.043388366699219,4.073669910430908,3.8159265518188477,7.897597789764404,2.9501137733459473,2.306929349899292,1.824960470199585,2.330260753631592,2.0131845474243164,7.055459976196289,5.047435283660889,2.9421029090881348,1.419670820236206,4.290738582611084,5.466446399688721,7.538706302642822,2.045685052871704,6.053645133972168,8.187773704528809,7.946074485778809,5.796541213989258,1.6767611503601074,5.004651069641113,2.7221271991729736,1.9270398616790771,5.3589982986450195,3.2084336280822754,7.945095062255859,3.8219172954559326,2.65621018409729,3.8925039768218994,4.948225021362305,4.987029075622559,4.907021522521973,7.208768367767334,3.63572096824646,5.740262031555176,5.182847499847412,5.564196586608887,4.49989652633667,2.73722243309021,4.933315277099609,3.0587048530578613,4.940858364105225,7.522311210632324,2.0335910320281982,3.669987201690674,3.553642988204956,1.6563793420791626,1.8650047779083252,6.087878704071045,2.763444185256958,1.152052640914917,8.65882396697998,3.1035258769989014,1.1021263599395752,5.8310627937316895,2.610555410385132,3.4791858196258545,6.004878044128418,5.341259956359863,4.917018890380859,1.312780737876892,4.879970073699951,5.282346248626709,3.1803762912750244,4.117953300476074,5.7942962646484375,4.207331657409668,4.607794284820557,5.119980335235596,4.2290425300598145,6.232375621795654,5.043121337890625,4.117620944976807,2.955369710922241,4.119303226470947,5.53794002532959,7.650176525115967,7.5026350021362305,2.5111687183380127,4.740745544433594,1.5676567554473877,2.1199285984039307,5.5094685554504395,3.5206425189971924,0.913123369216919,5.158773899078369,7.512912750244141,3.9863717555999756,4.674594879150391,5.342479705810547,2.777099132537842,1.121698021888733,1.0209342241287231,5.777166843414307,4.225544452667236,5.85006856918335,7.42364501953125,3.733466863632202,3.317434072494507,7.537754535675049,4.514862060546875,5.117133617401123,2.120269536972046,5.968461990356445,2.7365386486053467,3.0891847610473633,4.252189636230469,5.078535079956055,7.547964572906494,6.4696455001831055,5.397542953491211,3.407820463180542,6.247089385986328,2.9641897678375244,1.422303318977356,4.916575908660889,7.087245464324951,5.146923542022705,6.5628662109375,4.048070907592773,3.6764605045318604,1.10508394241333,5.083644866943359,5.385422229766846,5.84596586227417,2.691333055496216,5.589461326599121,7.545302867889404,4.914764404296875,4.981483459472656,2.9499006271362305,1.7582480907440186,2.7941272258758545,4.413736343383789,2.3433942794799805,4.0924763679504395,3.2553443908691406,2.2888600826263428,6.8290324211120605,1.1200826168060303,5.060472011566162,4.106095790863037,6.952960014343262,5.834535121917725,5.950061798095703,7.447625637054443,3.0713725090026855,4.85656213760376,4.846011638641357,1.720426082611084,7.4799485206604,4.921286106109619,5.9798054695129395,5.719414710998535,2.454663038253784,1.8285630941390991,4.942895889282227,3.974175214767456,4.360716819763184,5.268538951873779,1.573732614517212,1.796648621559143,2.558333396911621,2.721801996231079,1.6345106363296509,3.659066915512085,4.4931960105896,1.2465107440948486,5.41703987121582,3.9214494228363037,3.0734217166900635,3.4696390628814697,4.855010986328125,6.4240570068359375,1.8074103593826294,6.775521278381348,5.96073579788208,4.692080020904541,4.433165073394775],\"y\":[3.729188919067383,7.2352070808410645,3.9870009422302246,4.376253128051758,4.022036075592041,3.308274269104004,3.1158885955810547,5.7564239501953125,4.3768792152404785,4.899352073669434,7.390416145324707,6.312162399291992,4.955901622772217,6.409315586090088,6.270045280456543,3.3005552291870117,4.2949347496032715,4.356696605682373,3.1994543075561523,4.408110618591309,8.319429397583008,4.188653945922852,6.402508735656738,6.277730941772461,4.336509704589844,6.044162750244141,5.252098560333252,5.3243794441223145,4.43153715133667,6.671433448791504,4.496160507202148,7.135682582855225,7.815122127532959,4.856201171875,3.193145990371704,3.37988543510437,4.984663486480713,4.018009662628174,6.318941593170166,4.467952728271484,4.855855464935303,5.681685924530029,6.049434661865234,3.6786725521087646,3.565277099609375,3.397643566131592,3.7708799839019775,4.1599578857421875,2.2007546424865723,5.053921699523926,5.955738067626953,4.7307448387146,3.2874081134796143,4.892603397369385,4.6392316818237305,6.579432487487793,3.8738694190979004,4.953484535217285,4.563844680786133,3.7289161682128906,6.111566066741943,6.852729797363281,2.2216479778289795,6.969385147094727,3.2836127281188965,3.7788217067718506,5.230443477630615,4.533105850219727,4.543837547302246,6.283266544342041,5.960081577301025,5.784799098968506,5.512300968170166,5.873790264129639,7.227054595947266,6.080245494842529,4.4208903312683105,4.012613773345947,5.152182102203369,6.442479610443115,3.1630306243896484,4.036550521850586,3.866257429122925,4.852442741394043,4.684487342834473,4.481274604797363,5.673149585723877,6.276449680328369,4.2979607582092285,3.69840669631958,6.63463020324707,6.40291690826416,7.5639214515686035,4.889414310455322,4.499852657318115,5.432483196258545,4.049198150634766,4.978496551513672,6.71541166305542,3.1620519161224365,4.011434078216553,4.046773910522461,4.615530967712402,4.249305248260498,5.487553119659424,7.207679271697998,5.653322219848633,3.224215507507324,6.115375518798828,4.396618843078613,6.56201696395874,5.253716468811035,3.8289270401000977,4.771604061126709,4.281786918640137,4.432348251342773,3.6839282512664795,6.533195972442627,5.120832920074463,5.0517473220825195,6.537050724029541,5.536266326904297,5.06720495223999,3.9801442623138428,5.099615573883057,4.408108711242676,4.598293304443359,5.062918663024902,7.810036659240723,6.254366874694824,7.345289707183838,3.897164821624756,3.1277294158935547,3.6320536136627197,4.948115825653076,4.3677263259887695,3.7832489013671875,5.6983962059021,5.7436652183532715,5.03280782699585,4.771406173706055,3.187720775604248,6.383837699890137,2.2271299362182617,7.3793463706970215,4.388641834259033,4.675992488861084,3.7099504470825195,6.86322546005249,3.7093257904052734,4.446951389312744,3.8594624996185303,4.9395551681518555,5.344006538391113,3.052480459213257,2.3720157146453857,5.912715435028076,4.942607879638672,3.3002538681030273,3.4364116191864014,4.866541862487793,3.2597174644470215,7.604953765869141,4.276193141937256,6.447762966156006,3.9954402446746826,5.318460941314697,4.998056411743164,5.3017473220825195,5.534945487976074,5.816136837005615,4.458691120147705,5.971309661865234,4.26136589050293,4.504604339599609,3.473778486251831,3.1033730506896973,4.474698066711426,4.524410247802734,4.461093425750732,3.4706778526306152,3.631290912628174,3.9687581062316895,3.934551954269409,5.681539058685303,5.693686485290527,6.949945449829102,4.486828804016113,5.272899627685547,5.086225509643555,7.266907691955566,3.378598213195801,3.139343023300171,2.4840967655181885,4.388179779052734,4.534890651702881,4.485197067260742,4.507145404815674,4.567385673522949,3.878159284591675,5.812922954559326,3.2644147872924805,6.046049118041992,4.343194961547852,4.244394779205322,7.045738697052002,4.399531841278076,4.980692386627197,6.18948221206665,3.5484673976898193,5.707854747772217,4.576690196990967,3.8295083045959473,4.3651580810546875,4.371533393859863,4.445826530456543,7.292660713195801,3.3719840049743652,2.3983278274536133,5.105341911315918,4.0708394050598145,5.333564758300781,3.5693180561065674,4.870678424835205,4.601188659667969,5.747973918914795,4.804316997528076,5.712283134460449,4.166905879974365,4.241024971008301,4.405841827392578,3.1187167167663574,2.803014039993286,4.8627400398254395,4.186437606811523,4.569252967834473,4.923592567443848,4.36074686050415,5.823159694671631,3.8966190814971924,6.785267353057861,4.901059627532959,7.755248546600342,2.373544216156006,4.514930248260498,2.2267513275146484,4.75331449508667,4.6277384757995605,6.767467498779297,3.2500712871551514,3.138733148574829,3.9062576293945312,5.802073001861572,4.806249618530273,4.931509494781494,6.285061359405518,4.419487476348877,7.85312557220459,3.13045072555542,5.718653202056885,3.0525853633880615,7.136228084564209,3.2735748291015625,3.517199754714966,5.000078201293945,4.924854755401611,3.9826226234436035,5.75001335144043,4.286675453186035,5.253748893737793,6.487255096435547,3.913433074951172,4.360423564910889,6.417500019073486,3.038189649581909,6.194806098937988,6.469904899597168,8.195500373840332,6.949521064758301,7.210056304931641,3.876284599304199,5.910425662994385,3.0661463737487793,4.932094573974609,5.868854522705078,3.5424485206604004,3.1940629482269287,5.503509044647217,7.811428070068359,6.490337371826172,6.929398059844971,4.401051998138428,4.750441074371338,6.229190826416016,5.778814315795898,4.621330261230469,4.020710468292236,2.2308435440063477,4.592018127441406,5.836786270141602,5.04180908203125,4.3058247566223145,6.120116710662842,4.337861061096191,4.159107685089111,4.932203769683838,6.159716606140137,4.472251892089844,3.6758499145507812,3.7461676597595215,3.3358821868896484,4.990515232086182,4.980503559112549,6.9222259521484375,4.330723762512207,6.550935745239258,3.4646644592285156,3.7021517753601074,5.863140106201172,4.341353416442871,4.347633361816406,6.480666637420654,6.039340972900391,4.538619041442871,3.162116527557373,5.759593963623047,3.9932634830474854,4.47830057144165,4.418996810913086,6.288834095001221,2.2257535457611084,5.2417473793029785,6.211981773376465,3.6363377571105957,3.1107802391052246,2.236521005630493,3.7939565181732178,6.6291913986206055,5.740139007568359,5.114239692687988,4.456312656402588,3.3035073280334473,3.525383710861206,4.529935836791992,4.453389644622803,4.862241744995117,4.63778018951416,5.756349563598633,4.2478790283203125,4.054612159729004,4.627601623535156,6.061915397644043,4.783852577209473,4.815120220184326,4.745754718780518,6.962737083435059,5.405582904815674,4.563389301300049,3.206244707107544,4.5000457763671875,6.432155132293701,4.773739814758301,5.036942005157471,4.322659969329834,2.4540834426879883,5.389815330505371,3.0595929622650146,4.908714771270752,4.519760608673096,3.5343117713928223,5.265908241271973,6.409222602844238,4.411861896514893,5.934706211090088,4.995850086212158,4.179251670837402,7.802090644836426,3.9925646781921387,2.514058828353882,4.285921573638916,4.716848373413086,4.537283420562744,6.166968822479248,4.0185465812683105,5.167587757110596,5.807359218597412,6.1111063957214355,7.859978675842285,5.070127010345459,5.749979019165039,4.996709823608398,7.12950325012207,4.7142863273620605,3.7941911220550537,6.117545127868652,5.954143047332764,5.06866979598999,3.340094804763794,4.316779136657715,3.5071170330047607,5.082732677459717,4.631824970245361,3.2164669036865234,4.293877601623535,5.120723724365234,5.477719306945801,5.008129119873047,4.169458866119385,5.298872470855713,4.791661739349365,5.956246376037598,4.423859596252441,2.2267799377441406,5.827541351318359,5.932338714599609,5.84505033493042,4.94888973236084,3.4815492630004883,4.472893238067627,5.239349365234375,3.4136435985565186,3.193195343017578,4.724329471588135,6.927267074584961,7.143491744995117,4.435941696166992,4.009313583374023,6.106808662414551,4.333670139312744,5.269482612609863,4.966242790222168,4.91273307800293,4.8775224685668945,4.891666412353516,4.486611843109131,7.186735153198242,3.324399948120117,5.250877380371094,6.218151092529297,6.820305824279785,6.242973804473877,6.405601978302002,3.8815953731536865,4.871387004852295,3.604109048843384,4.489659309387207,4.894725322723389,3.8757221698760986,6.055866241455078,4.996274948120117,4.951164722442627,5.8660383224487305,5.036304473876953,5.764712810516357,4.656102657318115,3.472644090652466,3.134523868560791,7.218967914581299,3.5898349285125732,4.388753890991211,4.385786056518555,5.702870845794678,6.413167953491211,7.191713809967041,3.4669575691223145,5.3299150466918945,3.108046293258667,4.701922416687012,6.532336235046387,5.3104987144470215,4.414980411529541,6.798125743865967,3.762842893600464,6.439894676208496,4.672488212585449,3.1659255027770996,5.145938396453857,4.326054573059082,6.892239093780518,6.458654403686523,5.847271919250488,5.05256462097168,6.299360752105713,3.4760751724243164,5.788693904876709,7.816470623016357,5.258975982666016,5.436915397644043,3.9388020038604736,3.684528350830078,3.7638132572174072,5.2248311042785645,5.522813320159912,4.067306995391846,4.9601287841796875,3.7925355434417725,4.447248935699463,4.34546422958374,4.704826354980469,4.433567047119141,4.223352432250977,5.772514343261719,5.253899574279785,7.176025867462158,6.641825199127197,5.201646327972412,3.842179536819458,5.8640851974487305,4.432199001312256,6.302592754364014,4.1922383308410645,6.7017340660095215,5.867031097412109,4.264949798583984,7.6198015213012695,4.381882190704346,3.1863853931427,6.4743828773498535,4.536795616149902,5.304618835449219,3.8165643215179443,5.816998481750488,4.518337726593018,4.968919277191162,4.661256790161133,7.4078593254089355,5.995631694793701,4.682868957519531,7.336933135986328,4.360093593597412,7.135043621063232,4.338118553161621,4.193370819091797,5.0296807289123535,4.913324356079102],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System\",\"Model-Based Reinforcement Learning via Imagination with Derived Memory\",\"Policy Optimization in Adversarial MDPs: Improved Exploration via Dilated Bonuses\",\"Learning to Synthesize Programs as Interpretable and Generalizable Policies\",\"Minimax Optimal Quantile and Semi-Adversarial Regret via Root-Logarithmic Regularizers\",\"Distributionally Robust Imitation Learning\",\"Best-case lower bounds in online learning\",\"NovelD: A Simple yet Effective Exploration Criterion\",\"Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data\",\"Brick-by-Brick: Combinatorial Construction with Deep Reinforcement Learning\",\"Prior-independent Dynamic Auctions for a Value-maximizing Buyer\",\"On Effective Scheduling of Model-based Reinforcement Learning\",\"The Lazy Online Subgradient Algorithm is Universal on Strongly Convex Domains\",\"Proportional Participatory Budgeting with Additive Utilities\",\"Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games\",\"Faster Non-asymptotic Convergence for Double Q-learning\",\"Sim and Real: Better Together\",\"Continuous Mean-Covariance Bandits\",\"Offline Meta Reinforcement Learning -- Identifiability Challenges and Effective Data Collection Strategies\",\"Offline Constrained Multi-Objective Reinforcement Learning via Pessimistic Dual Value Iteration\",\"Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization\",\"Variational Automatic Curriculum Learning for Sparse-Reward Cooperative Multi-Agent Problems\",\"Risk-Aware Transfer in Reinforcement Learning using Successor Features\",\"Optimal Order Simple Regret for Gaussian Process Bandits\",\"Observation-Free Attacks on Stochastic Bandits\",\"A Unified Approach to Fair Online Learning via Blackwell Approachability\",\"PatchGame: Learning to Signal Mid-level Patches in Referential Games\",\"Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning\",\"The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle\",\"Making the most of your day: online learning for optimal allocation of time\",\"Multi-Objective SPIBB: Seldonian Offline Policy Improvement with Safety Constraints in Finite MDPs\",\"Bandit Learning with Delayed Impact of Actions\",\"No RL, No Simulation: Learning to Navigate without Navigating\",\"Improving Generalization in Meta-RL with Imaginary Tasks from Latent Dynamics Mixture\",\"Learning in two-player zero-sum partially observable Markov games with perfect recall\",\"Federated Linear Contextual Bandits\",\"Global Convergence of Online Optimization for Nonlinear Model Predictive Control\",\"Differentiable Simulation of Soft Multi-body Systems\",\"Online Convex Optimization with Continuous Switching Constraint\",\"Offline RL Without Off-Policy Evaluation\",\"Online and Offline Reinforcement Learning by Planning with a Learned Model\",\"PettingZoo: Gym for Multi-Agent Reinforcement Learning\",\"Improved Guarantees for Offline Stochastic Matching via new Ordered Contention Resolution Schemes\",\"Tuning Mixed Input Hyperparameters on the Fly for Efficient Population Based AutoRL\",\"Width-based Lookaheads with Learnt Base Policies and Heuristics Over the Atari-2600 Benchmark\",\"Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games\",\"Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning\",\"FACMAC: Factored Multi-Agent Centralised Policy Gradients\",\"Regime Switching Bandits\",\"Detecting Individual Decision-Making Style: Exploring Behavioral Stylometry in Chess\",\"Faster Matchings via Learned Duals\",\"Learning One Representation to Optimize All Rewards\",\"Asymptotically Best Causal Effect Identification with Multi-Armed Bandits\",\"Convex-Concave Min-Max Stackelberg Games\",\"Bridging the Imitation Gap by Adaptive Insubordination\",\"Differentially Private Multi-Armed Bandits in the Shuffle Model\",\"Optimal Policies Tend To Seek Power\",\"Towards Understanding Cooperative Multi-Agent Q-Learning with Value Factorization\",\"A Law of Iterated Logarithm for Multi-Agent Reinforcement Learning\",\"ProTo: Program-Guided Transformer for Program-Guided Tasks\",\"Towards Robust Bisimulation Metric Learning\",\"Deep Synoptic Monte-Carlo Planning in Reconnaissance Blind Chess\",\"Safe Policy Optimization with Local Generalized Linear Function Approximations\",\"On the Value of Interaction and Function Approximation in Imitation Learning\",\"Catalytic Role Of Noise And Necessity Of Inductive Biases In The Emergence Of Compositional Communication\",\"Pareto-Optimal Learning-Augmented Algorithms for Online Conversion Problems\",\"Subgaussian and Differentiable Importance Sampling for Off-Policy Evaluation and Learning\",\"Variance-Aware Off-Policy Evaluation with Linear Function Approximation\",\"Beyond Bandit Feedback in Online Multiclass Classification\",\"Bellman-consistent Pessimism for Offline Reinforcement Learning\",\"Mean-based Best Arm Identification in Stochastic Bandits under Reward Contamination\",\"Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free Reinforcement Learning\",\"EDGE: Explaining Deep Reinforcement Learning Policies\",\"Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble\",\"Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs with a Generative Model\",\"Learning Equilibria in Matching Markets from Bandit Feedback\",\"Information Directed Sampling for Sparse Linear Bandits\",\"Generalized Proximal Policy Optimization with Sample Reuse\",\"A Provably Efficient Model-Free Posterior Sampling Method for Episodic Reinforcement Learning\",\"Hierarchical Reinforcement Learning with Timed Subgoals\",\"Offline Reinforcement Learning as One Big Sequence Modeling Problem\",\"Provable Representation Learning for Imitation with Contrastive Fourier Features\",\"Iterative Amortized Policy Optimization\",\"Fast Routing under Uncertainty: Adaptive Learning in Congestion Games via Exponential Weights\",\"Online Sign Identification: Minimization of the Number of Errors in Thresholding Bandits\",\"Deep Bandits Show-Off: Simple and Efficient Exploration with Deep Networks\",\"Metadata-based Multi-Task Bandits with Bayesian Hierarchical Models\",\"Agent Modelling under Partial Observability for Deep Reinforcement Learning\",\"Cross-modal Domain Adaptation for Cost-Efficient Visual Reinforcement Learning\",\"ROI Maximization in Stochastic Online Decision-Making\",\"Fairness in Ranking under Uncertainty\",\"Information Directed Reward Learning for Reinforcement Learning\",\"Decentralized Learning in Online Queuing Systems\",\"Fast Approximate Dynamic Programming for Infinite-Horizon Markov Decision Processes\",\"Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism\",\"Curriculum Offline Imitating Learning\",\"Rebounding Bandits for Modeling Satiation Effects\",\"Identification of the Generalized Condorcet Winner in Multi-dueling Bandits\",\"The Value of Information When Deciding What to Learn\",\"Exploration-Exploitation in Multi-Agent Competition: Convergence with Bounded Rationality\",\"A Regression Approach to Learning-Augmented Online Algorithms\",\"Believe What You See: Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning\",\"Exploiting Opponents Under Utility Constraints in Sequential Games\",\"The Pareto Frontier of model selection for general Contextual Bandits\",\"Adaptable Agent Populations via a Generative Model of Policies\",\"Reinforcement Learning in Newcomblike Environments\",\"Identifiability in inverse reinforcement learning\",\"Learning to Execute: Efficient Learning of Universal Plan-Conditioned Policies in Robotics\",\"Robust Allocations with Diversity Constraints\",\"Proper Value Equivalence\",\"Improved Regret Bounds for Tracking Experts with Memory\",\"ELLA: Exploration through Learned Language Abstraction\",\"Learning Tree Interpretation from Object Representation for Deep Reinforcement Learning\",\"Fair Exploration via Axiomatic Bargaining\",\"Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality\",\"Dueling Bandits with Adversarial Sleeping\",\"Global Convergence  to Local Minmax Equilibrium in Classes of Nonconvex Zero-Sum Games\",\"Provable Model-based Nonlinear Bandit and Reinforcement Learning: Shelve Optimism, Embrace Virtual Curvature\",\"Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi\",\"Learning to delegate for large-scale vehicle routing\",\"The Utility of Explainable AI in Ad Hoc Human-Machine Teaming\",\"Optimal prediction of Markov chains with and without spectral gap\",\"Contrastive Active Inference\",\"Dynamic influence maximization\",\"Reinforcement Learning based Disease Progression Model for Alzheimer\\u2019s Disease\",\"One More Step Towards Reality: Cooperative Bandits with Imperfect Communication\",\"Dealing With Misspecification In Fixed-Confidence Linear Top-m Identification\",\"Online Multi-Armed Bandits with Adaptive Inference\",\"Invariant Causal Imitation Learning for Generalizable Policies\",\"Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification\",\"Learning MDPs from Features: Predict-Then-Optimize for Sequential Decision Making by Reinforcement Learning\",\"Hierarchical Skills for Efficient Exploration\",\"An Efficient Transfer Learning Framework for Multiagent Reinforcement Learning\",\"Equilibrium Refinement for the Age of Machines: The One-Sided Quasi-Perfect Equilibrium\",\"Coordinated Proximal Policy Optimization\",\"Extending Lagrangian and Hamiltonian Neural Networks with Differentiable Contact Models\",\"Fast rates for prediction with limited expert advice\",\"Heterogeneous Multi-player Multi-armed Bandits: Closing the Gap and Generalization\",\"Continual Auxiliary Task Learning\",\"Strategic Behavior is Bliss: Iterative Voting Improves Social Welfare\",\"Environment Generation for Zero-Shot Compositional Reinforcement Learning\",\"A Max-Min Entropy Framework for Reinforcement Learning\",\"Counterexample Guided RL Policy Refinement Using Bayesian Optimization\",\"Regret Minimization Experience Replay in Off-Policy Reinforcement Learning\",\"Improved Variance-Aware Confidence Sets for Linear Bandits and Linear Mixture MDP\",\"Oracle-Efficient Regret Minimization in Factored MDPs with Unknown Structure\",\"Offline Reinforcement Learning with Reverse Model-based Imagination\",\"Tactical Optimism and Pessimism for Deep Reinforcement Learning\",\"On the Expressivity of Markov Reward\",\"Learning Markov State Abstractions for Deep Reinforcement Learning\",\"Counterfactual Explanations in Sequential Decision Making Under Uncertainty\",\"Active Offline Policy Selection\",\"The Limits of Optimal Pricing in the Dark\",\"Learning Knowledge Graph-based World Models of Textual Environments\",\"No Regrets for Learning the Prior in Bandits\",\"A unified framework for bandit multiple testing\",\"Dual Adaptivity: A Universal Algorithm for Minimizing the Adaptive Regret of Convex Functions\",\"Towards Best-of-All-Worlds Online Learning with Feedback Graphs\",\"SEAL: Self-supervised Embodied Active Learning using Exploration and 3D Consistency\",\"A Minimalist Approach to Offline Reinforcement Learning\",\"Batched Thompson Sampling\",\"Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch\",\"(Almost) Free Incentivized Exploration from Decentralized Learning Agents\",\"Emergent Communication under Varying Sizes and Connectivities\",\"Learning Domain Invariant Representations in Goal-conditioned Block MDPs\",\"Breaking the Moments Condition Barrier: No-Regret Algorithm for Bandits with Super Heavy-Tailed Payoffs\",\"Online Learning in Periodic Zero-Sum Games\",\"Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning\",\"Explicable Reward Design for Reinforcement Learning Agents\",\"BooVI: Provably Efficient Bootstrapped Value Iteration\",\"Counterbalancing Learning and Strategic Incentives in Allocation Markets\",\"MAP Propagation Algorithm: Faster Learning with a Team of Reinforcement Learning Agents\",\"Revisiting Smoothed Online Learning\",\"The Difficulty of Passive Learning in Deep Reinforcement Learning\",\"Neural Auto-Curricula in Two-Player Zero-Sum Games\",\"Universal Off-Policy Evaluation\",\"Optimal Algorithms for Stochastic Contextual Preference Bandits \",\"Policy Learning Using Weak Supervision\",\"Reducing Collision Checking for Sampling-Based Motion Planning Using Graph Neural Networks\",\"Offline Model-based Adaptable Policy Learning\",\"Learning to Ground Multi-Agent Communication with Autoencoders\",\"Sparsely Changing Latent States for Prediction and Planning in Partially Observable Domains\",\"A Biased Graph Neural Network Sampler with Near-Optimal Regret\",\"Multi-armed Bandit Requiring Monotone Arm Sequences\",\"Dynamic population-based meta-learning for multi-agent communication with natural language\",\"Learning to Simulate Self-driven Particles System with Coordinated Policy Optimization\",\"The best of both worlds: stochastic and adversarial episodic MDPs with unknown transition\",\"Pessimism Meets Invariance: Provably Efficient Offline Mean-Field Multi-Agent RL\",\"Multi-Armed Bandits with Bounded Arm-Memory: Near-Optimal Guarantees for Best-Arm Identification and Regret Minimization\",\"Parametrized Quantum Policies for Reinforcement Learning\",\"Reinforcement Learning with Latent Flow\",\"$\\\\texttt{LeadCache}$: Regret-Optimal Caching in Networks\",\"Curriculum Design for Teaching via Demonstrations: Theory and Applications\",\"Control Variates for Slate Off-Policy Evaluation\",\"Behavior From the Void: Unsupervised Active Pre-Training\",\"A/B/n Testing with Control in the Presence of Subpopulations\",\"Fair Scheduling for Time-dependent Resources\",\"Teachable Reinforcement Learning via Advice Distillation\",\"Reward-Free Model-Based Reinforcement Learning with Linear Function Approximation\",\"Ranking Policy Decisions\",\"Optimal Gradient-based Algorithms for Non-concave Bandit Optimization\",\"Least Square Calibration for Peer Reviews\",\"Automated Dynamic Mechanism Design\",\"Provably Efficient Causal Reinforcement Learning with Confounded Observational Data\",\"Reinforcement Learning in Reward-Mixing MDPs\",\"Online Knapsack with Frequency Predictions\",\"Automatic Data Augmentation for Generalization in Reinforcement Learning\",\"Online Matching in Sparse Random Graphs: Non-Asymptotic Performances of Greedy Algorithm\",\"On the Estimation Bias in Double Q-Learning\",\"Doubly Robust Thompson Sampling with Linear Payoffs\",\"Collaborating with Humans without Human Data\",\"Program Synthesis Guided Reinforcement Learning for Partially Observed Environments\",\"Mitigating Covariate Shift in Imitation Learning via Offline Data With Partial Coverage\",\"Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods\",\"Stochastic Multi-Armed Bandits with Control Variates\",\"Fast Pure Exploration via Frank-Wolfe\",\"Safe Pontryagin Differentiable Programming\",\"Decentralized Q-learning in Zero-sum Markov Games\",\"Multi-Agent Reinforcement Learning for Active Voltage Control on Power Distribution Networks\",\"Local policy search with Bayesian optimization\",\"Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds\",\"On the Suboptimality  of Thompson Sampling in High Dimensions\",\"Reinforcement learning for optimization of variational quantum circuit architectures\",\"Pure Exploration in Kernel and Neural Bandits\",\"Multi-Agent Reinforcement Learning in Stochastic Networked Systems\",\"Regularized Softmax Deep Multi-Agent Q-Learning\",\"Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning\",\"Conservative Data Sharing for Multi-Task Offline Reinforcement Learning\",\"Interpretable agent communication from scratch (with a generic visual processor emerging on the side)\",\"Continuous Doubly Constrained Batch Reinforcement Learning\",\"MADE: Exploration via Maximizing Deviation from Explored Regions\",\"Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding\",\"Learning Collaborative Policies to Solve NP-hard Routing Problems\",\"On The Structure of Parametric Tournaments with Application to Ranking from Pairwise Comparisons\",\"Conic Blackwell Algorithm: Parameter-Free Convex-Concave Saddle-Point Solving\",\"Self-Consistent Models and Values\",\"The Semi-Random Satisfaction of Voting Axioms\",\"Selective Sampling for Online Best-arm Identification\",\"Navigating to the Best Policy in Markov Decision Processes\",\"Solving Min-Max Optimization with Hidden Structure via Gradient Descent Ascent\",\"Entropic Desired Dynamics for Intrinsic Control\",\"Variational Bayesian Reinforcement Learning with Regret Bounds\",\"Exponential Bellman Equation and Improved Regret Bounds for Risk-Sensitive Reinforcement Learning\",\"PreferenceNet: Encoding Human Preferences in Auction Design with Deep Learning\",\"Robust Predictable Control\",\"The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning\",\"Robust Auction Design in the Auto-bidding World\",\"Learning Space Partitions for Path Planning\",\"Subgame solving without common knowledge\",\"Visual Adversarial Imitation Learning using Variational Models\",\"Logarithmic Regret from Sublinear Hints\",\"RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem\",\"Risk-Averse Bayes-Adaptive Reinforcement Learning\",\"Bayesian decision-making under misspecified priors with applications to meta-learning\",\"On Optimal Robustness to Adversarial Corruption in Online Decision Problems\",\"Interesting Object, Curious Agent: Learning Task-Agnostic Exploration\",\"Autonomous Reinforcement Learning via Subgoal Curricula\",\"Off-Policy Risk Assessment in Contextual Bandits\",\"Robust Learning of Optimal Auctions\",\"COMBO: Conservative Offline Model-Based Policy Optimization\",\"Robust Deep Reinforcement Learning through Adversarial Loss\",\"Towards Unifying Behavioral and Response Diversity for Open-ended Learning in Zero-sum Games\",\"Stateful Strategic Regression\",\"CO-PILOT: COllaborative Planning and reInforcement Learning On sub-Task curriculum\",\"TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning\",\"Decision Transformer: Reinforcement Learning via Sequence Modeling\",\"Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives\",\"Iterative Teacher-Aware Learning\",\"RMIX: Learning Risk-Sensitive Policies for Cooperative Reinforcement Learning Agents\",\"Successor Feature Landmarks for Long-Horizon Goal-Conditioned Reinforcement Learning\",\"Adaptive Ensemble Q-learning: Minimizing Estimation Bias via Error Feedback\",\"Nearly Horizon-Free Offline Reinforcement Learning\",\"Stochastic bandits with groups of similar arms.\",\"Minimax Regret for Stochastic Shortest Path\",\"What Matters for Adversarial Imitation Learning?\",\"Subgoal Search For Complex Reasoning Tasks\",\"On the Convergence Theory of Debiased Model-Agnostic Meta-Reinforcement Learning\",\"Revenue maximization via machine learning with noisy data\",\"VAST: Value Function Factorization with Variable Agent Sub-Teams\",\"Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations\",\"Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs\",\"XDO: A Double Oracle Algorithm for Extensive-Form Games\",\"Model-Based Episodic Memory Induces Dynamic Hybrid Controls\",\"Non-Asymptotic Analysis for Two Time-scale TDC with General Smooth Function Approximation\",\"Damped Anderson Mixing for Deep Reinforcement Learning: Acceleration, Convergence, and Stabilization\",\"Fast Algorithms for $L_\\\\infty$-constrained S-rectangular Robust MDPs\",\"Uniform-PAC Bounds for Reinforcement Learning with Linear Function Approximation\",\"Design of Experiments for Stochastic Contextual Linear Bandits\",\"Efficient First-Order Contextual Bandits: Prediction, Allocation, and Triangular Discrimination\",\"Bandits with Knapsacks beyond the Worst Case\",\"UCB-based Algorithms for Multinomial Logistic Regression Bandits\",\"Combinatorial Pure Exploration with Bottleneck Reward Function\",\"Learning Large Neighborhood Search Policy for Integer Programming\",\"Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings\",\"An Efficient Pessimistic-Optimistic Algorithm for Stochastic Linear Bandits with General Constraints\",\"A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning\",\"Contextual Recommendations and Low-Regret Cutting-Plane Algorithms\",\"Finite Sample Analysis of Average-Reward TD Learning and $Q$-Learning\",\"Finite-Sample Analysis of Off-Policy TD-Learning via Generalized Bellman Operators\",\"Pretraining Representations for Data-Efficient Reinforcement Learning\",\"Curriculum Learning for Vision-and-Language Navigation\",\"Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design: Implicit Regularization and Sample Complexity\",\"Fair Sortition Made Transparent\",\"Object-Aware Regularization for Addressing Causal Confusion in Imitation Learning\",\"Improve Agents without Retraining: Parallel Tree Search with Off-Policy Correction\",\"Sample Complexity Bounds for Active Ranking from Multi-wise Comparisons\",\"A Provably Efficient Sample Collection Strategy for Reinforcement Learning\",\"Weighted model estimation for offline model-based reinforcement learning\",\"Amortized Synthesis of Constrained Configurations Using a Differentiable Surrogate\",\"Meta-Adaptive Nonlinear Control: Theory and Algorithms\",\"PiRank: Scalable Learning To Rank via Differentiable Sorting\",\"On the Rate of Convergence of Regularized Learning in Games: From Bandits and Uncertainty to Optimism and Beyond\",\"A Hierarchical Reinforcement Learning Based Optimization Framework for Large-scale Dynamic Pickup and Delivery Problems\",\"Settling the Variance of Multi-Agent Policy Gradients\",\"On the Convergence and Sample Efficiency of Variance-Reduced Policy Gradient Method\",\"Learning Diverse Policies in MOBA Games via Macro-Goals\",\"Imitation with Neural Density Models\",\"NeurWIN: Neural Whittle Index Network For Restless Bandits Via Deep RL\",\"From Optimality to Robustness: Adaptive Re-Sampling Strategies in Stochastic Bandits\",\"PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators\",\"Monte Carlo Tree Search With Iteratively Refining State Abstractions\",\"Accelerating Quadratic Optimization with Reinforcement Learning\",\"Outcome-Driven Reinforcement Learning via Variational Inference\",\"Learning in Multi-Stage Decentralized Matching Markets\",\"Provably Efficient Black-Box Action Poisoning Attacks Against Reinforcement Learning\",\"Residual Pathway Priors for Soft Equivariance Constraints\",\"A Closer Look at the Worst-case Behavior of Multi-armed Bandit Algorithms\",\"Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning\",\"Learning to Elect\",\"Understanding Bandits with Graph Feedback\",\"Logarithmic Regret in Feature-based Dynamic Pricing\",\"Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning\",\"When Is Generalizable Reinforcement Learning Tractable?\",\"Bandit Quickest Changepoint Detection\",\"Machine versus Human Attention in Deep Reinforcement Learning Tasks\",\"Infinite Time Horizon Safety of Bayesian Neural Networks\",\"Streaming Linear System Identification with Reverse Experience Replay\",\"Safe Reinforcement Learning by Imagining the Near Future\",\"IQ-Learn: Inverse soft-Q Learning for Imitation\",\"Provably Efficient Reinforcement Learning with Linear Function Approximation under Adaptivity Constraints\",\"Shaping embodied agent behavior with activity-context priors from egocentric video\",\"Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings \",\"Bandits with many optimal arms\",\"Fair Algorithms for Multi-Agent Multi-Armed Bandits\",\"Neural Algorithmic Reasoners are Implicit Planners\",\"The Adaptive Doubly Robust Estimator and a Paradox Concerning Logging Policy\",\"Two-sided fairness in rankings via Lorenz dominance\",\"Online Control of Unknown Time-Varying Dynamical Systems\",\"Towards Deeper Deep Reinforcement Learning with Spectral Normalization\",\"Chebyshev-Cantelli PAC-Bayes-Bennett Inequality for the Weighted Majority Vote\",\"Representation Learning for Event-based Visuomotor Policies\",\"Near-Optimal Offline Reinforcement Learning via Double Variance Reduction\",\"Solving Graph-based Public Goods Games with Tree Search and Imitation Learning\",\"Risk Minimization from Adaptively Collected Data: Guarantees for Supervised and Policy Learning\",\"Flexible Option Learning\",\"Twice regularized MDPs and the equivalence between robustness and regularization\",\"Stochastic Shortest Path: Minimax, Parameter-Free and Towards Horizon-Free Regret\",\"Factored Policy Gradients: Leveraging Structure for Efficient Learning in MOMDPs\",\"Last-iterate Convergence in Extensive-Form Games\",\"No-Press Diplomacy from Scratch\",\"On Pathologies in KL-Regularized Reinforcement Learning from Expert Demonstrations\",\"Discovering and Achieving Goals via World Models\",\"Emergent Discrete Communication in Semantic Spaces\",\"Towards Hyperparameter-free Policy Selection for Offline Reinforcement Learning\",\"Variational Bayesian Optimistic Sampling\",\"Adaptive Online Packing-guided Search for POMDPs\",\"Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation\",\"Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs\",\"Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms\",\"Near-Optimal No-Regret Learning in General Games\",\"Distributional Reinforcement Learning for Multi-Dimensional Reward Functions\",\"Structural Credit Assignment in Neural Networks using Reinforcement Learning\",\"Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability\",\"Parallelizing Thompson Sampling\",\"Who Leads and Who Follows in Strategic Classification?\",\"Recurrent Submodular Welfare and Matroid Blocking Semi-Bandits\",\"Functional Regularization for Reinforcement Learning via Learned Fourier Features\",\"Learning to Iteratively Solve Routing Problems with Dual-Aspect Collaborative Transformer\",\"MICo: Improved representations via sampling-based state similarity for Markov decision processes\",\"Online Market Equilibrium with Application to Fair Division\",\"Scheduling jobs with stochastic holding costs\",\"Inverse Reinforcement Learning in a Continuous State Space with Formal Guarantees\",\"Causal Navigation by Continuous-time Neural Networks\",\"Fast Policy Extragradient Methods for Competitive Games with Entropy Regularization\",\"Unifying Gradient Estimators for Meta-Reinforcement Learning  via Off-Policy Evaluation\",\"Dynamic Bottleneck for Robust Self-Supervised Exploration\",\"Information is Power: Intrinsic Control via Information Capture\",\"Heuristic-Guided Reinforcement Learning\",\"PlayVirtual: Augmenting Cycle-Consistent Virtual Trajectories for Reinforcement Learning\",\"Implicit Finite-Horizon Approximation and Efficient Optimal Algorithms for Stochastic Shortest Path\",\"Learning-to-learn non-convex piecewise-Lipschitz functions\",\"Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations\",\"Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of Representation Learning in Actor-Critic\",\"Generating High-Quality Explanations for Navigation in Partially-Revealed Environments\",\"Wisdom of the Crowd Voting: Truthful Aggregation of Voter Information and Preferences\",\"Provably efficient multi-task reinforcement learning with model transfer\",\"Post-Contextual-Bandit Inference\",\"Cooperative Stochastic Bandits with Asynchronous Agents and Constrained Feedback\",\"Optimal Best-Arm Identification Methods for Tail-Risk Measures\",\"Reinforcement Learning with State Observation Costs in Action-Contingent Noiselessly Observable Markov Decision Processes \",\"Stochastic Online Linear Regression: the Forward Algorithm to Replace Ridge\",\"Which Mutual-Information Representation Learning Objectives are Sufficient for Control?\",\"Replay-Guided Adversarial Environment Design\",\"NeuroLKH: Combining Deep Learning Model with Lin-Kernighan-Helsgaun Heuristic for Solving the Traveling Salesman Problem\",\"Contrastive Reinforcement Learning of Symbolic Reasoning Domains\",\"Play to Grade: Testing Coding Games as Classifying Markov Decision Process\",\"Deep Reinforcement Learning at the Edge of the Statistical Precipice\",\"Is Bang-Bang Control All You Need? Solving Continuous Control with Bernoulli Policies\",\"Bandit Phase Retrieval\",\"Hybrid Regret Bounds for Combinatorial Semi-Bandits and Adversarial Linear Bandits\",\"Average-Reward Learning and Planning with Options\",\"Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems\",\"Indexed Minimum Empirical Divergence for Unimodal Bandits\",\"On Component Interactions in Two-Stage Recommender Systems\",\"Scalable Online Planning via Reinforcement Learning Fine-Tuning\",\"Uncertain Decisions Facilitate Better Preference Learning\",\"Temporally Abstract Partial Models\",\"TAAC: Temporally Abstract Actor-Critic for Continuous Control\",\"Online Robust Reinforcement Learning with Model Uncertainty\",\"Sequential Causal Imitation Learning with Unobserved Confounders\",\"SOPE: Spectrum of Off-Policy Estimators\",\"There Is No Turning Back: A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning\",\"Learning to Schedule Heuristics in Branch and Bound\",\"Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates\",\"Learning in Non-Cooperative Configurable Markov Decision Processes\",\"Misspecified Gaussian Process Bandit Optimization\",\"Planning from Pixels in Environments with Combinatorially Hard Search Spaces\",\"Understanding the Effect of Stochasticity in Policy Optimization\",\"Safe Reinforcement Learning with Natural Language Constraints\",\" Taming Communication and Sample Complexities in Decentralized Policy Evaluation for Cooperative Multi-Agent Reinforcement Learning\",\"Going Beyond Linear RL: Sample Efficient Neural Function Approximation\",\"Towards Instance-Optimal Offline Reinforcement Learning with Pessimism\",\"Episodic Multi-agent Reinforcement Learning with Curiosity-driven Exploration\",\"Towards mental time travel: a hierarchical memory for reinforcement learning agents\",\"Asymptotically Exact Error Characterization of Offline Policy Evaluation with Misspecified Linear Models\",\"Celebrating Diversity in Shared Multi-Agent Reinforcement Learning\",\"Bayesian Bellman Operators\",\"Causal Influence Detection for Improving Efficiency in Reinforcement Learning\",\"Mixability made efficient: Fast online multiclass logistic regression\",\"RL for Latent MDPs: Regret Guarantees and a Lower Bound\",\"Provable Benefits of Actor-Critic Methods for Offline Reinforcement Learning\",\" Online learning in MDPs with linear function approximation and bandit feedback. \",\"Conservative Offline Distributional Reinforcement Learning\",\"Generalizable Imitation Learning from Observation via Inferring Goal Proximity\",\"BCORLE($\\\\lambda$): An Offline Reinforcement Learning and Evaluation Framework for Coupons Allocation in E-commerce Market\",\"Learning to Select Exogenous Events for Marked Temporal Point Process\",\"Sample-Efficient Reinforcement Learning Is Feasible for Linearly Realizable MDPs with Limited Revisiting\",\"On Blame Attribution for Accountable Multi-Agent Sequential Decision Making\",\"Regulating algorithmic filtering on social media\",\"Hindsight Task Relabelling: Experience Replay for Sparse Reward Meta-RL\",\"Reward is enough for convex MDPs\",\"Reinforcement Learning in Linear MDPs: Constant Regret and Representation Selection\",\"Dueling Bandits with Team Comparisons\",\"A Gang of Adversarial Bandits\",\"Discovery of Options via Meta-Learned Subgoals\",\"Evolution Gym: A Large-Scale Benchmark for Evolving Soft Robots\",\"A Faster Maximum Cardinality Matching Algorithm with Applications in Machine Learning\",\"An Exponential Lower Bound for Linearly Realizable MDP with Constant Suboptimality Gap\",\"Statistical Inference with M-Estimators on Adaptively Collected Data\",\"MobILE: Model-Based Imitation Learning From Observation Alone\",\"Habitat 2.0: Training Home Assistants to Rearrange their Habitat\",\"A/B Testing for Recommender Systems in a Two-sided Marketplace\",\"You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism\",\"Stabilizing Dynamical Systems via Policy Gradient Methods\",\"Learning State Representations from Random Deep Action-conditional Predictions\",\"Landmark-Guided Subgoal Generation in Hierarchical Reinforcement Learning\",\"On the Theory of Reinforcement Learning with Once-per-Episode Feedback\",\"Learning to Draw: Emergent Communication through Sketching\",\"K-level Reasoning for Zero-Shot Coordination in Hanabi\",\"Adversarial Intrinsic Motivation for Reinforcement Learning\",\"Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning\",\"Mastering Atari Games with Limited Data\",\"Medical Dead-ends and Learning to Identify High-Risk States and Treatments\",\"Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation\",\"Near Optimal Policy Optimization via REPS\",\"Compositional Reinforcement Learning from Logical Specifications\",\"Two steps to risk sensitivity\",\"Emergent Communication of Generalizations\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"0_learning_reinforcement_reinforcement learning\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"0_learning_reinforcement_reinforcement learning\"],\"textfont\":{\"size\":12},\"x\":[7.315122127532959,7.722226142883301,8.593917846679688,7.803572177886963,8.75753116607666,7.3409833908081055,8.746902465820312,8.262032508850098,8.419190406799316,7.997203826904297,9.242993354797363,7.7699384689331055,8.653899192810059,9.387613296508789,9.040651321411133,7.907831192016602,7.486181735992432,8.758886337280273,7.947709560394287,7.582317352294922,7.862964153289795,8.167044639587402,8.039511680603027,8.401509284973145,9.018293380737305,9.268794059753418,7.536667346954346,8.325456619262695,8.859652519226074,9.135991096496582,7.5742292404174805,9.10228443145752,7.292713642120361,8.167305946350098,9.022854804992676,9.025325775146484,8.342894554138184,6.281293869018555,8.796634674072266,7.838952541351318,7.552083492279053,8.553915023803711,9.338302612304688,7.820418357849121,8.470388412475586,9.040363311767578,7.886603832244873,8.535598754882812,8.780108451843262,8.882323265075684,9.35798454284668,7.837304592132568,8.450927734375,9.053187370300293,7.373266220092773,9.016934394836426,8.439309120178223,8.580438613891602,8.574362754821777,7.745372295379639,7.781689643859863,8.708914756774902,7.4361443519592285,8.174908638000488,7.542250156402588,8.873493194580078,8.536213874816895,8.039571762084961,8.781946182250977,7.970420837402344,8.696929931640625,8.532896995544434,7.659074306488037,7.7239837646484375,8.355602264404297,9.287510871887207,8.79973316192627,7.8756561279296875,8.746956825256348,8.206832885742188,7.649572372436523,7.34756326675415,7.88395881652832,8.800827980041504,8.706559181213379,8.653243064880371,8.840596199035645,7.770302772521973,7.576930522918701,8.909403800964355,9.297822952270508,8.01968765258789,9.067395210266113,8.427620887756348,7.576077938079834,7.388924598693848,8.985464096069336,9.1289644241333,8.64669132232666,9.060674667358398,8.664182662963867,7.620609283447266,8.905524253845215,8.921259880065918,8.54262924194336,8.415657043457031,7.319178581237793,7.953502655029297,9.378005981445312,8.307751655578613,8.577713966369629,8.147849082946777,7.645756721496582,9.22300910949707,7.3406805992126465,9.100719451904297,9.073118209838867,8.577357292175293,8.79748249053955,8.353432655334473,8.758881568908691,8.375662803649902,7.738555908203125,8.905447959899902,7.860427379608154,9.11162281036377,8.590246200561523,8.651423454284668,7.334620475769043,7.931162357330322,7.8572998046875,8.07558536529541,8.234097480773926,9.07201862335205,8.555207252502441,6.236958980560303,7.354132652282715,9.05494213104248,7.9881391525268555,9.370742797851562,7.97091817855835,8.118816375732422,7.432344436645508,7.956381797790527,8.763859748840332,8.548588752746582,7.561593055725098,7.796530723571777,8.452230453491211,7.784162998199463,7.047356605529785,7.59929084777832,9.2623929977417,7.644251346588135,8.769280433654785,8.681090354919434,8.650666236877441,8.883197784423828,7.3228278160095215,7.5816330909729,8.885791778564453,7.326985836029053,9.27934741973877,7.5400071144104,7.89951229095459,8.653898239135742,9.070723533630371,7.471034049987793,8.437188148498535,8.44009780883789,9.3809814453125,7.650296211242676,8.835677146911621,7.572292327880859,8.783482551574707,8.417194366455078,9.099529266357422,7.3625006675720215,8.025840759277344,7.54915714263916,7.549903869628906,7.624009132385254,8.629764556884766,9.164953231811523,7.554431915283203,8.600728034973145,8.668658256530762,8.072515487670898,9.055514335632324,7.895105361938477,7.553976535797119,8.847811698913574,7.383571147918701,8.702250480651855,7.787519454956055,8.73400592803955,9.310598373413086,7.945971488952637,8.389211654663086,7.882708549499512,8.593575477600098,9.220010757446289,8.963447570800781,7.539426326751709,8.439401626586914,8.735371589660645,7.561648368835449,9.349754333496094,7.892786979675293,8.808798789978027,8.766681671142578,7.944007396697998,7.321200847625732,7.988588333129883,8.681541442871094,8.707023620605469,7.422504901885986,9.101496696472168,8.404256820678711,7.99360990524292,8.606036186218262,8.861096382141113,7.870765686035156,8.582853317260742,8.422950744628906,8.529342651367188,8.509228706359863,7.559737682342529,7.5304741859436035,7.608546257019043,8.220598220825195,7.783440589904785,8.328059196472168,9.218069076538086,8.777324676513672,8.086121559143066,9.369339942932129,8.735166549682617,8.439187049865723,9.067557334899902,7.72274923324585,8.581204414367676,8.47697639465332,9.393776893615723,7.7358198165893555,7.681692123413086,9.305285453796387,8.22797966003418,8.838152885437012,7.327600002288818,8.792009353637695,7.562435150146484,8.417620658874512,8.744579315185547,8.995088577270508,8.02648639678955,7.956572532653809,8.584239959716797,9.300644874572754,7.551077842712402,7.446258068084717,8.767709732055664,8.993934631347656,8.134556770324707,7.863831043243408,7.740659236907959,8.058883666992188,8.039559364318848,8.418421745300293,8.141782760620117,7.7700042724609375,8.19742202758789,9.172106742858887,8.686626434326172,7.336069583892822,8.113364219665527,8.045114517211914,9.361308097839355,8.542867660522461,7.41324520111084,8.65466022491455,8.775357246398926,7.8691325187683105,8.123403549194336,7.700235366821289,8.3248291015625,8.361540794372559,8.828630447387695,8.886691093444824,8.94876480102539,8.992430686950684,9.004362106323242,7.854791641235352,7.54385232925415,8.709144592285156,7.761242866516113,8.828852653503418,8.220996856689453,8.150490760803223,7.6459808349609375,7.216483116149902,8.160140037536621,9.357361793518066,7.316392421722412,8.002596855163574,9.239623069763184,8.50643253326416,7.594111919403076,6.269066333770752,7.225005149841309,9.142516136169434,8.89559268951416,8.35299015045166,8.504225730895996,8.067014694213867,8.71635627746582,7.329880714416504,8.669485092163086,8.692877769470215,7.5136847496032715,8.459761619567871,7.899791240692139,7.583965301513672,9.307677268981934,7.364328384399414,7.736786842346191,8.952990531921387,8.549541473388672,4.177977561950684,8.94576644897461,9.000062942504883,7.948055744171143,8.358855247497559,8.55700969696045,7.569703578948975,7.31581974029541,7.677224159240723,7.4186201095581055,7.3426642417907715,8.54299545288086,7.354978084564209,8.143338203430176,8.911982536315918,9.236531257629395,8.010017395019531,8.452631950378418,9.267908096313477,8.231505393981934,7.54429292678833,6.748830795288086,7.246827602386475,8.155205726623535,8.708792686462402,8.603940963745117,8.228235244750977,8.321099281311035,8.626700401306152,8.388227462768555,8.936121940612793,8.711589813232422,7.36092472076416,7.41345739364624,7.542788982391357,7.895933628082275,8.796299934387207,8.490391731262207,7.582214832305908,8.60153865814209,8.361787796020508,8.960857391357422,8.028789520263672,7.875172138214111,8.039399147033691,8.876409530639648,8.892990112304688,9.22138786315918,7.47853422164917,8.357579231262207,7.81693172454834,9.327089309692383,9.200576782226562,7.308599948883057,7.223475933074951,9.054861068725586,8.011421203613281,8.221040725708008,7.770444869995117,8.059708595275879,7.537744998931885,8.624868392944336,8.532177925109863,8.31343936920166,7.97751522064209,7.60080623626709,9.399359703063965,8.502115249633789,8.577461242675781,9.238483428955078,8.550419807434082,8.233552932739258,8.678045272827148,7.808900356292725,8.005583763122559,8.35269832611084,7.774396896362305,7.974276542663574,7.782829284667969,7.804168701171875,8.719245910644531,8.989049911499023,8.37269401550293,8.35170841217041,8.814545631408691,9.242256164550781,8.634276390075684,7.335382461547852,8.270187377929688,7.905826568603516,7.952369689941406,7.322256088256836,8.432071685791016,8.006330490112305,8.30351734161377,8.217428207397461,8.53425121307373,8.317060470581055,8.1102876663208,8.327667236328125,7.447420120239258,8.55449390411377,7.909670829772949,8.141563415527344,8.503717422485352,7.1802287101745605,8.1444673538208,8.583699226379395,7.752854824066162,7.459537506103516,8.710916519165039,8.388154983520508,7.997075080871582,8.613302230834961,7.7654643058776855,7.369922637939453,7.6257429122924805,8.456298828125,8.146677017211914,7.180418014526367,9.354950904846191,8.191006660461426,8.446027755737305,8.555204391479492,9.253209114074707,9.078970909118652,8.148177146911621,6.344576358795166,9.405424118041992,8.290409088134766,8.578262329101562,7.354710578918457,7.444552898406982,9.300395011901855,9.248023986816406,7.974339485168457,7.60313606262207,8.163272857666016,8.039579391479492,7.534796714782715,8.779928207397461,7.855271816253662,8.140093803405762,7.568427562713623,7.669654369354248,7.496927261352539,7.971926689147949,7.922600746154785,8.217020988464355,7.537482261657715,8.260335922241211],\"y\":[9.017913818359375,9.369447708129883,7.909291744232178,9.462076187133789,6.666512489318848,9.067972183227539,6.611685752868652,9.367570877075195,6.757115364074707,9.490647315979004,6.414727210998535,8.345667839050293,6.584931373596191,6.2249040603637695,7.949948787689209,8.21259880065918,9.352087020874023,7.084969997406006,8.713580131530762,8.330307960510254,8.910905838012695,9.385805130004883,9.037123680114746,6.908563613891602,6.885492324829102,6.8831868171691895,10.154338836669922,8.724565505981445,7.098291873931885,7.218134880065918,8.431676864624023,6.876727104187012,9.510160446166992,9.29520034790039,8.014735221862793,6.975782871246338,7.695547580718994,8.430943489074707,6.695837497711182,8.336559295654297,8.288331985473633,8.964409828186035,6.7225165367126465,8.349595069885254,9.034883499145508,8.082172393798828,8.808436393737793,8.941699981689453,7.097262859344482,8.716367721557617,6.663328647613525,9.127655029296875,6.905579090118408,8.047652244567871,9.101951599121094,6.895694255828857,8.67451000213623,8.883176803588867,8.511983871459961,9.696154594421387,9.085204124450684,7.382382392883301,8.538797378540039,7.979264736175537,10.141206741333008,6.552117824554443,7.201644420623779,8.250935554504395,6.654621601104736,8.323229789733887,6.953575134277344,7.912653923034668,9.45944595336914,8.300976753234863,8.19826889038086,6.734495639801025,7.226870059967041,8.240204811096191,7.300809860229492,9.362532615661621,8.487122535705566,9.082254409790039,8.782798767089844,7.4870381355285645,6.95210599899292,7.255247592926025,7.164485454559326,9.484831809997559,9.38887882232666,6.8955206871032715,6.099343299865723,8.895564079284668,7.833613872528076,7.7202677726745605,8.377152442932129,9.007248878479004,7.164039611816406,6.680425643920898,7.102004051208496,8.119142532348633,6.455642223358154,8.325593948364258,8.649567604064941,7.022367477416992,8.951495170593262,8.60744857788086,9.02975082397461,9.315634727478027,6.298524379730225,8.631678581237793,6.8537211418151855,9.311776161193848,9.51047134399414,6.8486151695251465,9.09753131866455,6.765531063079834,8.042298316955566,7.526401042938232,8.943086624145508,9.78720760345459,8.998785018920898,6.899931907653809,9.30893611907959,6.4268879890441895,9.05549430847168,6.903472900390625,6.930613040924072,6.991363048553467,9.084258079528809,9.005887985229492,9.159454345703125,9.371826171875,9.206709861755371,8.16444206237793,8.929084777832031,8.38371753692627,5.411071300506592,6.941099643707275,9.2230224609375,6.295454978942871,9.609074592590332,8.65832233428955,8.543562889099121,8.186309814453125,7.13008975982666,7.906822681427002,8.362702369689941,8.406249046325684,8.636624336242676,9.269803047180176,7.319255828857422,8.304855346679688,6.502037048339844,9.992450714111328,7.190990447998047,6.893096446990967,6.522836685180664,6.699274063110352,9.510396003723145,8.298633575439453,7.157679557800293,9.024935722351074,6.8499603271484375,10.160603523254395,9.205601692199707,6.895727157592773,7.979130268096924,9.4122896194458,8.66999340057373,7.841515064239502,6.304253578186035,9.45754337310791,6.707935333251953,8.30258560180664,8.893453598022461,7.3967671394348145,6.7063422203063965,9.107613563537598,9.433201789855957,8.279534339904785,10.135313034057617,9.48904800415039,7.108563423156738,6.859377861022949,10.13670539855957,9.00536060333252,7.8100810050964355,8.021675109863281,6.875644207000732,8.374788284301758,9.454560279846191,6.736930847167969,9.139867782592773,7.1582818031311035,9.399837493896484,6.846063137054443,6.484314441680908,9.494403839111328,8.204787254333496,9.197661399841309,7.261794567108154,5.990140914916992,8.200758934020996,8.296756744384766,8.206961631774902,6.54744291305542,9.482008934020996,6.680242538452148,8.33518123626709,7.0927324295043945,8.952139854431152,9.5337495803833,9.03536319732666,8.419387817382812,6.9602227210998535,7.01076078414917,8.549201011657715,8.071213722229004,8.80254077911377,8.646803855895996,6.47896671295166,7.23848295211792,8.361249923706055,7.216376781463623,8.723337173461914,8.918050765991211,7.9882330894470215,8.292947769165039,10.159488677978516,8.308303833007812,9.196057319641113,9.479232788085938,9.754499435424805,6.190851211547852,7.391674518585205,9.250557899475098,6.182962894439697,6.912654399871826,8.148648262023926,8.076125144958496,9.088115692138672,7.79710054397583,7.918668270111084,6.313258647918701,9.065634727478027,9.530200004577637,6.3738112449646,9.378403663635254,8.777539253234863,9.14210319519043,6.760014533996582,8.289164543151855,8.011590957641602,7.133147239685059,6.829841136932373,8.947120666503906,9.224220275878906,7.1159210205078125,6.3947296142578125,8.319097518920898,8.599547386169434,8.800718307495117,8.20454216003418,9.457709312438965,9.251291275024414,8.991469383239746,9.298957824707031,9.414412498474121,8.871065139770508,9.415511131286621,8.290932655334473,7.915309429168701,6.854645729064941,7.590483665466309,9.090510368347168,9.481005668640137,8.353522300720215,6.3323822021484375,8.951620101928711,8.585776329040527,7.731991291046143,8.85755729675293,9.303319931030273,8.13613510131836,8.902181625366211,8.271305084228516,7.7904229164123535,7.090942859649658,6.84899377822876,6.85333776473999,6.8387064933776855,6.951449394226074,9.275129318237305,9.468782424926758,7.444142818450928,9.347724914550781,6.709969997406006,8.146735191345215,8.034496307373047,9.436964988708496,9.628174781799316,8.233282089233398,6.141103267669678,9.124889373779297,8.389995574951172,6.173459053039551,8.061957359313965,8.30186653137207,8.423186302185059,9.235526084899902,5.880747318267822,7.654795169830322,9.780290603637695,8.947503089904785,8.316267967224121,8.937240600585938,9.05249309539795,7.2445855140686035,6.960031986236572,8.216188430786133,9.060896873474121,8.331518173217773,9.045857429504395,6.716089725494385,8.608970642089844,9.03156852722168,6.892401695251465,8.13872241973877,3.9024088382720947,6.775485992431641,6.562301158905029,9.163620948791504,8.826565742492676,6.847626686096191,9.500568389892578,8.430356979370117,8.10080337524414,8.5595703125,9.02852725982666,8.019083976745605,9.53852367401123,7.964879989624023,6.956857204437256,6.8263092041015625,9.485815048217773,6.893364906311035,6.063197612762451,7.75758171081543,9.453384399414062,5.407004356384277,9.386792182922363,7.971062660217285,8.825815200805664,7.015824317932129,9.2166109085083,8.249512672424316,7.720217704772949,8.7413911819458,7.739684104919434,8.901510238647461,9.082138061523438,9.5106782913208,10.145834922790527,8.304986000061035,7.4107136726379395,8.010483741760254,9.581517219543457,7.940321445465088,8.114591598510742,7.7252678871154785,8.778611183166504,9.1747407913208,8.673659324645996,7.179189205169678,8.590816497802734,6.877049446105957,9.29342269897461,9.798493385314941,9.107808113098145,6.490915298461914,6.777701377868652,9.011527061462402,9.310144424438477,8.114830017089844,8.304211616516113,9.200156211853027,9.291457176208496,9.356667518615723,9.459084510803223,7.723587989807129,6.36080265045166,8.108981132507324,8.393566131591797,9.631476402282715,6.243815898895264,8.162103652954102,6.997295379638672,6.830887317657471,6.988122940063477,8.40942096710205,6.5720062255859375,9.135049819946289,9.217660903930664,9.795797348022461,9.620889663696289,9.60434627532959,8.447712898254395,9.006301879882812,6.932135581970215,6.913003921508789,8.644112586975098,7.68522310256958,6.943662643432617,5.956618309020996,8.936158180236816,9.026358604431152,9.119277000427246,8.502443313598633,8.240679740905762,9.084736824035645,7.37690544128418,9.111912727355957,9.714449882507324,8.088464736938477,8.309001922607422,6.932107448577881,9.459383964538574,8.055795669555664,8.598963737487793,8.5329008102417,8.20230770111084,7.974239349365234,9.002669334411621,9.627513885498047,7.9558186531066895,8.96726131439209,8.759620666503906,9.056404113769531,6.5357537269592285,8.120847702026367,8.266352653503418,7.939028263092041,8.644301414489746,9.168986320495605,8.279486656188965,8.22340202331543,8.283531188964844,7.379098415374756,5.9839372634887695,9.306270599365234,8.341813087463379,7.976102828979492,6.630163192749023,6.774626731872559,9.304058074951172,8.480511665344238,6.619227409362793,8.093428611755371,6.995602607727051,9.062202453613281,9.455039024353027,6.025697708129883,6.064977645874023,8.089686393737793,9.434144973754883,9.41627311706543,9.095005989074707,10.154401779174805,8.914674758911133,8.778623580932617,7.9983696937561035,9.45730209350586,8.499062538146973,9.517928123474121,8.759053230285645,9.465802192687988,9.050809860229492,10.165556907653809,8.172928810119629],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods\",\"SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks\",\"VQ-GNN: A Universal Framework to Scale up Graph Neural Networks using Vector Quantization\",\"Automorphic Equivalence-aware Graph Neural Network\",\"NN-Baker: A Neural-network Infused Algorithmic Framework for Optimization Problems on Geometric Intersection Graphs\",\"Learning on Random Balls is Sufficient for Estimating (Some) Graph Parameters\",\"Metropolis-Hastings Data Augmentation for Graph Neural Networks\",\"Beltrami Flow and Neural Diffusion on Graphs\",\"Federated Graph Classification over Non-IID Graphs\",\"On the Power of Edge Independent Graph Models\",\"Learning Conjoint Attentions for Graph Neural Nets\",\"Active Learning of Convex Halfspaces on Graphs\",\"Universal Graph Convolutional Networks\",\"Not All Low-Pass Filters are Robust in Graph Convolutional Networks\",\"Representing Long-Range Context for Graph Neural Networks with Global Attention\",\"Subgraph Federated Learning with Missing Neighbor Generation\",\"Directed Graph Contrastive Learning\",\"Transformers Generalize DeepSets and Can be Extended to Graphs & Hypergraphs\",\"Learning Dynamic Graph Representation of Brain Connectome with Spatio-Temporal Attention\",\"Iterative Connecting Probability Estimation for Networks\",\"EIGNN: Efficient Infinite-Depth Graph Neural Networks\",\"Directed Probabilistic Watershed\",\"Dirichlet Energy Constrained Learning for Deep Graph Neural Networks\",\"Coupled Segmentation and Edge Learning via Dynamic Graph Propagation\",\"Edge Representation Learning with Hypergraphs\",\"Nested Graph Neural Networks\",\"Neighborhood Reconstructing Autoencoders\",\"A Bi-Level Framework for Learning to Solve Combinatorial Optimization on Graphs\",\"DropGNN: Random Dropouts Increase the Expressiveness of Graph Neural Networks\",\"Adaptive Diffusion in Graph Neural Networks\",\"Optimality of variational inference for stochasticblock model with missing links\",\"Topology-Imbalance Learning for Semi-Supervised Node Classification\",\"Autobahn: Automorphism-based Graph Neural Nets\",\"Graphical Models in Heavy-Tailed Markets\",\"Learning to Learn Graph Topologies\",\"Residual2Vec: Debiasing graph embedding with random graphs\",\"INDIGO: GNN-Based Inductive Knowledge Graph Completion Using Pair-Wise Encoding\",\"Neural Bellman-Ford Networks: A General Graph Neural Network Framework for Link Prediction\",\"Contrastive Laplacian Eigenmaps\",\"Ensembling Graph Predictions for AMR Parsing\",\"Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration\",\"Towards Multi-Grained Explainability for Graph Neural Networks\",\"Weisfeiler and Lehman Go Cellular: CW Networks\",\"Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization\",\"Adaptive Data Augmentation on Temporal Graphs\",\"Permutation-Invariant Variational Autoencoder for Graph-Level Representation Learning\",\"GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph\",\"Learning Theory Can (Sometimes) Explain Generalisation in Graph Neural Networks\",\"Spectral embedding for dynamic networks with stability guarantees\",\"Local Hyper-Flow Diffusion\",\"Snowflake: Scaling GNNs to high-dimensional continuous control via parameter freezing\",\"On Provable Benefits of Depth in Training Graph Convolutional Networks\",\"Structure-Aware Random Fourier Kernel for Graphs\",\"Contrastive Graph Poisson Networks: Semi-Supervised Learning with Extremely Limited Labels\",\"MagNet: A Neural Network for Directed Graphs\",\"Graph Neural Networks with Local Graph  Parameters\",\"Dissecting the Diffusion Process in Linear Graph Convolutional Networks\",\"Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data\",\"InfoGCL: Information-Aware Graph Contrastive Learning\",\"Streaming Belief Propagation for Community Detection\",\"Representation Learning on Spatial Networks\",\"Graph Adversarial Self-Supervised Learning\",\"Adversarial Graph Augmentation to Improve Graph Contrastive Learning\",\"Partition and Code: learning how to compress graphs\",\"Slow Learning and Fast Inference: Efficient Graph Similarity Computation via Knowledge Distillation\",\"Decoupling the Depth and Scope of Graph Neural Networks\",\"Correlated Stochastic Block Models: Exact Graph Matching with Applications to Recovering Communities\",\"On the Universality of Graph Neural Networks on Large Random Graphs\",\"Neo-GNNs: Neighborhood Overlap-aware Graph Neural Networks for Link Prediction\",\"Node Dependent Local Smoothing for Scalable Graph Learning\",\"A Convergence Analysis of Gradient Descent on Graph Neural Networks\",\"Robustness of Graph Neural Networks at Scale\",\"Diverse Message Passing for Attribute with Heterophily\",\"Hypergraph Propagation and Community Selection for Objects Retrieval\",\"Robust Counterfactual Explanations on Graph Neural Networks\",\"Efficient and Local Parallel Random Walks\",\"Do Transformers Really Perform Badly for Graph Representation?\",\"Topological Relational Learning on Graphs\",\"Multi-view Contrastive Graph Clustering\",\"Subgroup Generalization and Fairness of Graph Neural Networks\",\"Finding Bipartite Components in Hypergraphs\",\"Reinforcement Learning Enhanced Explainer for Graph Neural Networks\",\"Graph Neural Networks with Adaptive Residual\",\"Deconvolutional Networks on Graph Data\",\"KS-GNN: Keywords Search over Incomplete Graphs via Graphs Neural Network\",\"Data driven semi-supervised learning\",\"Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs\",\"Rethinking Graph Transformers with Spectral Attention\",\"Graph Posterior Network: Bayesian Predictive Uncertainty for Node Classification\",\"Labeling Trick: A Theory of Using Graph Neural Networks for Multi-Node Representation Learning\",\"AutoGEL: An Automated Graph Neural Network with Explicit Link Information\",\"BernNet: Learning Arbitrary Graph Spectral Filters via Bernstein Approximation\",\"Adversarial Attacks on Graph Classifiers via Bayesian Optimisation\",\"Reconstruction for Powerful Graph Representations\",\"Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach\",\"Sharp Impossibility Results for Hyper-graph Testing\",\"The decomposition of the higher-order homology embedding constructed from the $k$-Laplacian\",\"Learning Graph Cellular Automata\",\"Disentangled Contrastive Learning on Graphs\",\"Neural Trees for Learning on Graphs\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"1_graph_gnns_graphs\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"1_graph_gnns_graphs\"],\"textfont\":{\"size\":12},\"x\":[1.9082597494125366,1.6186310052871704,1.549123764038086,1.4950305223464966,1.91273033618927,2.0990960597991943,1.797146201133728,1.5560247898101807,1.9552271366119385,1.7096197605133057,1.391457200050354,2.1633782386779785,1.7769964933395386,1.781079888343811,1.4394316673278809,1.962704062461853,1.762809157371521,1.4153584241867065,1.4422632455825806,1.9940166473388672,1.6409714221954346,2.1587352752685547,1.642408847808838,1.5436127185821533,1.5284489393234253,1.6075853109359741,1.6178247928619385,1.9367237091064453,1.7162926197052002,1.5585424900054932,1.9374334812164307,2.079228639602661,1.4257608652114868,2.219529151916504,1.7597976922988892,1.5918822288513184,1.4647642374038696,1.601632833480835,1.7330403327941895,1.5351011753082275,1.7668848037719727,1.97421395778656,1.5298384428024292,1.5981913805007935,1.5771111249923706,1.5004421472549438,1.4727795124053955,2.0233612060546875,1.6527336835861206,2.2632076740264893,1.6288927793502808,1.6951686143875122,2.241288900375366,1.763320803642273,1.633698582649231,1.6314570903778076,1.5643017292022705,1.8344831466674805,1.7526826858520508,2.1775920391082764,1.480453372001648,1.7248493432998657,1.753648042678833,1.610859990119934,1.476660966873169,1.6984628438949585,1.9866780042648315,1.756145715713501,1.726723074913025,1.7794480323791504,1.7776941061019897,1.902093768119812,1.6013206243515015,2.242098808288574,1.8826667070388794,1.9770864248275757,1.446962833404541,1.6939976215362549,1.7535041570663452,1.8881698846817017,2.23946213722229,1.6326451301574707,1.7594692707061768,1.5839126110076904,1.439828872680664,2.0599372386932373,2.245638847351074,1.4503530263900757,2.0348000526428223,1.5442982912063599,1.480766773223877,1.6566078662872314,1.924933671951294,1.581464171409607,1.5073978900909424,2.2294180393218994,2.0778234004974365,1.4654314517974854,1.7859892845153809,1.6490769386291504,1.7482014894485474],\"y\":[2.449221134185791,2.5212690830230713,2.438957691192627,2.463364362716675,2.4676504135131836,2.366476535797119,2.499788761138916,2.464507579803467,2.4020133018493652,2.296349287033081,2.668517589569092,2.3392555713653564,2.2464230060577393,2.547039747238159,2.6181294918060303,2.3665452003479004,2.9744114875793457,2.6347317695617676,2.6247382164001465,2.191476821899414,2.435432195663452,2.3585968017578125,2.4150760173797607,2.5979084968566895,2.596876382827759,2.4518473148345947,2.4888105392456055,2.509124517440796,2.4055542945861816,2.4540300369262695,2.168346405029297,2.41420578956604,2.5158567428588867,2.392080068588257,2.452789306640625,2.774941921234131,2.5991628170013428,2.4733054637908936,2.9982340335845947,2.679042100906372,2.5929019451141357,2.851450204849243,2.4952392578125,2.429582357406616,2.586291551589966,2.578113317489624,2.6097285747528076,2.3785901069641113,2.798927068710327,2.2245543003082275,2.4355568885803223,2.431091547012329,2.463945150375366,2.877105951309204,2.444110631942749,2.408008575439453,2.459768533706665,2.5422842502593994,2.9783666133880615,2.204555034637451,2.725813388824463,2.5684423446655273,2.6055266857147217,2.4776289463043213,2.550121545791626,2.350024938583374,2.227931022644043,2.283771276473999,2.3983254432678223,2.413921594619751,2.4846889972686768,2.5429482460021973,2.5085692405700684,2.2419300079345703,2.6781036853790283,2.3438949584960938,2.619366407394409,2.4372780323028564,2.9849853515625,2.4201812744140625,2.2332210540771484,2.580991506576538,2.5146915912628174,2.4954233169555664,2.5833077430725098,2.403754711151123,2.2798855304718018,2.5956785678863525,2.4758691787719727,2.544154405593872,2.4712586402893066,2.4626879692077637,2.524622678756714,2.459409236907959,2.652548313140869,2.250678300857544,2.8268165588378906,2.508837938308716,3.0684046745300293,2.3669967651367188,2.5071496963500977],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Disrupting Deep Uncertainty Estimation Without Harming Accuracy\",\"On the Existence of The Adversarial Bayes Classifier\",\"Towards Better Understanding of Training Certifiably Robust Models against Adversarial Examples\",\"Shift Invariance Can Reduce Adversarial Robustness\",\"Adversarial Training Helps Transfer Learning via Better Representations\",\"Improving Calibration through the Relationship with Adversarial Robustness\",\"Unadversarial Examples: Designing Objects for Robust Vision\",\"Clustering Effect of Adversarial Robust Models\",\"Random Noise Defense Against Query-Based Black-Box Attacks\",\"On the Algorithmic Stability of Adversarial Training\",\"Exponential Separation between Two Learning Models and Adversarial Robustness\",\"Evaluating model performance under worst-case subpopulations\",\"Adversarially Robust Change Point Detection\",\"Manipulating SGD with Data Ordering Attacks\",\"Robustness between the worst and average case\",\"Gradient-Free Adversarial Training Against Image Corruption for Learning-based Steering\",\"Meta-Learning the Search Distribution of Black-Box Random Search Based Adversarial Attacks\",\"Do Wider Neural Networks Really Help Adversarial Robustness?\",\"Topological Detection of Trojaned Neural Networks\",\"Neural Architecture Dilation for Adversarial Robustness\",\"On Success and Simplicity: A Second Look at Transferable Targeted Attacks\",\"Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks\",\"Data Augmentation Can Improve Robustness\",\"Revisiting Hilbert-Schmidt Information Bottleneck for Adversarial Robustness\",\"Adversarial Feature Desensitization\",\"Towards a Unified Game-Theoretic View of Adversarial Perturbations and Robustness\",\"Relaxing Local Robustness\",\"Adversarial Examples Make Strong Poisons\",\"Class-Disentanglement and Applications in Adversarial Detection and Defense\",\"A Little Robustness Goes a Long Way: Leveraging Robust Features for Targeted Transfer Attacks\",\"Anti-Backdoor Learning: Training Clean Models on Poisoned Data\",\"Backdoor Attack with Imperceptible Input and Latent Modification\",\"Probabilistic Margins for Instance Reweighting in Adversarial Training\",\"MixACM: Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps\",\"Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks\",\"Distilling Robust and Non-Robust Features in Adversarial Examples by Information Bottleneck\",\"Fair Classification with Adversarial Perturbations\",\"Adversarial Robustness without Adversarial Training: A Teacher-Guided Curriculum Learning Approach\",\"The Many Faces of Adversarial Risk\",\"Adversarial Robustness of Streaming Algorithms through Importance Sampling\",\"Mori\\u00e9 Attack (MA): A New Potential Risk of Screen Photos\",\"Adversarial Attacks on Black Box Video Classifiers: Leveraging the Power of Geometric Transformations\",\"Towards Efficient and Effective Adversarial Training\",\"Drawing Robust Scratch Tickets: Subnetworks with Inborn Robustness Are Found within Randomly Initialized Networks\",\"Stable Neural ODE with Lyapunov-Stable Equilibrium Points for Defending Against Adversarial Attacks\",\"Adversarial Examples for k-Nearest Neighbor Classifiers Based on Higher-Order Voronoi Diagrams\",\"Adversarial Robustness with Semi-Infinite Constrained Learning\",\"Finding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks\",\"Adversarial Attack Generation Empowered by Min-Max Optimization\",\"Learning Transferable Adversarial Perturbations\",\"Adversarial Robustness with Non-uniform Perturbations\",\"How does a Neural Network's Architecture Impact its Robustness to Noisy Labels?\",\"A Separation Result Between Data-oblivious and Data-aware Poisoning Attacks\",\"Center Smoothing: Certified Robustness for Networks with Structured Outputs\",\"ReLU Regression with Massart Noise\",\"RoMA: Robust Model Adaptation for Offline Model-based Optimization\",\"BulletTrain: Accelerating Robust Neural Network Training via Boundary Example Mining\",\"Efficient Statistical Assessment of Neural Network Corruption Robustness\",\"TRS: Transferability Reduced Ensemble via Promoting Gradient Diversity and Model Smoothness\",\"Adversarially robust learning for security-constrained optimal power flow\",\"Automated Discovery of Adaptive Attacks on Adversarial Defenses\",\"Better Safe Than Sorry: Preventing Delusive Adversaries with Adversarial Training\",\"Adversarial Neuron Pruning Purifies Backdoored Deep Models\",\"Qu-ANTI-zation: Exploiting Quantization Artifacts for Achieving Adversarial Outcomes\",\"SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness\",\"Adversarial Regression with Doubly Non-negative Weighting Matrices\",\"Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints\",\"ScaleCert: Scalable Certified Defense against Adversarial Patches with Sparse Superficial Layers\",\"A PAC-Bayes Analysis of Adversarial Robustness\",\"Neural Population Geometry Reveals the Role of Stochasticity in Robust Perception\",\"Formalizing Generalization and Adversarial Robustness of Neural Networks to Weight Perturbations\",\"Calibration and Consistency of Adversarial Surrogate Losses\",\"Variational Model Inversion Attacks\",\"Excess Capacity and Backdoor Poisoning\",\"Accumulative Poisoning Attacks on Real-time Data\",\"Consistent Non-Parametric Methods for Maximizing Robustness\",\"Improving Robustness using Generated Data\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"2_adversarial_robustness_attacks\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"2_adversarial_robustness_attacks\"],\"textfont\":{\"size\":12},\"x\":[4.627467155456543,4.944485664367676,4.869174957275391,4.69708776473999,4.3191680908203125,4.867515563964844,4.484776496887207,4.655294895172119,4.725086688995361,4.836606979370117,4.927734375,4.9209465980529785,4.786957740783691,4.792983531951904,4.933009624481201,4.483432292938232,4.723743915557861,4.738288879394531,4.641453742980957,4.585549354553223,4.484197616577148,4.604284286499023,4.612705230712891,4.653776168823242,4.690027236938477,4.720914840698242,4.912953853607178,4.772207736968994,4.764719009399414,4.465388774871826,4.765316486358643,4.788853645324707,4.929882049560547,4.411003112792969,4.6337785720825195,4.683825492858887,4.932149887084961,4.561077117919922,4.94758415222168,4.731888771057129,4.597063064575195,4.769603252410889,4.649632453918457,4.613059997558594,4.6798224449157715,4.823504447937012,4.926944732666016,4.8243021965026855,4.727322578430176,4.481359958648682,4.7344231605529785,4.713258266448975,4.773171424865723,4.863537311553955,5.015630722045898,4.677649021148682,4.716166973114014,4.8627729415893555,4.519495010375977,4.821653842926025,4.734206199645996,4.762639045715332,4.765890121459961,4.568594932556152,4.864701271057129,4.990664958953857,4.803413391113281,4.568662166595459,4.901072978973389,4.604870319366455,4.777024269104004,4.9459967613220215,4.676492691040039,4.80684232711792,4.815128803253174,4.941256523132324,4.814171314239502,4.737133979797363],\"y\":[2.233074426651001,2.3801186084747314,2.387269973754883,2.086714029312134,2.4735708236694336,2.330801248550415,2.2309844493865967,2.1903553009033203,2.1060996055603027,2.2927048206329346,2.2557482719421387,2.4009170532226562,2.0777947902679443,2.0111351013183594,2.4098432064056396,2.236614465713501,2.082505226135254,2.312351942062378,2.057603359222412,2.1942057609558105,2.3078970909118652,2.2790586948394775,2.28004789352417,2.2339634895324707,2.114393949508667,2.178779363632202,2.423901319503784,2.066560983657837,2.130110025405884,2.2797484397888184,2.0428528785705566,2.0443334579467773,2.3444230556488037,2.380401849746704,2.186600923538208,2.1857495307922363,2.4122235774993896,2.1621100902557373,2.389023542404175,2.2445313930511475,2.175248861312866,2.049414873123169,2.2156617641448975,2.1682379245758057,2.17207932472229,2.301276445388794,2.403132438659668,2.209683656692505,2.171396493911743,2.3208582401275635,2.164369821548462,3.0569252967834473,2.009122371673584,2.384272813796997,2.39795184135437,2.618471384048462,2.325021266937256,2.5085182189941406,2.3232481479644775,2.275367498397827,2.1194729804992676,2.101769208908081,2.0760862827301025,2.19730544090271,2.3709030151367188,2.390350341796875,2.283384084701538,2.1435394287109375,2.302358388900757,2.2326555252075195,2.289046049118042,2.401263475418091,2.1610820293426514,2.037938356399536,2.0275659561157227,2.4088211059570312,2.365011692047119,2.2544925212860107],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"T\\u00f6RF: Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis\",\"Interpreting Representation Quality of DNNs for 3D Point Cloud Processing\",\"Coarse-to-fine Animal Pose and Shape Estimation\",\"CoFiNet: Reliable Coarse-to-fine Correspondences for Robust PointCloud Registration\",\"Fast Training of Neural Lumigraph Representations using Meta Learning\",\"3D Pose Transfer with Correspondence Learning and Mesh Refinement\",\"Multimodal Virtual Point 3D Detection\",\"DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras\",\"Accurate Point Cloud Registration with Robust Optimal Transport\",\"Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving Objects\",\"To The Point: Correspondence-driven monocular 3D category reconstruction\",\"Test-Time Personalization with a Transformer for Human Pose Estimation\",\"NeRS: Neural Reflectance Surfaces for Sparse-view 3D Reconstruction in the Wild\",\"Non-local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation\",\"Extracting Deformation-Aware Local Features by Learning to Deform\",\"Progressive Coordinate Transforms for Monocular 3D Object Detection\",\"Shape As Points: A Differentiable Poisson Solver\",\"Direct Multi-view Multi-person 3D  Pose Estimation\",\"Canonical Capsules: Self-Supervised Capsules in Canonical Pose\",\"Learning Transferable Features for Point Cloud Detection via 3D Contrastive Co-training\",\"Dynamics-regulated kinematic policy for egocentric pose estimation\",\"Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition\",\"A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose\",\"ASSANet: An Anisotropic Separable Set Abstraction for Efficient Point Cloud Representation Learning\",\"Balanced Chamfer Distance as a Comprehensive Metric for Point Cloud Completion\",\"Geometry Processing with Neural Fields\",\"Leveraging SE(3) Equivariance for Self-supervised Category-Level Object  Pose Estimation from Point Clouds\",\"Spot the Difference: Detection of Topological Changes via Geometric Alignment\",\"TransformerFusion: Monocular RGB Scene Reconstruction using Transformers\",\"Generative Occupancy Fields for 3D Surface-Aware Image Synthesis\",\"ViSER: Video-Specific Surface Embeddings for Articulated 3D Shape Reconstruction\",\"Voxel-based 3D Detection and Reconstruction of Multiple Objects from a Single Image\",\"Robust Pose Estimation in Crowded Scenes with Direct Pose-Level Inference\",\"Volume Rendering of Neural Implicit Surfaces\",\"Class-agnostic Reconstruction of Dynamic Objects from Videos\",\"Learning to dehaze with polarization\",\"H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion\",\"Adversarially Robust 3D Point Cloud Recognition Using Self-Supervisions\",\"Unsupervised Object-Based Transition Models For 3D Partially Observable Environments\",\"Dense Keypoints via Multiview Supervision\",\"3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds\",\"Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering\",\"Aligning Silhouette Topology for Self-Adaptive 3D Human Pose Recovery\",\"Capturing implicit hierarchical structure in 3D biomedical images with self-supervised hyperbolic representations\",\"ATISS: Autoregressive Transformers for Indoor Scene Synthesis\",\"REMIPS: Physically Consistent 3D Reconstruction of Multiple Interacting People under Weak Supervision\",\"Shape Registration in the Time of Transformers\",\"Multi-Person 3D Motion Prediction with Multi-Range Transformers\",\"3DP3: 3D Scene Perception via Probabilistic Programming\",\"Neural View Synthesis and Matching for Semi-Supervised Few-Shot Learning of 3D Pose\",\"Learning 3D Dense Correspondence via Canonical Point Autoencoder\",\"NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction\",\"CorticalFlow: A Diffeomorphic Mesh Transformer Network for Cortical Surface Reconstruction\",\"DIB-R++: Learning to Predict Lighting and Material with a Hybrid Differentiable Renderer\",\"Neural Relightable Participating Media Rendering\",\"MetaAvatar: Learning Animatable Clothed Human Models from Few Depth Images\",\"Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis\",\"Sparse Steerable Convolutions: An Efficient Learning of SE(3)-Equivariant Features for Estimation and Tracking of Object Poses in 3D Space\",\"Revisiting 3D Object Detection From an Egocentric Perspective\",\"Tracking People with 3D Representations\",\"Neural Human Performer: Learning Generalizable Radiance Fields for Human Performance Rendering\",\"Active 3D Shape Reconstruction from Vision and Touch\",\"Object DGCNN: 3D Object Detection using Dynamic Graphs\",\"A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware Image Synthesis\",\"Differentiable rendering with perturbed optimizers\",\"OctField: Hierarchical Implicit Functions for 3D Modeling\",\"Garment4D: Garment Reconstruction from Point Cloud Sequences\",\"PolarStream: Streaming Object Detection and Segmentation with Polar Pillars\",\"Panoptic 3D Scene Reconstruction From a Single RGB Image\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"3_3d_pose_reconstruction\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"3_3d_pose_reconstruction\"],\"textfont\":{\"size\":12},\"x\":[0.18823352456092834,-0.04411764070391655,0.2702568471431732,-0.004529215395450592,0.6208394765853882,0.2236759513616562,-0.03243580833077431,0.14420218765735626,0.09609571099281311,0.19583386182785034,0.12623098492622375,0.2843799591064453,0.5848686695098877,0.1962762027978897,0.07919562608003616,-3.0223469366319478e-05,0.49652743339538574,0.24066299200057983,-0.01470910757780075,-0.03503997623920441,0.2420801818370819,0.5937192440032959,0.2558813691139221,-0.03901781141757965,0.011260803788900375,0.6637850403785706,0.05361483246088028,0.7574770450592041,0.15787386894226074,0.5942301750183105,0.16353482007980347,0.07044409215450287,0.28748196363449097,0.5877587199211121,0.16551624238491058,0.6138297915458679,0.2366912066936493,-0.04951567202806473,0.303278386592865,0.0837981253862381,0.00014239500160329044,0.5877163410186768,0.2448875904083252,0.6519076824188232,1.8286383152008057,0.255994975566864,0.04069899767637253,0.33718857169151306,0.18171599507331848,0.09311733394861221,-0.0031666092108935118,0.5897929668426514,0.6333860158920288,0.5765036344528198,0.5896968841552734,0.2550773620605469,0.5813441872596741,0.11777598410844803,0.044905178248882294,0.291709303855896,0.30625444650650024,0.4437621235847473,-0.045204631984233856,0.5672484636306763,0.5790419578552246,0.5725685358047485,0.23960931599140167,-0.10304055362939835,0.1353372484445572,0.2893442213535309],\"y\":[7.136591911315918,7.241354465484619,7.186314105987549,7.269770622253418,7.588041305541992,7.129814147949219,7.231273174285889,7.131678104400635,7.261255741119385,7.151464939117432,7.1583333015441895,6.973325729370117,7.566598415374756,7.0329084396362305,7.1965179443359375,7.210423469543457,7.446264743804932,7.0134501457214355,7.213092803955078,7.2571539878845215,7.04005765914917,7.582630634307861,7.074512004852295,7.243595123291016,7.247921943664551,7.450910568237305,7.182931423187256,7.381432056427002,7.120439529418945,7.59112024307251,7.123175144195557,7.182348251342773,6.979330539703369,7.553504943847656,7.139278888702393,7.581035614013672,7.1078033447265625,7.23823881149292,6.9932966232299805,7.186175346374512,7.234585285186768,7.589540004730225,7.066005229949951,7.449301242828369,7.130316257476807,7.056802272796631,7.274995803833008,6.966353416442871,7.105916976928711,7.175232410430908,7.268126964569092,7.53728723526001,7.469719409942627,7.596725940704346,7.5930585861206055,7.094120025634766,7.507023334503174,7.126978397369385,7.185366153717041,7.004589557647705,6.9767985343933105,7.385469913482666,7.208468437194824,7.578887939453125,7.5555806159973145,7.50634765625,7.134282112121582,7.288298606872559,7.143744945526123,7.255148887634277],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Beyond BatchNorm: Towards a Unified Understanding of Normalization in Deep Learning\",\"Does Preprocessing Help Training Over-parameterized Neural Networks?\",\"Deep Networks Provably Classify Data on Curves\",\"A single gradient step finds adversarial examples on random two-layers neural networks\",\"The staircase property: How hierarchical structure can guide deep learning\",\"On the Expected Complexity of Maxout Networks\",\"Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity\",\"On the Variance of the Fisher Information for Deep Learning\",\"On the Representation Power of Set Pooling Networks\",\"Spherical Motion Dynamics: Learning Dynamics of Normalized Neural Network using SGD and Weight Decay\",\"Gradient Descent on Two-layer Nets: Margin Maximization and Simplicity Bias\",\"Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space\",\"Imitating Deep Learning Dynamics via  Locally Elastic Stochastic Differential Equations\",\"Relative stability toward diffeomorphisms indicates performance in deep nets\",\"Noether\\u2019s Learning Dynamics: Role of Symmetry Breaking in Neural Networks\",\"$(\\\\textrm{Implicit})^2$: Implicit Layers for Implicit Representations\",\"On the Periodic Behavior of Neural Network Training with Batch Normalization and Weight Decay\",\"Limiting fluctuation and trajectorial stability of multilayer neural networks with mean field training\",\"Stability & Generalisation of Gradient Descent for Shallow Neural Networks without the Neural Tangent Kernel\",\"An Exponential Improvement on the Memorization Capacity of Deep Threshold Networks\",\"Representation Learning Beyond Linear Prediction Functions\",\"Gradient Starvation: A Learning Proclivity in Neural Networks\",\"Towards Lower Bounds on the Depth of ReLU Neural Networks\",\"Network-to-Network Regularization: Enforcing Occam's Razor to Improve Generalization\",\"Batch Normalization Orthogonalizes Representations in Deep Random Networks\",\"Learning a Single Neuron with Bias Using Gradient Descent\",\"CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions\",\"Continuous vs. Discrete Optimization of Deep Neural Networks\",\"Analysis of one-hidden-layer neural networks via the resolvent method\",\"Measuring Generalization with Optimal Transport\",\"Embedding Principle of Loss Landscape of Deep Neural Networks\",\"Faster Directional Convergence of Linear Neural Networks under Spherically Symmetric Data\",\"Early-stopped neural networks are consistent\",\"Explicit loss asymptotics in the gradient descent training of neural networks\",\"When Expressivity Meets Trainability: Fewer than $n$ Neurons Can Work\",\"On the Cryptographic Hardness of Learning Single Periodic Neurons\",\"Subquadratic Overparameterization for Shallow Neural Networks\",\"Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks: A Tale of Symmetry II\",\"On the Equivalence between Neural Network and Support Vector Machine\",\"Training Neural Networks is ER-complete\",\"Robust Implicit Networks via Non-Euclidean Contractions\",\"On Training Implicit Models\",\"Adversarial Examples in Multi-Layer Random ReLU Networks\",\"Differentiable Spline Approximations\",\"Analytic Insights into Structure and Rank of Neural Network Hessian Maps\",\"The Implicit Bias of Minima Stability: A View from Function Space\",\"A Geometric Analysis of Neural Collapse with Unconstrained Features\",\"Fractal Structure and Generalization Properties of Stochastic Optimization Algorithms\",\"What can linearized neural networks actually say about generalization?\",\"Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Neural Network Robustness Verification\",\"On the Provable Generalization of Recurrent Neural Networks\",\"Regularization in ResNet with Stochastic Depth\",\"Convergence and Alignment of Gradient Descent with Random Backpropagation Weights\",\"Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence\",\"Efficiently Learning One Hidden Layer ReLU Networks From Queries\",\"Model, sample, and epoch-wise descents: exact solution of gradient flow in the random feature model\",\"Numerical influence of ReLU\\u2019(0) on backpropagation\",\"Nonsmooth Implicit Differentiation for Machine-Learning and Optimization\",\"Representation Costs of Linear Neural Networks: Analysis and Design\",\"A Universal Law of Robustness via Isoperimetry\",\"Efficient Algorithms for Learning Depth-2 Neural Networks with General ReLU Activations\",\"On Linear Stability of SGD and Input-Smoothness of Neural Networks\",\"Parametric Complexity Bounds for Approximating PDEs with Neural Networks\",\"When Are Solutions Connected in Deep Networks?\",\"Intrinsic Dimension, Persistent Homology and Generalization in Neural Networks\",\"What training reveals about neural network complexity\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"4_networks_neural_neural networks\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"4_networks_neural_neural networks\"],\"textfont\":{\"size\":12},\"x\":[4.5708842277526855,5.176290035247803,4.751432418823242,4.899293899536133,4.777162075042725,4.945036888122559,5.0822577476501465,5.056582927703857,4.582616806030273,4.683023452758789,4.832042217254639,4.989717960357666,4.989213466644287,4.751372814178467,4.63606071472168,4.211744785308838,4.586996078491211,5.152592182159424,5.174015045166016,4.970796585083008,4.70010232925415,4.730163097381592,4.7118353843688965,5.112128734588623,4.83997917175293,4.8320746421813965,4.5291056632995605,4.818990707397461,4.992223262786865,5.071516990661621,4.781207084655762,4.790064811706543,4.737669944763184,5.055925369262695,4.830990314483643,4.917922496795654,4.987466335296631,4.874690055847168,4.908415794372559,4.855682373046875,4.309650421142578,4.29398775100708,4.860494136810303,4.316776752471924,4.858703136444092,4.873589992523193,4.778616905212402,4.861382007598877,4.902152061462402,4.173831939697266,4.98445463180542,4.850217342376709,3.943948984146118,4.574190616607666,4.861245632171631,5.091588497161865,4.6914567947387695,4.377653121948242,4.587696075439453,5.339564323425293,4.887609481811523,4.932921886444092,4.67691707611084,4.842345714569092,4.7400126457214355,4.969802379608154,4.7951226234436035],\"y\":[5.231447219848633,4.856237888336182,5.071018218994141,5.076491355895996,5.13702392578125,5.078227519989014,5.281705856323242,5.113366603851318,5.186125755310059,5.192703723907471,5.0615410804748535,5.117561340332031,5.264898300170898,5.24369478225708,5.233119010925293,5.187661647796631,5.216693878173828,5.310647964477539,5.027697563171387,5.203497886657715,4.944155693054199,4.846906661987305,5.150070667266846,5.06831169128418,5.288963317871094,5.237728118896484,5.156949043273926,5.215935230255127,5.218448162078857,4.9880475997924805,4.937664985656738,5.092494010925293,4.931317329406738,5.194879531860352,5.031769752502441,5.1841959953308105,5.081971168518066,5.099654674530029,5.0847954750061035,5.160788059234619,5.117612838745117,5.239206790924072,5.1083807945251465,5.356852054595947,5.050473690032959,5.148639678955078,4.889975070953369,5.253317356109619,5.085208892822266,4.890860557556152,5.165463447570801,5.4041337966918945,7.827113628387451,5.206316947937012,5.138345718383789,5.2977824211120605,5.036482810974121,5.267807960510254,5.039551734924316,4.920538902282715,5.112998962402344,5.422139644622803,5.504592418670654,5.054234504699707,5.268850326538086,5.133534908294678,5.1810126304626465],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"High Probability Complexity Bounds for Line Search Based on Stochastic Oracles\",\"Submodular + Concave\",\"Exploiting Local Convergence of Quasi-Newton Methods Globally: Adaptive Sample Size Approach\",\"Can we globally optimize cross-validation loss? Quasiconvexity in ridge regression\",\"Information-constrained optimization: can adaptive processing of gradients help?\",\"An Online Method for A Class of Distributionally Robust Optimization with Non-convex Objectives\",\"Cardinality constrained submodular maximization for random streams\",\"Sifting through the noise: Universal first-order methods for stochastic variational inequalities\",\"Distributed Estimation with Multiple Samples per User: Sharp Rates and Phase Transition\",\"A Stochastic Newton Algorithm for Distributed Convex Optimization\",\"Multiple Descent: Design Your Own Generalization Curve\",\"High-probability Bounds for Non-Convex Stochastic Optimization with Heavy Tails\",\"Near-Optimal Lower Bounds For Convex Optimization For All Orders of Smoothness\",\"Three Operator Splitting with Subgradients, Stochastic Gradients, and Adaptive Learning Rates\",\"On the Bias-Variance-Cost Tradeoff of Stochastic Optimization\",\"Mixture weights optimisation for Alpha-Divergence Variational Inference\",\"Minibatch and Momentum Model-based Methods for Stochastic Weakly Convex Optimization\",\"Proxy Convexity: A Unified Framework for the Analysis of Neural Networks Trained by Gradient Descent\",\"Linear Convergence of Gradient Methods for Estimating Structured Transition Matrices in High-dimensional Vector Autoregressive Models\",\"A first-order primal-dual method with adaptivity to local smoothness\",\"Stochastic $L^\\\\natural$-convex Function Minimization\",\"Automatic and Harmless  Regularization  with Constrained and Lexicographic Optimization: A Dynamic Barrier Approach\",\"Stochastic Bias-Reduced Gradient Methods\",\"Analytical Study of Momentum-Based Acceleration Methods in Paradigmatic High-Dimensional Non-Convex Problems\",\"Convergence of adaptive algorithms for constrained weakly convex optimization\",\"Last iterate convergence of SGD for Least-Squares in the Interpolation regime.\",\"STORM+: Fully Adaptive SGD with Recursive Momentum for Nonconvex Optimization\",\"Momentum Centering and Asynchronous Update for Adaptive Gradient Methods\",\"An Analysis of Constant Step Size SGD in the Non-convex Regime: Asymptotic Normality and Bias\",\"The Benefits of Implicit Regularization from SGD in Least Squares Problems\",\"Label Noise SGD Provably Prefers Flat Global Minimizers\",\"On the Role of Optimization in Double Descent: A Least Squares Study\",\"Adaptive First-Order Methods Revisited: Convex Minimization without Lipschitz Requirements\",\"Closing the Gap: Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems\",\"Adaptive Proximal Gradient Methods for Structured Neural Networks\",\"Heavy Ball Momentum for Conditional Gradient\",\"Towards Gradient-based Bilevel Optimization with Non-convex Followers and Beyond\",\"Towards Understanding Why Lookahead Generalizes Better Than SGD and Beyond\",\"On the Second-order Convergence Properties of Random Search Methods\",\"Never Go Full Batch (in Stochastic Convex Optimization)\",\"An Even More Optimal Stochastic Optimization Algorithm: Minibatching and Interpolation Learning\",\"Beyond Tikhonov: faster learning with self-concordant losses, via iterative regularization\",\"Efficient Mirror Descent Ascent Methods for Nonsmooth Minimax Problems\",\"Tight High Probability Bounds for Linear Stochastic Approximation with Fixed Stepsize\",\"A Gradient Method for Multilevel Optimization\",\"Oracle Complexity in Nonsmooth Nonconvex Optimization\",\"On the Convergence of Step Decay Step-Size for Stochastic Optimization\",\"A Near-Optimal Algorithm for Stochastic Bilevel Optimization via Double-Momentum\",\"Implicit Sparse Regularization: The Impact of Depth and Early Stopping\",\"Non-convex Distributionally Robust Optimization: Non-asymptotic Analysis\",\"Algorithmic Instabilities of Accelerated Gradient Descent\",\"SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients\",\"Random Shuffling Beats SGD Only After Many Epochs on Ill-Conditioned Problems\",\"Fast Extra Gradient Methods for Smooth Structured Nonconvex-Nonconcave Minimax Problems\",\"Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance\",\"On Optimal Interpolation in Linear Regression\",\"A Geometric Structure of Acceleration and Its Role in Making Gradients Small Fast\",\"Rethinking the Variational Interpretation of Accelerated Optimization Methods\",\"On the Power of Differentiable Learning versus PAC and SQ Learning\",\"Dynamics of Stochastic Momentum Methods on Large-scale, Quadratic Models\",\"How Data Augmentation affects Optimization for Linear Regression\",\"Greedy and Random Quasi-Newton Methods with Faster Explicit Superlinear Convergence\",\"Stability and Generalization of Bilevel Programming in Hyperparameter Optimization\",\"An Improved Analysis and Rates for Variance Reduction under Without-replacement Sampling Orders \",\"Provably Faster Algorithms for Bilevel Optimization\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"5_stochastic_gradient_optimization\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"5_stochastic_gradient_optimization\"],\"textfont\":{\"size\":12},\"x\":[7.475703716278076,7.50456428527832,7.1371235847473145,6.534539222717285,7.595311164855957,6.804623603820801,7.730898380279541,7.471795558929443,7.88287878036499,7.234872817993164,6.460463523864746,7.243000507354736,7.7127509117126465,7.2914581298828125,7.104661464691162,7.566399574279785,7.243451118469238,6.989306449890137,7.08828592300415,7.4177374839782715,7.437501430511475,6.638625144958496,7.300017833709717,7.239615440368652,7.297338962554932,7.093902587890625,7.2991228103637695,7.365152359008789,7.107594013214111,6.5226616859436035,6.543597221374512,6.506107330322266,7.38408899307251,7.0233025550842285,6.925788879394531,7.286564350128174,7.220334529876709,6.963434219360352,7.50875997543335,7.160240650177002,7.20908784866333,6.771404266357422,7.488511085510254,7.357157230377197,7.070592880249023,7.558002471923828,7.071659088134766,7.163626194000244,6.489177227020264,7.170675754547119,7.394339561462402,7.315929889678955,7.435292720794678,7.409063816070557,7.285384654998779,6.290069580078125,7.38407564163208,7.30109977722168,6.781547546386719,7.222362041473389,6.610074996948242,7.30830717086792,6.986907958984375,7.3043622970581055,7.001633167266846,7.164522171020508],\"y\":[4.77598762512207,4.53971529006958,4.599416255950928,4.3585524559021,4.606527328491211,4.60336446762085,4.459288597106934,4.666288375854492,4.554502964019775,4.6915178298950195,4.3596906661987305,4.827824592590332,4.442811012268066,4.706930160522461,4.692478179931641,4.574985027313232,4.756067276000977,4.6975626945495605,4.662045955657959,4.5484514236450195,4.651340961456299,4.45138692855835,4.768924236297607,4.677276134490967,4.767627239227295,4.67038106918335,4.783880710601807,4.7483625411987305,4.721159934997559,4.380923271179199,4.428716659545898,4.410802364349365,4.686258792877197,4.614042282104492,4.685042381286621,4.73252534866333,4.652626991271973,4.699746608734131,4.7909345626831055,4.744711875915527,4.733310699462891,4.5325212478637695,4.613786697387695,4.422684192657471,4.598862648010254,4.506438732147217,4.794719696044922,4.675838470458984,4.389895439147949,4.715699195861816,4.610842704772949,4.651973724365234,4.723166465759277,4.502662658691406,4.791281223297119,4.332943916320801,4.57668924331665,4.643550872802734,5.152037143707275,4.753356456756592,4.580382347106934,4.687019348144531,4.611375331878662,4.865353107452393,4.592031002044678,4.634601593017578],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Multi-Facet Clustering Variational Autoencoders\",\"Collapsed Variational Bounds for Bayesian Neural Networks\",\"A Contrastive Learning Approach for Training Variational Autoencoder Priors\",\"E(n) Equivariant Normalizing Flows\",\"Pseudo-Spherical Contrastive Divergence\",\"Shape your Space: A Gaussian Mixture Regularization Approach to Deterministic Autoencoders\",\"Moser Flow: Divergence-based Generative Modeling on Manifolds\",\"Arbitrary Conditional Distributions with Energy\",\"ByPE-VAE: Bayesian Pseudocoresets Exemplar VAE\",\"A generative nonparametric Bayesian model for whole genomes\",\"Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation\",\"Loss function based second-order Jensen inequality and its application to particle variational inference\",\"Amortized Variational Inference for Simple Hierarchical Models\",\"Manifold Topology Divergence: a Framework for Comparing Data Manifolds. \",\"A Variational Perspective on Diffusion-Based Generative Models and Score Matching\",\"Statistical Regeneration Guarantees of the Wasserstein Autoencoder with Latent Space Consistency\",\"Time-series Generation by Contrastive Imitation\",\"Exploiting Chain Rule and Bayes' Theorem to Compare Probability Distributions\",\"Densely connected normalizing flows\",\"Tractable Density Estimation on Learned Manifolds with Conformal Embedding Flows\",\"Score-based Generative Modeling in Latent Space\",\"On Memorization in Probabilistic Deep Generative Models\",\"Structured Denoising Diffusion Models in Discrete State-Spaces\",\"Diffusion Schr\\u00f6dinger Bridge with Applications to Score-Based Generative Modeling\",\"Evidential Softmax for Sparse Multimodal Distributions in Deep Generative Models\",\"Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions\",\"Consistency Regularization for Variational Auto-Encoders\",\"Posterior Collapse and Latent Variable Non-identifiability\",\"Denoising Normalizing Flow\",\"Improving black-box optimization in VAE latent space using decoder uncertainty\",\"PLUGIn: A simple algorithm for inverting generative models with recovery guarantees\",\"Score-based Generative Neural Networks for Large-Scale Optimal Transport\",\"On the Generative Utility of Cyclic Conditionals\",\"Physics-Integrated Variational Autoencoders for Robust and Interpretable Generative Modeling\",\"Universal Approximation Using Well-Conditioned Normalizing Flows\",\"Smooth Normalizing Flows\",\"On the Value of Infinite Gradients in Variational Autoencoder Models\",\"Model Selection for Bayesian Autoencoders\",\"Bounds all around: training energy-based models with bidirectional bounds\",\"Divergence Frontiers for Generative Models: Sample Complexity, Quantization Effects, and Frontier Integrals\",\"Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation\",\"Diffusion Normalizing Flow\",\"Bridging Explicit and Implicit Deep Generative Models via Neural Stein Estimators\",\"Trustworthy Multimodal Regression with Mixture of Normal-inverse Gamma Distributions\",\"CARMS: Categorical-Antithetic-REINFORCE Multi-Sample Gradient Estimator\",\"BooVAE: Boosting Approach for Continual Learning of VAE\",\"Deep Conditional Gaussian Mixture Model for Constrained Clustering\",\"Implicit Generative Copulas\",\"Rectangular Flows for Manifold Learning\",\"Challenges and Opportunities in High Dimensional Variational Inference\",\"Understanding Instance-based Interpretability of Variational Auto-Encoders\",\"Identifiable Generative models for Missing Not at Random Data Imputation\",\"Maximum Likelihood Training of Score-Based Diffusion Models\",\"Learning Equivariant Energy Based Models with Equivariant Stein Variational Gradient Descent\",\"Equivariant Manifold Flows\",\"Nested Variational Inference\",\"Variational Diffusion Models\",\"Evaluating State-of-the-Art Classification Models Against Bayes Optimality\",\"Estimating the Unique Information of Continuous Variables\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"6_generative_models_variational\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"6_generative_models_variational\"],\"textfont\":{\"size\":12},\"x\":[4.25402307510376,5.000951766967773,4.054470062255859,4.120020866394043,4.1568450927734375,4.3265061378479,4.149495601654053,4.43937873840332,4.432248592376709,4.5092058181762695,4.7992844581604,5.0091471672058105,4.853813648223877,4.057525634765625,3.713395357131958,3.760636329650879,3.858581304550171,3.8627243041992188,4.167355537414551,4.146583557128906,4.100536823272705,4.131174087524414,3.6829440593719482,3.7955777645111084,4.250332355499268,3.6903979778289795,4.334263801574707,4.398304462432861,4.111340045928955,4.412589073181152,3.795602560043335,3.9316272735595703,4.452311038970947,4.304710865020752,4.240200996398926,4.143640041351318,4.28706693649292,4.426988124847412,3.8659591674804688,3.963620901107788,3.901060104370117,3.77354097366333,4.091657638549805,2.5833137035369873,4.544320106506348,4.269848346710205,4.258833885192871,4.449841022491455,4.124251365661621,4.970174312591553,4.204691410064697,4.487046241760254,3.730231523513794,4.172613620758057,4.128963947296143,4.61766242980957,3.6325175762176514,4.737549304962158,4.368868350982666,4.187090873718262],\"y\":[7.000930309295654,6.185802936553955,6.904600143432617,6.471437454223633,6.724552154541016,6.982205390930176,6.473620891571045,6.929891109466553,6.818479537963867,6.866794586181641,6.566859245300293,6.221890449523926,6.552000999450684,6.672642230987549,6.798352241516113,6.814611911773682,6.857365608215332,6.860725402832031,6.528841972351074,6.4988884925842285,6.896821022033691,6.880938529968262,6.820611953735352,6.8119401931762695,6.825377941131592,6.829989433288574,7.038811683654785,7.009695053100586,6.471428871154785,6.873423099517822,6.723778247833252,6.82697868347168,6.996426582336426,6.888209819793701,6.555410385131836,6.478745937347412,6.969951152801514,6.853167533874512,6.868491172790527,6.813934326171875,6.828423976898193,6.786262035369873,6.816221237182617,6.066422939300537,6.802290439605713,7.04859733581543,6.965866565704346,6.998134613037109,6.5056867599487305,6.418937683105469,6.930009365081787,6.93011999130249,6.808352470397949,6.7468581199646,6.488726615905762,6.67954683303833,6.808919429779053,6.285199165344238,7.117253303527832,6.749092102050781],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Causal Effect Inference for Structured Treatments\",\"For high-dimensional hierarchical models, consider exchangeability of effects across covariates instead of across datasets\",\"Causal Inference for Event Pairs in Multivariate Point Processes\",\"Finding Regions of Heterogeneity in Decision-Making via Expected Conditional Covariance\",\"Dynamic COVID risk assessment accounting for community virus exposure from a spatial-temporal transmission model\",\"Counterfactual Invariance to Spurious Correlations in Text Classification\",\"Recursive Bayesian Networks: Generalising and Unifying Probabilistic Context-Free Grammars and Dynamic Bayesian Networks\",\"Inverse-Weighted Survival Games\",\"Reliable Causal Discovery with Improved Exact Search and Weaker Assumptions\",\"Efficient Online Estimation of Causal Effects by Deciding What to Observe\",\"Identification and Estimation of Joint Probabilities of Potential Outcomes in Observational Studies with Covariate Information\",\"Learning Treatment Effects in Panels with General Intervention Patterns\",\"BCD Nets: Scalable Variational Approaches for Bayesian Causal Discovery\",\"Collaborative Causal Discovery with Atomic Interventions\",\"Cardinality-Regularized Hawkes-Granger Model\",\"Iterative Causal Discovery in the Possible Presence of Latent Confounders and Selection Bias\",\"Scalable Intervention Target Estimation in Linear Models\",\"Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game\",\"Nested Counterfactual Identification from Arbitrary Surrogate Experiments\",\"Actively Identifying Causal Effects with Latent Variables Given Only Response Variable Observable\",\"Deep Extended Hazard Models for Survival Analysis\",\"Estimating the Long-Term Effects of Novel Treatments\",\"Double/Debiased Machine Learning for Dynamic Treatment Effects\",\"Recursive Causal Structure Learning in the Presence of Latent Variables and Selection Bias\",\"Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation\",\"Interventional Sum-Product Networks: Causal Inference with Tractable Probabilistic Models\",\"A Topological Perspective on Causal Inference\",\"Statistical Undecidability in Linear, Non-Gaussian Causal Models in the Presence of Latent Confounders\",\"Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases\",\"BayesIMP: Uncertainty Quantification for Causal Data Fusion\",\"Matching a Desired Causal State via Shift Interventions\",\"Dynamic Causal Bayesian Optimization\",\"Higher Order Kernel Mean Embeddings to Capture Filtrations of Stochastic Processes\",\"Causal Abstractions of Neural Networks\",\"Estimating Multi-cause Treatment Effects via Single-cause Perturbation\",\"Causal Bandits with Unknown Graph Structure\",\"SurvITE: Learning Heterogeneous Treatment Effects from Time-to-Event Data\",\"Learning latent causal graphs via mixture oracles\",\"Near-Optimal Multi-Perturbation Experimental Design for Causal Structure Learning\",\"Recovering Latent Causal Factor for Generalization to Distributional Shifts\",\"A Critical Look at the Consistency of Causal Estimation with Deep Latent Variable Models\",\"On Inductive Biases for Heterogeneous Treatment Effect Estimation\",\"Multi-task Learning of Order-Consistent Causal Graphs\",\"SyncTwin: Treatment Effect Estimation with Longitudinal Outcomes\",\"Counterfactual Maximum Likelihood Estimation for Training Deep Networks\",\"The Causal-Neural Connection: Expressiveness, Learnability, and Inference\",\"Synthetic Design: An Optimization Approach to Experimental Design with Synthetic Controls\",\"Learning Generalized Gumbel-max Causal Mechanisms\",\"Causal-BALD: Deep Bayesian Active Learning of Outcomes to Infer Treatment-Effects from Observational Data\",\"Necessary and sufficient graphical conditions for optimal adjustment sets in causal graphical models with hidden variables\",\"Machine Learning for Variance Reduction in Online Experiments\",\"Deep Jump Learning for Off-Policy Evaluation in Continuous Treatment Settings\",\"Absolute Neighbour Difference based Correlation Test for Detecting Heteroscedastic Relationships\",\"Answering Complex Causal Queries With the Maximum Causal Set Effect\",\"Causal Identification with Matrix Equations\",\"Independent mechanism analysis, a new concept?\",\"Double Machine Learning Density Estimation for Local Treatment Effects with Instruments\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"7_causal_treatment_effects\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"7_causal_treatment_effects\"],\"textfont\":{\"size\":12},\"x\":[6.650749683380127,6.598132610321045,6.736263751983643,6.700540065765381,6.638492107391357,4.9132232666015625,6.071353435516357,6.700633525848389,6.592648506164551,6.792873859405518,6.660879611968994,6.831761837005615,6.3867034912109375,6.63395357131958,6.597792148590088,6.623660087585449,6.682927131652832,6.547175407409668,6.947063446044922,6.605461120605469,6.649909019470215,6.741497993469238,6.760139465332031,6.5988593101501465,6.819752216339111,6.538814544677734,6.608668327331543,6.613041877746582,6.614588737487793,6.426334857940674,6.68875789642334,6.722740173339844,6.142055034637451,6.55518913269043,6.714618682861328,8.1816987991333,6.710085391998291,6.53253698348999,6.675442695617676,4.998563766479492,6.375338077545166,6.70824670791626,6.562717914581299,6.695093154907227,4.9687042236328125,6.567524433135986,6.772353172302246,6.724329471588135,6.712376117706299,6.593631267547607,6.795678615570068,6.732471942901611,5.557623863220215,6.687586784362793,6.626577854156494,6.409915447235107,6.744537353515625,6.551583766937256],\"y\":[6.752397060394287,6.823394298553467,6.931852340698242,6.9368462562561035,6.973357677459717,3.86297607421875,6.500439167022705,7.1381096839904785,6.683033466339111,6.880040168762207,6.863441467285156,7.019235134124756,6.559841632843018,6.747581958770752,6.746995449066162,6.754072189331055,6.787818431854248,6.685862064361572,7.178366184234619,6.7460761070251465,7.131536960601807,7.024985313415527,7.01806116104126,6.737465858459473,7.283016204833984,6.6376824378967285,6.72542667388916,6.792672157287598,6.782383441925049,6.598575115203857,6.797093868255615,6.953929424285889,6.230586528778076,6.62278413772583,6.943855285644531,6.8230743408203125,7.081745624542236,6.724676132202148,6.804327487945557,3.8731491565704346,6.694882869720459,7.0746169090271,6.714012622833252,7.030947685241699,3.651348352432251,6.66719913482666,7.008691310882568,6.9462456703186035,7.062007904052734,6.751841068267822,6.9682207107543945,7.11060905456543,4.680012226104736,6.877798557281494,6.783350467681885,6.7713422775268555,6.995631217956543,6.648202419281006],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Directed Spectrum Measures Improve Latent Network Models Of Neural Populations\",\"Probabilistic Tensor Decomposition of Neural Population Spiking Activity\",\"Dynamic Analysis of Higher-Order Coordination in Neuronal Assemblies via De-Sparsified Orthogonal Matching Pursuit\",\"On Path Integration of Grid Cells: Group Representation and Isotropic Scaling\",\"Your head is there to move you around: Goal-driven models of the primate dorsal pathway\",\"Credit Assignment in Neural Networks through Deep Feedback Control\",\"Understanding Adaptive, Multiscale Temporal Integration In Deep Speech Recognition Systems\",\"Learning rule influences recurrent network representations but not attractor structure in decision-making tasks\",\"Local plasticity rules can learn deep representations using self-supervised contrastive predictions\",\"Online Learning Of Neural Computations From Sparse Temporal Feedback\",\"Towards robust vision by multi-task learning on monkey visual cortex\",\"Can fMRI reveal the representation of syntactic structure in the brain?\",\"Differentiable Spike: Rethinking Gradient-Descent for Training Spiking Neural Networks\",\"Noisy Adaptation Generates L\\u00e9vy Flights in Attractor Neural Networks\",\"A mechanistic multi-area recurrent network model of decision-making\",\"Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss\",\"Cortico-cerebellar networks as decoupling neural interfaces\",\"The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning\",\"Three-dimensional spike localization and improved motion correction for Neuropixels recordings\",\"Self-Adaptable Point Processes with Nonparametric Time Decays\",\"Towards Biologically Plausible Convolutional Networks\",\"Explaining heterogeneity in medial entorhinal cortex with task-driven neural networks\",\"Activation Sharing with Asymmetric Paths Solves Weight Transport Problem without Bidirectional Connection\",\"Biological learning in key-value memory networks\",\"A Normative and Biologically Plausible Algorithm for Independent Component Analysis\",\"Tracking Without Re-recognition in Humans and Machines\",\"A flow-based latent state generative model of neural population responses to natural images\",\"Deep Residual Learning in Spiking Neural Networks\",\"Neural optimal feedback control with local learning rules\",\"A universal probabilistic spike count model reveals ongoing modulation of neural variability\",\"Deep Markov Factor Analysis: Towards Concurrent Temporal and Spatial Analysis of fMRI Data\",\"Removing Inter-Experimental Variability from Functional Data in Systems Neuroscience\",\"Targeted Neural Dynamical Modeling\",\"Bias and variance of the Bayesian-mean decoder\",\"Across-animal odor decoding by probabilistic manifold alignment\",\"DeepSITH: Efficient Learning via Decomposition of What and When Across Time Scales\",\"Fitting summary statistics of neural data with a differentiable spiking network simulator\",\"Training Feedback Spiking Neural Networks by Implicit Differentiation on the Equilibrium State\",\"Increasing Liquid State Machine Performance with Edge-of-Chaos Dynamics Organized by Astrocyte-modulated Plasticity\",\"A sampling-based circuit for optimal decision making\",\"Credit Assignment Through Broadcasting a Global Error Vector\",\"Deep inference of latent dynamics with spatio-temporal super-resolution using selective backpropagation through time\",\"Impression learning: Online representation learning with synaptic plasticity\",\"Neural Regression, Representational Similarity, Model Zoology & Neural Taskonomy at Scale in Rodent Visual Cortex\",\"Sparse Spiking Gradient Descent\",\"Charting and Navigating the Space of Solutions for Recurrent Neural Networks\",\"Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks\",\"Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons\",\"Bubblewrap: Online tiling and real-time flow prediction on neural manifolds\",\"Learning to Time-Decode in Spiking Neural Networks Through the Information Bottleneck\",\"Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics\",\"Learning Robust Hierarchical Patterns of Human Brain across Many fMRI Studies\",\"Drop, Swap, and Generate: A Self-Supervised Approach for Generating Neural Activity\",\"Tensor decompositions of higher-order correlations by nonlinear Hebbian plasticity\",\"Associative Memories via Predictive Coding\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"8_neural_brain_networks\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"8_neural_brain_networks\"],\"textfont\":{\"size\":12},\"x\":[4.252603530883789,4.185873985290527,4.069568157196045,0.8395858407020569,3.6380157470703125,3.9089643955230713,3.303385019302368,3.8667428493499756,3.7466347217559814,3.9708168506622314,3.5685739517211914,3.989619255065918,3.9553492069244385,3.919142484664917,3.7299206256866455,3.8019821643829346,3.7586581707000732,3.651287078857422,4.081921577453613,3.851004123687744,3.6213932037353516,3.6230015754699707,3.8211305141448975,3.755631923675537,4.074319362640381,3.5462162494659424,4.016064167022705,3.9157848358154297,3.9984002113342285,4.150290489196777,4.2170939445495605,4.1351847648620605,4.209334373474121,4.07474422454834,4.1118268966674805,3.3708651065826416,4.105795860290527,3.9794023036956787,3.981255292892456,4.125958442687988,3.8816897869110107,4.043730735778809,4.056494235992432,3.599215030670166,3.939424753189087,3.8387067317962646,3.9350428581237793,4.020949363708496,4.084709644317627,3.969906806945801,3.6365854740142822,4.220437049865723,3.8950798511505127,3.920396089553833,3.7181830406188965,3.8487982749938965],\"y\":[7.806700229644775,7.87929105758667,7.980485916137695,7.368147373199463,7.752316474914551,7.877050876617432,7.036148548126221,7.855718612670898,7.804531097412109,7.997570991516113,7.661759853363037,7.555788040161133,8.059475898742676,7.93009090423584,7.758204936981201,7.904460430145264,7.840950012207031,7.755809307098389,7.9715166091918945,8.05588150024414,7.749650955200195,7.733471393585205,7.857789516448975,7.998816013336182,7.754903793334961,7.694490432739258,7.67422342300415,8.044833183288574,7.947022438049316,7.915818214416504,7.586800575256348,3.2498345375061035,7.700506687164307,7.763767242431641,7.891488552093506,6.965184211730957,7.939065456390381,8.010941505432129,7.939461708068848,7.904690742492676,7.888290882110596,7.885403633117676,7.864625453948975,7.70407772064209,8.041399955749512,7.774328231811523,8.044137001037598,7.944827079772949,7.886335372924805,8.005380630493164,7.726273059844971,7.557211399078369,7.5122199058532715,7.919677257537842,7.930864334106445,7.724721908569336],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"TokenLearner: Adaptive Space-Time Tokenization for Videos\",\"TriBERT: Human-centric Audio-visual Representation Learning\",\"Low-dimensional Structure in the Space of Language Representations is Reflected in Brain Responses\",\"Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers\",\"Align before Fuse: Vision and Language Representation Learning with Momentum Distillation\",\"Video Instance Segmentation using Inter-Frame Communication Transformers\",\"SOAT: A Scene- and Object-Aware Transformer for Vision-and-Language Navigation\",\"Perceptual Score: What Data Modalities Does Your Model Perceive?\",\"VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text\",\"Skipping the Frame-Level: Event-Based Piano Transcription With Neural Semi-CRFs\",\"Learning with Noisy Correspondence for Cross-modal Matching\",\"Alignment Attention by Matching Key and Query Distributions\",\"End-to-end Multi-modal Video Temporal Grounding\",\"MERLOT: Multimodal Neural Script Knowledge Models\",\"Look at What I\\u2019m Doing: Self-Supervised Spatial Grounding of Narrations in Instructional Videos\",\"Learning from Inside: Self-driven Siamese Sampling and Reasoning for Video Question Answering\",\"Grounding Spatio-Temporal Language with Transformers\",\"UniDoc: Unified Pretraining Framework for Document Understanding\",\"Explainable Semantic Space by Grounding Language to Vision with Cross-Modal Contrastive Learning\",\"Space-time Mixing Attention for Video Transformer\",\"Robust Visual Reasoning via Language Guided Neural Module Networks\",\"MAU: A Motion-Aware Unit for Video Prediction and Beyond\",\"Deep Contextual Video Compression\",\"CentripetalText: An Efficient Text Instance Representation for Scene Text Detection\",\"Relational Self-Attention: What's Missing in Attention for Video Understanding\",\"Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation\",\"Clockwork Variational Autoencoders\",\"VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer\",\"Referring Transformer: A One-step Approach to Multi-task Visual Grounding\",\"How Modular should Neural Module Networks Be for Systematic Generalization?\",\"MOMA: Multi-Object Multi-Actor Activity Parsing\",\"Landmark-RxR: Solving Vision-and-Language Navigation with Fine-Grained Alignment Supervision\",\"History Aware Multimodal Transformer for Vision-and-Language Navigation\",\"Temporal-attentive Covariance Pooling Networks for Video Recognition\",\"Action-guided 3D Human Motion Prediction\",\"Predicting Event Memorability from Contextual Visual Semantics\",\"Detecting Moments and Highlights in Videos via Natural Language Queries\",\"Long Short-Term Transformer for Online Action Detection\",\"Dynamic Normalization and Relay for Video Action Recognition\",\"Spatiotemporal Joint Filter Decomposition in 3D Convolutional Neural Networks\",\"Drop-DTW: Aligning Common Signal Between Sequences While Dropping Outliers\",\"Multi-modal Dependency Tree for Video Captioning\",\"Exploring Cross-Video and Cross-Modality Signals for Weakly-Supervised Audio-Visual Video Parsing\",\"SILG: The Multi-domain Symbolic Interactive Language Grounding Benchmark\",\"Contrast and Mix: Temporal Contrastive Video Domain Adaptation with Background Mixing\",\"Multimodal Few-Shot Learning with Frozen Language Models\",\"Contrastive Learning of Global and Local Video Representations\",\"Unsupervised Motion Representation Learning with Capsule Autoencoders\",\"Compressed Video Contrastive Learning\",\"Probing Inter-modality: Visual Parsing with Self-Attention for Vision-and-Language Pre-training\",\"CLIP-It! Language-Guided Video Summarization\",\"NeRV: Neural Representations for Videos\",\"Low-Fidelity Video Encoder Optimization for Temporal Action Localization\",\"Shifted Chunk Transformer for Spatio-Temporal Representational Learning\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"9_video_language_visual\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"9_video_language_visual\"],\"textfont\":{\"size\":12},\"x\":[1.2078073024749756,1.3106745481491089,1.1429102420806885,1.1913570165634155,1.249972939491272,1.2804878950119019,7.118980884552002,1.2429476976394653,1.3082009553909302,1.1725326776504517,1.3949612379074097,1.3332558870315552,1.165146827697754,1.1182717084884644,1.1395831108093262,1.0683581829071045,1.0589271783828735,1.2551685571670532,1.1720385551452637,1.2702786922454834,1.2730218172073364,1.0882697105407715,2.306776285171509,1.2952196598052979,1.1792323589324951,1.3265002965927124,2.3033924102783203,1.1215500831604004,1.2697745561599731,1.2797588109970093,1.1671628952026367,7.150463104248047,7.141653060913086,1.2370924949645996,0.9860548973083496,1.1686725616455078,1.1023980379104614,1.1843183040618896,1.1938594579696655,1.2017419338226318,1.1235653162002563,1.0956871509552002,1.1573853492736816,1.079221487045288,1.185689926147461,1.1355071067810059,1.2160537242889404,0.959152102470398,2.303433656692505,1.2263946533203125,1.1188820600509644,2.2693960666656494,1.186032772064209,1.1679867506027222,1.6000585556030273],\"y\":[5.95180082321167,5.81896448135376,5.384714126586914,5.944267272949219,5.452245235443115,5.837440490722656,9.666333198547363,5.105239391326904,5.7438507080078125,5.74574613571167,5.485393047332764,5.104809761047363,5.749093532562256,5.497946262359619,5.512871742248535,5.473057746887207,5.313021183013916,5.430316925048828,5.371589660644531,5.907267093658447,5.154658317565918,6.19109582901001,6.202629566192627,5.811436176300049,5.923166751861572,5.834953784942627,6.490381240844727,5.499244213104248,5.272946834564209,5.022337436676025,5.806345462799072,9.654520988464355,9.628283500671387,5.933960914611816,6.337833404541016,5.732186794281006,5.600694179534912,5.947664260864258,5.9390106201171875,5.942389011383057,5.775047302246094,5.465756416320801,5.774832248687744,5.320352554321289,5.818436622619629,5.403951644897461,5.806739330291748,6.205496788024902,6.111523628234863,5.294889450073242,5.524826526641846,6.2018632888793945,5.913907527923584,5.909874439239502,5.924985408782959],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model\",\"Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition\",\"Achieving Rotational Invariance with Bessel-Convolutional Neural Networks\",\"Blending Anti-Aliasing into Vision Transformer\",\"Searching the Search Space of Vision Transformer\",\"Dynamic Grained Encoder for Vision Transformers\",\"Dynamic Resolution Network \",\"Encoding Spatial Distribution of Convolutional Features for Texture Representation\",\"MST: Masked Self-Supervised Transformer for Visual Representation\",\"Raw Nav-merge Seismic Data to Subsurface Properties with MLP based Multi-Modal Information Unscrambler\",\"Gauge Equivariant Transformer\",\"Revitalizing CNN Attention via Transformers in Self-Supervised Visual Representation Learning\",\"TransMatcher: Deep Image Matching Through Transformers for Generalizable Person Re-identification\",\"Cross-view Geo-localization with Layer-to-Layer Transformer\",\"CATs: Cost Aggregation Transformers for Visual Correspondence\",\"Few-Shot Segmentation via Cycle-Consistent Transformer\",\"Twins: Revisiting the Design of Spatial Attention in Vision Transformers\",\"Early Convolutions Help Transformers See Better\",\"Exploring Forensic Dental Identification with Deep Learning\",\"Post-Training Quantization for Vision Transformer\",\"Do Vision Transformers See Like Convolutional Neural Networks?\",\"XCiT: Cross-Covariance Image Transformers\",\"HRFormer: High-Resolution Vision Transformer for Dense Predict\",\"ResT: An Efficient Transformer for Visual Recognition\",\"Recurrence along Depth: Deep Convolutional Neural Networks with Recurrent Layer Aggregation\",\"Efficient Equivariant Network\",\"SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers\",\"Intriguing Properties of Vision Transformers\",\"IA-RED$^2$: Interpretability-Aware Redundancy Reduction for Vision Transformers\",\"Revisiting ResNets: Improved Training and Scaling Strategies\",\"Augmented Shortcuts for Vision Transformers\",\"Global Filter Networks for Image Classification\",\"You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection\",\"CoAtNet: Marrying Convolution and Attention for All Data Sizes\",\"Group Equivariant Subsampling\",\"Adder Attention for Vision Transformer\",\"Recognizing Vector Graphics without Rasterization\",\"Efficient Training of Visual Transformers with Small Datasets\",\"Glance-and-Gaze Vision Transformer\",\"DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification\",\"Transformer in Transformer\",\"Hard-Attention for Scalable Image Classification\",\"Focal Attention for Long-Range Interactions in Vision Transformers\",\"Container: Context Aggregation Networks\",\"All Tokens Matter: Token Labeling for Training Better Vision Transformers\",\"Learnable Fourier Features for Multi-dimensional Spatial Positional Encoding\",\"Dual-stream Network for Visual Recognition\",\"MLP-Mixer: An all-MLP Architecture for Vision\",\"ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias\",\"Dynamic Neural Representational Decoders for High-Resolution Semantic Segmentation\",\"Implicit Transformer Network for Screen Content Image Continuous Super-Resolution\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"10_vision_transformer_transformers\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"10_vision_transformer_transformers\"],\"textfont\":{\"size\":12},\"x\":[2.334940195083618,2.2888083457946777,2.9778223037719727,2.2756433486938477,2.309391498565674,2.2218620777130127,2.674345016479492,2.5682852268218994,2.1526260375976562,2.6496458053588867,2.567479133605957,2.522425413131714,2.259718418121338,2.430878162384033,2.27144455909729,2.1184964179992676,2.332578182220459,2.617262601852417,2.474797487258911,2.4961998462677,2.4734301567077637,2.221677303314209,2.3265178203582764,2.386160373687744,2.4382519721984863,2.678178310394287,2.057943344116211,2.708754062652588,2.265935182571411,2.6599128246307373,2.305978536605835,2.4751431941986084,2.278965473175049,2.493283271789551,2.6868834495544434,2.519510507583618,2.3574981689453125,2.651981830596924,2.2338666915893555,2.2842674255371094,2.2124881744384766,2.573047399520874,2.2221951484680176,2.457943916320801,2.2957255840301514,2.2970519065856934,2.5414974689483643,2.449286937713623,2.3145039081573486,2.109367609024048,2.699669599533081,2.416109085083008],\"y\":[5.1448655128479,5.26569128036499,5.678258419036865,5.343583106994629,5.180190563201904,5.1478657722473145,5.559108734130859,5.3916754722595215,5.363565921783447,5.440093040466309,5.625679016113281,5.369520664215088,5.14755392074585,5.484771728515625,5.325124740600586,5.018413543701172,5.376245021820068,5.349222660064697,5.254008769989014,5.288907051086426,5.35548210144043,5.372713565826416,5.466339588165283,5.4667863845825195,5.088961124420166,5.644391059875488,5.152021884918213,5.2919487953186035,5.364694118499756,5.50216007232666,5.350067138671875,5.528782844543457,5.013021469116211,5.38421630859375,5.6194634437561035,5.349668502807617,5.397723197937012,5.36245059967041,5.401662826538086,5.328516483306885,5.347890853881836,5.5164666175842285,5.3836212158203125,5.4069976806640625,5.248091697692871,5.600757122039795,5.335323333740234,5.453212261199951,5.426047325134277,5.007076740264893,5.6425347328186035,5.36398983001709],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Exact Privacy Guarantees for Markov Chain Implementations of the Exponential Mechanism with Artificial Atoms\",\"Individual Privacy Accounting via a R\\u00e9nyi Filter\",\"Privately Publishable Per-instance Privacy\",\"Private learning implies quantum stability\",\"Forster Decomposition and Learning Halfspaces with Noise\",\"Local Differential Privacy for Regret Minimization in Reinforcement Learning\",\"Differentially Private Learning with Adaptive Clipping\",\"Fast and Memory Efficient Differentially Private-SGD via JL Projections\",\"Iterative Methods for Private Synthetic Data: Unifying Framework and New Methods\",\"Robust and differentially private mean estimation\",\"Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent\",\"Differentially Private n-gram Extraction\",\"Privately Learning Subspaces\",\"Multiclass versus Binary Differentially Private PAC Learning\",\"Locally differentially private estimation of functionals of discrete distributions\",\"Littlestone Classes are Privately Online Learnable\",\"Enabling Fast Differentially Private SGD via Just-in-Time Compilation and Vectorization\",\"Differential Privacy Over Riemannian Manifolds\",\"On the Sample Complexity of Privately Learning Axis-Aligned Rectangles\",\"Differentially Private Sampling from Distributions\",\"Don\\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence\",\"Parameter-free HE-friendly Logistic Regression\",\"Instance-optimal Mean Estimation Under Differential Privacy\",\"Differentially Private Empirical Risk Minimization under the Fairness Lens\",\"Photonic Differential Privacy with Direct Feedback Alignment\",\"An Uncertainty Principle is a Price of Privacy-Preserving Microdata\",\"Renyi Differential Privacy of The Subsampled Shuffle Model In Distributed Learning\",\"Differentially Private Model Personalization\",\"Deep Learning with Label Differential Privacy\",\"CrypTen: Secure Multi-Party Computation Meets Machine Learning\",\"Adaptive Machine Unlearning\",\"User-Level Differentially Private Learning via Correlated Sampling\",\"Learning with User-Level Privacy\",\"Numerical Composition of Differential Privacy\",\"Privately Learning Mixtures of Axis-Aligned Gaussians\",\"The Skellam Mechanism for Differentially Private Federated Learning\",\"A Central Limit Theorem for Differentially Private Query Answering\",\"Relaxed Marginal Consistency for Differentially Private Query Answering\",\"Locally private online change point detection\",\"Remember What You Want to Forget: Algorithms for Machine Unlearning\",\"Covariance-Aware Private Mean Estimation Without Private Covariance Estimation\",\"Generalized Linear Bandits with Local Differential Privacy \",\"Private and Non-private Uniformity Testing for Ranking Data\",\"Identity testing for Mallows model\",\"Exploiting Data Sparsity in Secure Cross-Platform Social Recommendation\",\"G-PATE: Scalable Differentially Private Data Generator via Private Aggregation of Teacher Discriminators\",\"Differentially Private Federated Bayesian Optimization with Distributed Exploration\",\"Antipodes of Label Differential Privacy: PATE and ALIBI\",\"Circa: Stochastic ReLUs for Private Deep Learning\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"11_privacy_private_differential privacy\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"11_privacy_private_differential privacy\"],\"textfont\":{\"size\":12},\"x\":[10.035268783569336,10.025609970092773,10.054367065429688,9.981289863586426,9.740917205810547,9.976459503173828,10.001197814941406,10.065771102905273,10.051095008850098,10.013181686401367,9.915882110595703,10.06157112121582,10.045103073120117,9.982555389404297,9.944404602050781,9.968539237976074,10.06554126739502,9.956586837768555,9.798738479614258,9.901291847229004,10.014129638671875,10.063030242919922,10.047880172729492,10.046156883239746,10.10718059539795,10.020492553710938,10.023752212524414,10.035236358642578,10.056305885314941,10.090394020080566,9.949798583984375,9.957450866699219,9.990655899047852,10.063496589660645,9.831414222717285,10.064919471740723,9.935057640075684,10.036438941955566,9.969526290893555,9.986729621887207,9.878409385681152,9.987675666809082,9.87419319152832,9.755072593688965,10.084701538085938,10.055228233337402,10.043490409851074,10.051095962524414,10.087063789367676,9.993721008300781],\"y\":[4.268683910369873,4.3163228034973145,4.279604434967041,4.353400707244873,4.317129611968994,4.290635108947754,4.291469097137451,4.31895637512207,4.312681674957275,4.294314384460449,4.370019435882568,4.278369426727295,4.280278205871582,4.307107925415039,4.273309230804443,4.320887565612793,4.320420265197754,4.278273582458496,4.310704708099365,4.291679382324219,4.3288702964782715,4.2921881675720215,4.272790431976318,4.287517547607422,4.248804569244385,4.2348408699035645,4.2724480628967285,4.269473552703857,4.313571929931641,4.347047805786133,4.388821125030518,4.245128631591797,4.305662155151367,4.266593933105469,4.303011894226074,4.240327835083008,4.257595539093018,4.275327205657959,4.308279991149902,4.322305679321289,4.283351898193359,4.350564002990723,4.413839817047119,4.558371067047119,4.368980884552002,4.331829071044922,4.285904407501221,4.2902092933654785,4.347839832305908,4.307872772216797],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Dual Progressive Prototype Network for Generalized Zero-Shot Learning\",\"The Emergence of Objectness: Learning Zero-shot Segmentation from Videos\",\"Instance-Conditional Knowledge Distillation for Object Detection\",\"Semi-Supervised Semantic Segmentation via Adaptive Equalization Learning\",\"Unsupervised Representation Transfer for Small Networks: I Believe I Can Distill On-the-Fly\",\"Intriguing Properties of Contrastive Losses\",\"A Theory-Driven Self-Labeling Refinement Method for Contrastive Representation Learning\",\"Predicting What You Already Know Helps: Provable Self-Supervised Learning\",\"See More for Scene: Pairwise Consistency Learning for Scene Classification\",\"Can contrastive learning avoid shortcut solutions?\",\"Reducing Information Bottleneck for Weakly Supervised Semantic Segmentation\",\"Few-Shot Object Detection via Association and DIscrimination\",\"Dense Unsupervised Learning for Video Segmentation\",\"Unleashing the Power of Contrastive Self-Supervised Visual Models via Contrast-Regularized Fine-Tuning\",\"Mining the Benefits of Two-stage and  One-stage HOI Detection\",\"SubTab: Subsetting Features of Tabular Data for Self-Supervised Representation Learning\",\"Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations\",\"Self-Supervised Representation Learning on Neural Network Weights for Model Characteristic Prediction\",\"ReSSL: Relational Self-Supervised Learning with Weak Augmentation\",\"Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation\",\"K-Net: Towards Unified Image Segmentation\",\"Robust Contrastive Learning Using Negative Samples with Diminished Semantics\",\"Distilling Image Classifiers in Object Detectors\",\"Independent Prototype Propagation for Zero-Shot Compositionality\",\"GENESIS-V2: Inferring Unordered Object Representations without Iterative Refinement\",\"Regularized Frank-Wolfe for Dense CRFs: Generalizing Mean Field and Beyond\",\"On Model Calibration for Long-Tailed Object Detection and Instance Segmentation\",\"Large-Scale Unsupervised Object Discovery\",\"Unsupervised Foreground Extraction via Deep Region Competition\",\"Intermediate Layers Matter in Momentum Contrastive Self Supervised Learning\",\"CROCS: Clustering and Retrieval of Cardiac Signals Based on Patient Disease Class, Sex, and Age\",\"Learning Distilled Collaboration Graph for Multi-Agent Perception\",\"Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style\",\"Unsupervised Object-Level Representation Learning from Scene Images\",\"Distilling Object Detectors with Feature Richness\",\"Looking Beyond Single Images for Contrastive Semantic Segmentation Learning\",\"Bootstrap Your Object Detector via Mixed Training\",\"Generalized and Discriminative Few-Shot Object Detection via SVD-Dictionary Enhancement\",\"Joint Semantic Mining for Weakly Supervised RGB-D Salient Object Detection\",\"Combinatorial Optimization for Panoptic Segmentation: A Fully Differentiable Approach\",\"Self-Paced Contrastive Learning for Semi-supervised Medical Image Segmentation with Meta-labels\",\"Unsupervised Part Discovery from Contrastive Reconstruction\",\"Mixed Supervised Object Detection by Transferring Mask Prior and Semantic Similarity\",\"Fine-Grained Zero-Shot Learning with DNA as Side Information\",\"Improving Transferability of Representations via Augmentation-Aware Self-Supervision\",\"Object-aware Contrastive Learning for Debiased Scene Representation\",\"Aligning Pretraining for Detection via Object-Level Contrastive Learning\",\"Per-Pixel Classification is Not All You Need for Semantic Segmentation\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"12_contrastive_segmentation_object\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"12_contrastive_segmentation_object\"],\"textfont\":{\"size\":12},\"x\":[2.528228282928467,1.979651927947998,2.26127028465271,2.2432117462158203,2.2278707027435303,2.1729159355163574,2.1855719089508057,2.2227768898010254,2.128262996673584,2.2327373027801514,2.312009811401367,2.348877191543579,1.8596991300582886,2.212571859359741,2.3184680938720703,2.219820499420166,2.1001577377319336,2.162091016769409,2.1845414638519287,2.2937192916870117,2.158770799636841,2.1729629039764404,2.269413471221924,2.4890902042388916,1.9687899351119995,2.1634979248046875,2.4460067749023438,2.130467653274536,2.0232319831848145,2.2124061584472656,2.1969075202941895,2.3269941806793213,2.1786935329437256,2.1039657592773438,2.265167236328125,2.142336130142212,2.3545851707458496,2.3588812351226807,2.1053671836853027,2.128816604614258,2.265596866607666,2.0852980613708496,2.3204102516174316,2.479262351989746,2.1923446655273438,2.073754072189331,2.2248122692108154,2.1464765071868896,2.21205735206604],\"y\":[4.059206008911133,4.493788719177246,4.506769180297852,4.510913372039795,4.20833158493042,4.241196632385254,4.1200385093688965,3.805651903152466,4.468076229095459,4.062196731567383,4.607046604156494,4.291323661804199,4.679717540740967,4.023449897766113,4.391216278076172,3.861102342605591,4.412850856781006,4.06099796295166,3.854140043258667,4.2842116355896,4.771260738372803,4.3255486488342285,4.486217498779297,4.086060523986816,4.303199291229248,4.563923358917236,4.437976360321045,4.324315071105957,4.403366565704346,3.9853711128234863,3.9330639839172363,3.433680295944214,3.83854603767395,4.445016860961914,4.469927787780762,4.370151519775391,4.702749729156494,4.213830947875977,4.404012203216553,4.6570587158203125,4.025913238525391,4.366001129150391,4.350732326507568,4.108534812927246,3.9498953819274902,4.394253730773926,4.652249336242676,4.7930073738098145,4.286210536956787],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Catch-A-Waveform: Learning to Generate Audio from a Single Short Example\",\"Alias-Free Generative Adversarial Networks\",\"Image Generation using Continuous Filter Atoms\",\"Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware  Adversarial Training\",\"Why Spectral Normalization Stabilizes GANs: Analysis and Improvements\",\"Self-Diagnosing GAN: Diagnosing Underrepresented Samples in Generative Adversarial Networks\",\" Improving Visual Quality of Image Synthesis by A Token-based Generator with Transformers\",\"Deceive D: Adaptive Pseudo Augmentation for GAN Training with Limited Data\",\"Improved Transformer for High-Resolution GANs\",\"Compositional Transformers for Scene Generation\",\"Revisiting Discriminator in GAN Compression: A Generator-discriminator Cooperative Compression Scheme\",\"Meta Internal Learning\",\"Differentiable Quality Diversity\",\"TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up\",\"Low-Rank Subspaces in GANs\",\"Rethinking conditional GAN training: An approach using geometrically structured latent manifolds\",\"Towards Scalable Unpaired Virtual Try-On via Patch-Routed Spatially-Adaptive GAN\",\"CogView: Mastering Text-to-Image Generation via Transformers\",\"Invertible Tabular GANs: Killing Two Birds with One Stone for Tabular Data Synthesis\",\"Conditional Generation Using Polynomial Expansions\",\"Self-Supervised GANs with Label Augmentation\",\"To Beam Or Not To Beam: That is a Question of Cooperation for Language GANs\",\"Controllable and Compositional Generation with Latent-Space Energy-Based Models\",\"The Image Local Autoregressive Transformer\",\"Diffusion Models Beat GANs on Image Synthesis\",\"Data-Efficient Instance Generation from Instance Discrimination\",\"Lip to Speech Synthesis with Visual Context Attentional GAN\",\"Particle Cloud Generation with Message Passing Generative Adversarial Networks\",\"Breaking the Dilemma of Medical Image-to-image Translation\",\"On the Frequency Bias of Generative Models\",\"Deep Self-Dissimilarities as Powerful Visual Fingerprints\",\"Learning to See by Looking at Noise\",\"D2C: Diffusion-Decoding Models for Few-Shot Conditional Generation\",\"EditGAN: High-Precision Semantic Image Editing\",\"Artistic Style Transfer with Internal-external Learning and Contrastive Learning\",\"Rebooting ACGAN: Auxiliary Classifier GANs with Stable Training\",\"Data-Efficient GAN Training Beyond (Just) Augmentations: A Lottery Ticket Perspective\",\"Instance-Conditioned GAN\",\"UFC-BERT: Unifying Multi-Modal Controls for Conditional Image Synthesis\",\"BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation\",\"Projected GANs Converge Faster\",\"CCVS: Context-aware Controllable Video Synthesis\",\"A Unified View of cGANs with and without Classifiers\",\"CAM-GAN: Continual Adaptation Modules for Generative Adversarial Networks\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"13_image_gans_gan\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"13_image_gans_gan\"],\"textfont\":{\"size\":12},\"x\":[1.939685344696045,2.312701463699341,2.8205552101135254,2.510709285736084,2.387981653213501,2.3919501304626465,2.2763710021972656,2.4124317169189453,2.3209733963012695,2.21663761138916,2.422793388366699,2.376096725463867,2.5558223724365234,2.2963552474975586,2.3677866458892822,2.4022598266601562,2.340646982192993,2.287829637527466,2.3991024494171143,2.5634615421295166,2.399467706680298,2.407661199569702,2.7611494064331055,2.2821199893951416,2.4971320629119873,2.3956711292266846,1.9916560649871826,2.435861587524414,2.347144603729248,2.363736152648926,2.396831750869751,2.7960407733917236,2.7362735271453857,2.296935796737671,2.2999026775360107,2.4499456882476807,2.394778251647949,2.47209095954895,2.254274368286133,2.260857343673706,2.4100069999694824,2.262270927429199,2.4424610137939453,2.4103305339813232,2.3946986198425293],\"y\":[6.747672080993652,7.0300822257995605,6.864166259765625,6.9785919189453125,7.120795249938965,7.098933219909668,6.9974751472473145,7.103268146514893,6.885530948638916,7.007604122161865,7.077967643737793,7.051969528198242,7.005834579467773,6.964879989624023,7.073542594909668,7.063625335693359,7.071145534515381,7.007482051849365,7.111145973205566,6.943459510803223,7.108308792114258,7.102899074554443,6.878872871398926,6.805866718292236,7.031071662902832,7.0938520431518555,6.707797050476074,7.061107158660889,6.442465782165527,7.106057167053223,7.108109951019287,6.807902812957764,6.868391990661621,7.020470142364502,6.974707126617432,7.082059383392334,7.06651496887207,7.0156683921813965,6.796225070953369,6.971664905548096,7.088321208953857,6.683847904205322,7.075862884521484,7.089266300201416,6.98164701461792],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Deformable Butterfly: A Highly Structured and Sparse Linear Transform\",\"DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning\",\"Post-Training Sparsity-Aware Quantization\",\"Rethinking gradient sparsification as total error minimization\",\"OSOA: One-Shot Online Adaptation of Deep Generative Models for Lossless Compression\",\"Compressing Neural Networks: Towards Determining the Optimal Layer-wise Decomposition\",\"Validating the Lottery Ticket Hypothesis with Inertial Manifold Theory\",\"Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Sparse Neural Networks\",\"Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks\",\"Hyperparameter Tuning is All You Need for LISTA\",\"Only Train Once: A One-Shot Neural Network Training And Pruning Framework\",\"AC-GC: Lossy Activation Compression with Guaranteed Convergence\",\"Training Neural Networks with Fixed Sparse Masks\",\"Generalized Depthwise-Separable Convolutions for Adversarially Robust and Efficient Neural Networks\",\"Efficient Neural Network Training via Forward and Backward Propagation Sparsification\",\"The Flip Side of the Reweighted Coin: Duality of Adaptive Dropout and Regularization\",\"Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?\",\"You are caught stealing my winning lottery ticket! Making a lottery ticket claim its ownership\",\"Channel Permutations for N:M Sparsity\",\"Scaling Up Exact Neural Network Compression by ReLU Stability\",\"DominoSearch: Find layer-wise fine-grained N:M sparse schemes from dense neural networks\",\"Learning Compact Representations of Neural Networks using DiscriminAtive Masking (DAM)\",\"Sparse Training via Boosting Pruning Plasticity  with Neuroregeneration\",\"Faster Neural Network Training with Approximate Tensor Operations\",\"Rethinking the Pruning Criteria for Convolutional Neural Network\",\"DeepReduce: A Sparse-tensor Communication Framework for Federated Deep Learning\",\"Efficient Combination of Rematerialization and Offloading for Training DNNs\",\"MEST: Accurate and Fast Memory-Economic Sparse Training Framework on the Edge\",\"RED : Looking for Redundancies for Data-FreeStructured Compression of Deep Neural Networks\",\"CHIP: CHannel Independence-based Pruning for Compact Neural Networks\",\"Piper: Multidimensional Planner for DNN Parallelization\",\"Powerpropagation: A sparsity inducing weight reparameterisation\",\"Pruning Randomly Initialized Neural Networks with Iterative Randomization\",\"Memory-efficient Patch-based Inference for Tiny Deep Learning\",\"The Elastic Lottery Ticket Hypothesis\",\"AC/DC: Alternating Compressed/DeCompressed Training of Deep Neural Networks\",\"Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer\",\"A Winning Hand: Compressing Deep Networks Can Improve Out-of-Distribution Robustness\",\"iFlow: Numerically Invertible Flows for Efficient Lossless Compression via a Uniform Coder\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"14_pruning_sparse_training\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"14_pruning_sparse_training\"],\"textfont\":{\"size\":12},\"x\":[3.52677059173584,3.4703028202056885,3.6675124168395996,3.782332181930542,3.3046252727508545,3.5211405754089355,3.5577266216278076,3.5912070274353027,3.5712385177612305,3.707664966583252,3.5494325160980225,3.5185439586639404,3.735308885574341,3.4453935623168945,3.7697105407714844,3.8207077980041504,3.5866713523864746,3.5887959003448486,3.5315206050872803,3.6305150985717773,3.552032709121704,3.4836323261260986,3.5427117347717285,3.579634666442871,3.509246587753296,3.6089160442352295,3.52095365524292,3.5767149925231934,3.4711036682128906,3.4798996448516846,3.4859869480133057,3.7210214138031006,3.551356077194214,3.414525270462036,3.5767922401428223,3.62646484375,3.606996774673462,3.564939498901367,3.396824598312378,3.56786847114563],\"y\":[5.228945255279541,4.495490074157715,4.891676425933838,5.127246856689453,5.318667411804199,5.225000858306885,5.353558540344238,5.343131065368652,5.14841890335083,5.044360637664795,5.091320991516113,5.049656391143799,5.045172691345215,5.182827472686768,5.010714054107666,5.038549900054932,5.344000339508057,5.325800895690918,5.186102390289307,5.167758464813232,5.194565296173096,5.299868583679199,5.350517272949219,4.923274517059326,5.30380392074585,5.1473517417907715,4.849906921386719,5.138669013977051,5.267707824707031,5.241654396057129,4.801788330078125,5.033646583557129,5.353194236755371,4.945348262786865,5.344951629638672,5.084722518920898,4.882364749908447,5.331457138061523,5.284568786621094,5.138403415679932],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Dynamic Trace Estimation\",\"Analysis of Sensing Spectral for Signal Recovery under a Generalized Linear Model\",\"Unique sparse decomposition of low rank matrices\",\"Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction\",\"A Note on Sparse Generalized Eigenvalue Problem\",\"Hessian Eigenspectra of More Realistic Nonlinear Models\",\"Implicit Regularization in Matrix Sensing via Mirror Descent\",\"Towards Sample-Optimal Compressive Phase Retrieval with Sparse and Generative Priors\",\"Unlabeled Principal Component Analysis\",\"Optimal Sketching for Trace Estimation\",\"Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient\",\"Fine-grained Generalization Analysis of Inductive Matrix Completion\",\"Rate-Optimal Subspace Estimation on Random Graphs\",\"An Online Riemannian PCA for Stochastic Canonical Correlation Analysis\",\"Distributed Principal Component Analysis with Limited Communication\",\"Learned Robust PCA: A Scalable Deep Unfolding Approach for High-Dimensional Outlier Detection\",\"Global Convergence of Gradient Descent for Asymmetric Low-Rank Matrix Factorization\",\"Low-Rank Extragradient Method for Nonsmooth and Low-Rank Matrix Optimization Problems\",\"Bootstrapping the Error of Oja's Algorithm \",\"The Complexity of Sparse Tensor PCA\",\"How can classical multidimensional scaling go wrong?\",\"Few-Shot Data-Driven Algorithms for Low Rank Approximation\",\"Implicit SVD for Graph Representation Learning\",\"Square Root Principal Component Pursuit: Tuning-Free Noisy Robust Matrix Recovery\",\"PCA Initialization for Approximate Message Passing in Rotationally Invariant Models\",\"Preconditioned Gradient Descent for Over-Parameterized Nonconvex Matrix Factorization\",\"Sparse Quadratic Optimisation over the Stiefel Manifold with Application to Permutation Synchronisation\",\"Consistent Estimation for PCA and Sparse Regression with Oblivious Outliers\",\"On learning sparse vectors from mixture of responses\",\"Rank Overspecified Robust Matrix Recovery: Subgradient Method and Exact Recovery\",\"A Comprehensively Tight Analysis of Gradient Descent for PCA\",\"Distributed Machine Learning with Sparse Heterogeneous Data\",\"General Low-rank Matrix Optimization: Geometric Analysis and Sharper Bounds\",\"Faster proximal algorithms for matrix optimization using Jacobi-based eigenvalue methods\",\"Learning the optimal Tikhonov regularizer for inverse problems\",\"Iteratively Reweighted Least Squares for Basis Pursuit with Global Linear Convergence Rate\",\"A Non-commutative Extension of  Lee-Seung's Algorithm for Positive Semidefinite Factorizations\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"15_matrix_sparse_pca\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"15_matrix_sparse_pca\"],\"textfont\":{\"size\":12},\"x\":[7.338102340698242,7.112682342529297,7.322794437408447,7.261673927307129,7.21107816696167,7.201481819152832,7.238692283630371,7.0587992668151855,7.324640274047852,7.3788580894470215,7.328531742095947,7.40244197845459,7.2994513511657715,7.441730499267578,7.462278366088867,7.261941909790039,7.362809181213379,7.330896377563477,7.480364799499512,7.547987461090088,7.402060031890869,7.190693378448486,7.151392936706543,7.226198196411133,7.462901592254639,7.301449775695801,7.277782917022705,7.419004440307617,7.032363414764404,7.267244815826416,7.463698387145996,6.99456787109375,7.363844871520996,7.296933650970459,6.953803062438965,7.106457710266113,7.375097751617432,7.2879109382629395],\"y\":[4.125914096832275,3.863551378250122,3.8250041007995605,3.8847498893737793,3.8495919704437256,3.919708013534546,3.9071967601776123,3.775747776031494,3.7814764976501465,4.032857894897461,4.105457305908203,3.8557376861572266,3.8712682723999023,3.7915432453155518,3.7974982261657715,3.8405165672302246,3.8348305225372314,3.8705124855041504,3.7493417263031006,3.6320314407348633,3.8072738647460938,4.034728527069092,4.175788879394531,3.8052310943603516,3.732642412185669,3.8916215896606445,3.8783273696899414,3.7756223678588867,3.720473289489746,3.8295483589172363,3.896029233932495,3.692725419998169,3.833963394165039,4.092773914337158,4.0969367027282715,3.7952818870544434,3.8414573669433594,3.8706750869750977],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining\",\"FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition\",\"Sequence-to-Sequence Learning with Latent Neural Grammars\",\"Making a (Counterfactual) Difference One Rationale at a Time\",\"MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers\",\"Speech-T: Transducer for Text to Speech and Beyond\",\"Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning\",\"Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation\",\"End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering\",\"Mind the Gap: Assessing Temporal Generalization in Neural Language Models\",\"Multilingual Pre-training with Universal Dependency Learning\",\"Pay Better Attention to Attention: Head Selection in Multilingual and Multi-Domain Sequence Modeling\",\"Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as a Target for NLP\",\"BARTScore: Evaluating Generated Text as Text Generation\",\"Word2Fun: Modelling Words as Functions for Diachronic Word Representation\",\"Structured Reordering for Modeling Latent Alignments in Sequence Transduction\",\"Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models\",\"Refining Language Models with Compositional Explanations\",\"Duplex Sequence-to-Sequence Learning for Reversible Machine Translation\",\"Multimodal and Multilingual Embeddings for Large-Scale Speech Mining\",\"Low-Rank Constraints for Fast Inference in Structured Models\",\"PortaSpeech: Portable and High-Quality Generative Text-to-Speech\",\"IRM\\u2014when it works and when it doesn't: A test case of natural language inference\",\"How Should Pre-Trained Language Models Be Fine-Tuned Towards Adversarial Robustness?\",\"Stylized Dialogue Generation with Multi-Pass Dual Learning\",\"Robust Optimization for Multilingual Translation with Imbalanced Data\",\"One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval\",\"Controlled Text Generation as Continuous Optimization with Multiple Constraints\",\"Local Explanation of Dialogue Response Generation\",\"Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets\",\"PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition\",\"A Causal Lens for Controllable Text Generation\",\"Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence\",\"Unsupervised Speech Recognition\",\"Contrastive Learning for Neural Topic Model\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"16_text_language_models\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"16_text_language_models\"],\"textfont\":{\"size\":12},\"x\":[1.2858521938323975,1.4001367092132568,1.227274775505066,0.9579935073852539,0.9068435430526733,1.7138004302978516,1.0195354223251343,1.1546906232833862,1.2215694189071655,1.052912712097168,1.160422444343567,1.3697324991226196,0.9881064295768738,1.0002541542053223,1.0640445947647095,1.2347067594528198,0.8884233832359314,0.9849631190299988,1.3031178712844849,1.643890619277954,1.3799504041671753,1.7543302774429321,0.9783393144607544,0.9581755995750427,0.9648196697235107,1.4158837795257568,1.1480329036712646,0.9642961025238037,0.9597944021224976,0.910054624080658,1.7526527643203735,0.9292969703674316,0.780603289604187,1.68936288356781,0.7803584933280945,1.169834852218628],\"y\":[5.224627494812012,5.345925807952881,5.151309013366699,4.793219566345215,4.884343147277832,6.327513217926025,4.922173976898193,5.083004951477051,4.942710876464844,5.055208683013916,4.951788902282715,5.200160980224609,4.74297571182251,4.932334899902344,5.057518482208252,5.158320903778076,4.786092281341553,4.720953941345215,5.230205059051514,6.190196514129639,5.22953462600708,6.385772228240967,4.738973140716553,4.719263553619385,4.949625492095947,5.142513751983643,4.94223690032959,4.94429349899292,4.862674713134766,4.827757835388184,6.141925811767578,4.851485252380371,4.649570941925049,6.206301689147949,4.647820949554443,5.141152381896973],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization\",\"Revisiting the Calibration of Modern Neural Networks\",\"Scaling Ensemble Distribution Distillation to Many Classes with Proxy Targets\",\"Soft Calibration Objectives for Neural Networks\",\"Towards a Theoretical Framework of Out-of-Distribution Generalization\",\"Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization\",\"Boost Neural Networks by Checkpoints\",\"Detecting Errors and Estimating Accuracy on Unlabeled Data with Self-training  Ensembles\",\"Detecting and Adapting to Irregular Distribution Shifts in Bayesian Online Learning\",\"Neural Bootstrapper\",\"Neural Ensemble Search for Uncertainty Estimation and Dataset Shift\",\"Characterizing Generalization under Out-Of-Distribution Shifts in Deep Metric Learning\",\"Adaptive Risk Minimization: Learning to Adapt to Domain Shift\",\"An Information-theoretic Approach to Distribution Shifts\",\"TestRank: Bringing Order into Unlabeled Test Instances for Deep Learning Tasks\",\"Rethinking Calibration of Deep Neural Networks: Do Not Be Afraid of Overconfidence\",\"Robust Generalization despite Distribution Shift via Minimum Discriminating Information\",\"Backward-Compatible Prediction Updates: A Probabilistic Approach\",\"Uncertainty Calibration for Ensemble-Based Debiasing Methods\",\"Training for the Future: A Simple Gradient Interpolation Loss to Generalize Along Time\",\"Reliable Decisions with Threshold Calibration\",\"TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?\",\"Diversity Matters When Learning From Ensembles\",\"Predicting Deep Neural Network Generalization with Perturbation Response Curves\",\"Identifying and Benchmarking Natural Out-of-Context Prediction Problems\",\"Reliable and Trustworthy Machine Learning for Health Using Dataset Shift Detection\",\"Bayesian Adaptation for Covariate Shift\",\"Online Adaptation to Label Distribution Shift\",\"Calibrating Predictions to Decisions: A Novel Approach to Multi-Class Calibration\",\"Overparameterization Improves Robustness to Covariate Shift in High Dimensions\",\"Towards optimally abstaining from prediction with OOD test examples\",\"Uncertainty Quantification and Deep Ensembles\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"17_calibration_test_distribution\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"17_calibration_test_distribution\"],\"textfont\":{\"size\":12},\"x\":[4.935543060302734,4.235655307769775,4.5543975830078125,4.341434478759766,4.760069370269775,4.843688488006592,4.456268310546875,4.564553260803223,5.1933441162109375,4.457693576812744,4.437370300292969,4.557572364807129,5.057645797729492,5.118912696838379,4.547408580780029,4.312953472137451,5.142138481140137,4.842616081237793,4.453446865081787,4.819000720977783,4.936886310577393,4.719335556030273,4.45820426940918,4.555344581604004,4.542990684509277,4.75466775894165,5.064374923706055,5.090826034545898,4.880397319793701,5.181282997131348,4.928310394287109,4.386595249176025,4.722841262817383],\"y\":[3.895690441131592,4.49151086807251,4.4832763671875,4.436058044433594,3.8097774982452393,4.050317287445068,4.350984573364258,4.233912467956543,4.253161430358887,4.41158390045166,4.410125732421875,4.211334705352783,4.085710048675537,4.058773040771484,4.25853967666626,4.427093505859375,4.1149492263793945,3.6297852993011475,4.379383087158203,4.04008674621582,4.01918888092041,4.115949630737305,4.419804096221924,4.2325358390808105,4.208754062652588,3.9426774978637695,4.13971471786499,4.125072479248047,3.65316104888916,4.133758544921875,3.847452402114868,4.448775768280029,4.166215896606445],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Automatic Unsupervised Outlier Model Selection\",\"How Fine-Tuning Allows for Effective Meta-Learning\",\"Memory Efficient Meta-Learning with Large Images\",\"Meta-learning with an Adaptive Task Scheduler\",\"Generalization of Model-Agnostic Meta-Learning Algorithms: Recurring and Unseen Tasks\",\"Noether Networks: meta-learning useful conserved quantities\",\"Towards Enabling Meta-Learning from Target Models\",\"Learning where to learn: Gradient sparsity in meta and continual learning\",\"Two Sides of Meta-Learning Evaluation: In vs. Out of Distribution\",\"On sensitivity of meta-learning to support data\",\"Meta-Learning Reliable Priors in the Function Space\",\"Meta-Learning for Relative Density-Ratio Estimation\",\"Revisit Multimodal Meta-Learning through the Lens of Multi-Task Learning\",\"Functionally Regionalized Knowledge Transfer for Low-resource Drug Discovery\",\"Meta-learning to Improve Pre-training\",\"Towards Sample-efficient Overparameterized Meta-learning\",\"Conflict-Averse Gradient Descent for Multi-task learning\",\"Bridging the Gap Between Practice and PAC-Bayes Theory in Few-Shot Meta-Learning\",\"Effective Meta-Regularization by Kernelized Proximal Regularization\",\"Efficiently Identifying Task Groupings for Multi-Task Learning\",\"Meta Learning Backpropagation And Improving It\",\"Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis\",\"Online Meta-Learning via Learning with Layer-Distributed Memory\",\"Tailoring: encoding inductive biases by optimizing unsupervised objectives at prediction time\",\"Multi-Objective Meta Learning\",\"Statistically and Computationally Efficient Linear Meta-representation Learning\",\"EvoGrad: Efficient Gradient-Based Meta-Learning and Hyperparameter Optimization\",\"Gradient-based Hyperparameter Optimization Over Long Horizons\",\"Generalization Bounds for Meta-Learning via PAC-Bayes and Uniform Stability\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"18_metalearning_tasks_task\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"18_metalearning_tasks_task\"],\"textfont\":{\"size\":12},\"x\":[3.2481589317321777,3.2905781269073486,3.2791876792907715,3.324878692626953,3.3085739612579346,3.4004034996032715,3.29905104637146,3.357635974884033,3.2580604553222656,3.082303762435913,3.306222915649414,3.3593273162841797,3.21732759475708,3.1003518104553223,3.203956127166748,3.334392547607422,3.3218719959259033,3.229085922241211,3.350507974624634,3.2983453273773193,3.3578240871429443,3.310640811920166,3.317936420440674,3.3715579509735107,3.3056280612945557,3.2406020164489746,3.3643956184387207,3.5507194995880127,3.304495334625244,3.2997937202453613],\"y\":[3.746790885925293,3.7980520725250244,3.9344494342803955,3.781745672225952,3.772347927093506,3.7866547107696533,3.769125461578369,3.9104089736938477,3.7332265377044678,3.871832847595215,3.730309247970581,3.841966390609741,3.901430606842041,3.754539966583252,3.8665597438812256,3.8112096786499023,3.8172550201416016,3.77541184425354,3.8553693294525146,3.865133285522461,3.92395281791687,3.7866735458374023,3.9037227630615234,3.8149428367614746,3.7983922958374023,3.823409080505371,3.9167702198028564,4.080828666687012,3.7460975646972656,3.8316760063171387],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"A Gaussian Process-Bayesian Bernoulli Mixture Model for Multi-Label Active Learning\",\"Certifying Robustness to Programmable Data Bias in Decision Trees\",\"Sample Selection for Fair and Robust Training\",\"Scalable and Stable Surrogates for Flexible Classifiers with Fairness Constraints\",\"Retiring Adult: New Datasets for Fair Machine Learning\",\"When False Positive is Intolerant: End-to-End  Optimization with Low FPR for Multipartite Ranking\",\"Assessing Fairness in the Presence of Missing Data\",\"Unintended Selection: Persistent Qualification Rate Disparities and Interventions\",\"Can Information Flows Suggest Targets for Interventions in Neural Circuits?\",\"AutoBalance: Optimized Loss Functions for Imbalanced Data\",\" Boosted CVaR Classification\",\"Label-Imbalanced and Group-Sensitive Classification under Overparameterization\",\"Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence\",\"Does enforcing fairness mitigate biases caused by subpopulation shift?\",\"Learning Optimal Predictive Checklists\",\"Post-processing for Individual Fairness\",\"Fairness via Representation Neutralization\",\"Fair Sequential Selection Using Supervised Learning Models\",\"Rethinking and Reweighting the Univariate Losses for Multi-Label Ranking: Consistency and Generalization\",\"Good Classification Measures and How to Find Them\",\"Mixture Proportion Estimation and PU Learning:A Modern Approach\",\"Are My Deep Learning Systems Fair? An Empirical Study of Fixed-Seed Training\",\"Neural Pseudo-Label Optimism for the Bank Loan Problem\",\"DECAF:  Generating Fair Synthetic Data Using Causally-Aware Generative Networks\",\"Learning Models for Actionable Recourse\",\"Adaptive Sampling for Minimax Fair Classification\",\"Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes\",\"Training Over-parameterized Models with Non-decomposable Objectives\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"19_fairness_data_classification\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"19_fairness_data_classification\"],\"textfont\":{\"size\":12},\"x\":[5.595175266265869,5.003562927246094,5.4172492027282715,5.428616523742676,5.447485446929932,5.155884742736816,5.491466522216797,5.284214973449707,5.434675693511963,5.214673042297363,5.270035743713379,5.262922763824463,5.073967933654785,5.449533939361572,5.120628356933594,5.437178611755371,5.409801959991455,5.448732376098633,5.464625835418701,5.401425838470459,5.338979244232178,5.434764862060547,4.867700576782227,5.433911323547363,4.899816989898682,5.280909061431885,5.164494514465332,5.1737284660339355,5.300220012664795],\"y\":[2.9892003536224365,3.508822441101074,3.580533504486084,3.528808116912842,3.5917599201202393,3.4276039600372314,3.5992839336395264,3.446793794631958,3.5442492961883545,3.4314143657684326,3.375670909881592,3.39532732963562,3.410384178161621,3.563646078109741,3.5272371768951416,3.561629056930542,3.530588388442993,3.5700266361236572,3.1410915851593018,3.170917272567749,3.2762210369110107,3.5464253425598145,3.4015979766845703,3.655130624771118,3.360490560531616,3.422158718109131,3.415165424346924,3.455920934677124,3.4438607692718506],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Exploiting Domain-Specific Features to Enhance Domain Generalization\",\"On Learning Domain-Invariant Representations for Transfer Learning with Multiple Sources\",\"Pareto Domain Adaptation\",\"Understanding the Limits of Unsupervised Domain Adaptation via Data Poisoning\",\"Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?\",\"Adversarial Reweighting for Partial Domain Adaptation\",\"Confident Anchor-Induced Multi-Source Free Domain Adaptation\",\"Quantifying and Improving Transferability in Domain Generalization\",\"Gradual Domain Adaptation without Indexed Intermediate Domains\",\"Implicit Semantic Response Alignment for Partial Domain Adaptation\",\"A Prototype-Oriented Framework for Unsupervised Domain Adaptation\",\"Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data\",\"The balancing principle for parameter choice in distance-regularized domain adaptation\",\"Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation\",\"ToAlign: Task-Oriented Alignment for Unsupervised Domain Adaptation\",\"Leveraging Distribution Alignment via Stein Path for Cross-Domain Cold-Start Recommendation\",\"TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation\",\"CLDA: Contrastive Learning for Semi-Supervised Domain Adaptation\",\"Unsupervised Noise Adaptive Speech Enhancement by Discriminator-Constrained Optimal Transport\",\"Implicit Task-Driven Probability Discrepancy Measure for Unsupervised Domain Adaptation\",\"Reducing the Covariate Shift by Mirror Samples in Cross Domain Alignment\",\"Domain Invariant Representation Learning with Domain Density Transformations\",\"Adversarial Teacher-Student Representation Learning for Domain Generalization\",\"Cycle Self-Training for Domain Adaptation\",\"argmax centroid\",\"Learning to Adapt via Latent Domains for Adaptive Semantic Segmentation\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"20_domain_adaptation_source\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"20_domain_adaptation_source\"],\"textfont\":{\"size\":12},\"x\":[3.8926236629486084,3.9241280555725098,3.736515998840332,3.726074695587158,3.9083259105682373,3.8111958503723145,3.6817846298217773,4.035050392150879,3.7033634185791016,3.6812164783477783,3.6775736808776855,3.6864941120147705,3.7020511627197266,3.692326068878174,3.7013542652130127,3.8649065494537354,3.6655123233795166,3.685776710510254,3.7319395542144775,3.73380184173584,3.7027833461761475,3.935023307800293,3.9106738567352295,3.668419361114502,3.838648796081543,3.6886937618255615,3.7687020301818848],\"y\":[2.987442970275879,3.0205161571502686,2.7916650772094727,2.7874157428741455,3.003584623336792,2.8379316329956055,2.744248628616333,3.13704514503479,2.774697780609131,2.744532346725464,2.729188919067383,2.738983392715454,2.7707624435424805,2.7567403316497803,2.7634973526000977,3.020944118499756,2.7317020893096924,2.7756075859069824,2.7793281078338623,2.7937991619110107,2.759812831878662,3.0580661296844482,3.0157830715179443,2.7598514556884766,2.960556983947754,2.755737066268921,2.846132516860962],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Spatio-Temporal Variational Gaussian Processes\",\"A variational approximate posterior for the deep Wishart process\",\"Scalable Inference of Sparsely-changing Gaussian Markov Random Fields \",\"Marginalised Gaussian Processes with Nested Sampling\",\"Online Variational Filtering and Parameter Learning\",\"Deconditional Downscaling with Gaussian Processes\",\"Conditioning Sparse Variational Gaussian Processes for Online Decision-making\",\"Fast Bayesian Inference for Gaussian Cox Processes via Path Integral Formulation\",\"Row-clustering of a Point Process-valued Matrix\",\"Non-Gaussian Gaussian Processes for Few-Shot Regression\",\"Dual Parameterization of Sparse Variational Gaussian Processes\",\"Dynamical Wasserstein Barycenters for Time-series Modeling\",\"Efficient methods for Gaussian Markov random fields under sparse linear constraints\",\"Continuous Latent Process Flows\",\"Modular Gaussian Processes for Transfer Learning\",\"Vector-valued Gaussian Processes on Riemannian Manifolds via Gauge Independent Projected Kernels\",\"Linear-Time Probabilistic Solution of Boundary Value Problems\",\"On Contrastive Representations of Stochastic Processes\",\"Functional Variational Inference based on Stochastic Process Generators\",\"Continuous-time edge modelling using non-parametric point processes\",\"Compositional Modeling of Nonlinear Dynamical Systems with ODE-based Random Features\",\"Scaling Gaussian Processes with Derivative Information Using Variational Inference\",\"Black Box Probabilistic Numerics\",\"Learning Nonparametric Volterra Kernels with Gaussian Processes\",\"Deep Explicit Duration Switching Models for Time Series\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"21_processes_gaussian_gaussian processes\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"21_processes_gaussian_gaussian processes\"],\"textfont\":{\"size\":12},\"x\":[5.217749118804932,5.0693745613098145,5.3637471199035645,5.222273826599121,5.002015590667725,5.1722540855407715,5.249944686889648,5.239330768585205,5.3026909828186035,5.1735076904296875,5.238581657409668,5.0244975090026855,5.295557498931885,5.105544567108154,5.236741065979004,5.126407146453857,5.364651203155518,5.12241792678833,4.92131233215332,5.189866065979004,5.181088924407959,5.215312480926514,5.481094837188721,5.2272138595581055,5.010478973388672,5.190146446228027],\"y\":[6.808567047119141,6.600924491882324,6.697770118713379,6.657611846923828,6.9811110496521,6.648296356201172,6.772158145904541,6.797800540924072,6.7186174392700195,6.69992733001709,6.727316856384277,7.060735702514648,6.731500148773193,6.970092296600342,6.704309940338135,6.63344144821167,6.618669033050537,6.824801445007324,6.689651012420654,6.829967498779297,6.7029523849487305,6.681628704071045,6.472380638122559,6.6614813804626465,7.112929821014404,6.752185821533203],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Variational Continual Bayesian Meta-Learning\",\"Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning\",\"Mitigating Forgetting in Online Continual Learning with  Neuron Calibration\",\"Class-Incremental Learning via Dual Augmentation\",\"Flattening Sharpness for Dynamic Gradient Projection Memory Benefits Continual Learning\",\"BNS: Building Network Structures Dynamically for Continual Learning\",\"Natural continual learning: success is a journey, not (just) a destination\",\"Optimizing Reusable Knowledge for Continual Learning via Metalearning\",\"AFEC: Active Forgetting of Negative Transfer in Continual Learning\",\"Gradient-based Editing of Memory Examples for Online Task-free Continual Learning\",\"Continual Learning via Local Module Composition\",\"DualNet: Continual Learning, Fast and Slow\",\"On Plasticity, Invariance, and Mutually Frozen Weights in Sequential Task Learning\",\"Generative vs. Discriminative: Rethinking The Meta-Continual Learning\",\"Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima\",\"Formalizing the Generalization-Forgetting Trade-off in Continual Learning\",\"Knowledge-Adaptation Priors\",\"RMM: Reinforced Memory Management for Class-Incremental Learning\",\"Lifelong Domain Adaptation via Consolidated Internal Distribution\",\"Continual World: A Robotic Benchmark For Continual Reinforcement Learning\",\"Posterior Meta-Replay for Continual Learning\",\"Bridging Non Co-occurrence with Unlabeled In-the-wild Data for Incremental Object Detection\",\"SSUL: Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"22_continual_continual learning_forgetting\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"22_continual_continual learning_forgetting\"],\"textfont\":{\"size\":12},\"x\":[3.4245784282684326,3.4288153648376465,3.422299385070801,3.2942543029785156,3.4198157787323,3.429311990737915,3.404756784439087,3.4121150970458984,3.4214162826538086,3.371652364730835,3.4131553173065186,3.4207911491394043,3.43369197845459,3.406477689743042,3.322615146636963,3.415919303894043,3.4068570137023926,3.3626441955566406,3.3925817012786865,3.4175915718078613,3.4182190895080566,3.3346424102783203,3.3278398513793945,3.3957412242889404],\"y\":[9.026310920715332,9.05123233795166,9.034875869750977,8.901800155639648,9.03534984588623,9.064373016357422,9.051128387451172,9.035040855407715,9.030982971191406,8.988542556762695,9.036615371704102,9.053852081298828,8.944190979003906,9.016304016113281,8.931713104248047,9.072742462158203,9.002436637878418,8.978053092956543,9.007661819458008,9.04051685333252,9.025260925292969,8.95236873626709,8.928905487060547,9.009140968322754],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"FMMformer: Efficient and Flexible Transformer via Decomposed Near-field and Far-field Attention\",\"Scatterbrain: Unifying Sparse and Low-rank Attention\",\"CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings\",\"Searching for Efficient Transformers for Language Modeling\",\"Luna: Linear Unified Nested Attention\",\"Sub-Linear Memory: How to Make Performers SLiM\",\"SOFT: Softmax-free Transformer with Linear Complexity\",\"Skyformer: Remodel Self-Attention with Gaussian Kernel and Nystr\\\\\\\"om Method\",\"Combiner: Full Attention Transformer with Sparse Computation Cost\",\"Attention Approximates Sparse Distributed Memory\",\"Compacter: Efficient Low-Rank Hypercomplex Adapter Layers\",\"Fast Multi-Resolution Transformer Fine-tuning for Extreme Multi-label Text Classification\",\"DRONE: Data-aware Low-rank Compression for Large NLP Models\",\"Long-Short Transformer: Efficient Transformers for Language and Vision\",\"Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding\",\"GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training\",\"NxMTransformer: Semi-Structured Sparsification for Natural Language Understanding via ADMM\",\"Shapeshifter: a Parameter-efficient Transformer using Factorized Reshaped Matrices\",\"Sparse is Enough in Scaling Transformers\",\"Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems\",\"Choose a Transformer: Fourier or Galerkin\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"23_attention_transformer_lowrank\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"23_attention_transformer_lowrank\"],\"textfont\":{\"size\":12},\"x\":[1.7826143503189087,1.7834850549697876,1.8591276407241821,1.79286527633667,1.6682637929916382,1.7597910165786743,1.861811637878418,1.8245898485183716,1.7707124948501587,1.8005867004394531,1.7026995420455933,1.7788368463516235,1.7309210300445557,1.943644404411316,1.8235421180725098,1.906532645225525,1.7850593328475952,1.7047159671783447,1.7842960357666016,1.7959762811660767,1.8496944904327393,1.7957029342651367],\"y\":[5.444819450378418,5.416059494018555,5.4784135818481445,5.400382995605469,5.3930535316467285,5.46061897277832,5.4883036613464355,5.491921901702881,5.474546909332275,5.453568458557129,5.292346000671387,5.3348541259765625,5.347545146942139,5.466842174530029,5.494087219238281,5.323827743530273,5.350746154785156,5.2809576988220215,5.390938758850098,5.484118938446045,5.47435188293457,5.416300296783447],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"A 3D Generative Model for Structure-Based Drug Design\",\"GeoMol: Torsional Geometric Generation of Molecular 3D Conformer Ensembles\",\"Co-evolution Transformer for Protein Contact Prediction\",\"Learning Graph Models for Retrosynthesis Prediction\",\"Vector-valued Distance and Gyrocalculus on the Space of Symmetric Positive Definite Matrices\",\"SE(3)-equivariant prediction of molecular wavefunctions and electronic densities\",\"Deep Molecular Representation Learning via Fusing Physical and Chemical Information\",\"Directional Message Passing on Molecular Graphs via Synthetic Coordinates\",\"GemNet: Universal Directional Graph Neural Networks for Molecules\",\"Matrix factorisation and the interpretation of geodesic distance\",\"Hit and Lead Discovery with Explorative RL and Fragment-based Molecule Generation\",\"Motif-based Graph Self-Supervised Learning for Molecular Property Prediction\",\"Property-Aware Relation Networks for Few-Shot Molecular Property Prediction\",\"Distilling Meta Knowledge on Heterogeneous Graph for Illicit Drug Trafficker Detection on Social Media\",\"Capacity and Bias of Learned Geometric Embeddings for Directed Graphs\",\"Hyperbolic Procrustes Analysis Using Riemannian Geometry\",\"Multi-Scale Representation Learning on Proteins\",\"Neural Distance Embeddings for Biological Sequences\",\"Predicting Molecular Conformation via Dynamic Graph Score Matching\",\"Representing Hyperbolic Space Accurately using Multi-Component Floats\",\"Towards understanding retrosynthesis by energy-based models\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"24_molecular_molecules_drug\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"24_molecular_molecules_drug\"],\"textfont\":{\"size\":12},\"x\":[1.0230244398117065,1.0350229740142822,1.4749338626861572,1.0070586204528809,1.5777502059936523,1.038501262664795,1.0370844602584839,1.0412572622299194,1.0443732738494873,1.7990448474884033,1.0387901067733765,1.0635550022125244,1.0991913080215454,2.0611796379089355,1.543771743774414,1.5514878034591675,1.4777125120162964,1.5621159076690674,1.0374186038970947,1.530167579650879,1.0384119749069214,1.289612054824829],\"y\":[3.0593268871307373,3.051349639892578,3.381542444229126,3.0480732917785645,3.244309186935425,3.0477418899536133,3.048095703125,3.0390536785125732,3.0476019382476807,3.0881173610687256,3.087775707244873,2.9954936504364014,3.0913314819335938,2.4077308177948,3.2737691402435303,3.3177435398101807,3.293332576751709,3.3190581798553467,3.0506813526153564,3.3523435592651367,3.0544726848602295,3.109473466873169],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Characterizing possible failure modes in physics-informed neural networks\",\"SAPE: Spatially-Adaptive Progressive Encoding for Neural Optimization\",\"NTopo: Mesh-free Topology Optimization using Implicit Neural Representations\",\"Accurately Solving Rod Dynamics with Graph Learning\",\"Heavy Ball Neural Ordinary Differential Equations\",\"Conditionally Parameterized, Discretization-Aware Neural Networks for Mesh-Based Modeling of Physical Systems\",\"Efficient and Accurate Gradients for Neural SDEs\",\"Second-Order Neural ODE Optimizer\",\"Stateful ODE-Nets using Basis Function Expansions\",\"Multiwavelet-based Operator Learning for Differential Equations\",\"DNN-based Topology Optimisation:  Spatial Invariance and Neural Tangent Kernel\",\"Neural Flows: Efficient Alternative to Neural ODEs\",\"Framing RNN as a kernel method: A neural ODE approach\",\"LSH-SMILE: Locality Sensitive Hashing Accelerated Simulation and Learning\",\"PDE-GCN: Novel Architectures for Graph Neural Networks Motivated by Partial Differential Equations\",\"Differentiable Multiple Shooting Layers\",\"Symplectic Adjoint Method for Exact Gradient of Neural ODE with Minimal Memory\",\"Sparse Flows: Pruning Continuous-depth Models\",\"Parameter Inference with Bifurcation Diagrams\",\"Noisy Recurrent Neural Networks\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"25_neural_differential_differential equations\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"25_neural_differential_differential equations\"],\"textfont\":{\"size\":12},\"x\":[4.420780181884766,4.090820789337158,4.187465667724609,6.196145057678223,4.314940929412842,4.41532564163208,4.839496612548828,4.32161808013916,4.238587856292725,4.340628623962402,4.184372901916504,4.382853984832764,4.485737323760986,4.407100200653076,4.3781609535217285,4.3374528884887695,4.33841609954834,4.284165382385254,4.415652275085449,4.683536529541016,4.463162899017334],\"y\":[6.063581466674805,5.805236339569092,5.856333255767822,8.288269996643066,6.012856483459473,6.060664176940918,5.9796648025512695,6.042635917663574,6.029359340667725,5.746974468231201,5.859081268310547,6.082721710205078,5.944032192230225,6.114992618560791,5.897457599639893,6.066339015960693,6.065272331237793,6.08613920211792,6.1254401206970215,5.671498775482178,6.089927673339844],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Label consistency in overfitted generalized $k$-means\",\"Robust Online Correlation Clustering\",\"Memory-Efficient Approximation Algorithms for Max-k-Cut and Correlation Clustering\",\"Fuzzy Clustering with Similarity Queries\",\"Online Facility Location with Multiple Advice\",\"Better Algorithms for Individually Fair $k$-Clustering\",\"Nearly-Tight and Oblivious Algorithms for Explainable Clustering\",\"Coresets for Clustering with Missing Values\",\"Parallel and Efficient Hierarchical k-Median Clustering\",\"Coresets for Time Series Clustering\",\"A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering\",\"Permuton-induced Chinese Restaurant Process\",\"Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter\",\"Fair Clustering Under a Bounded Cost\",\"Coresets for Decision Trees of Signals\",\"SPANN: Highly-efficient Billion-scale Approximate Nearest Neighborhood Search\",\"On Margin-Based Cluster Recovery with Oracle Queries\",\" Practical Near Neighbor Search via Group Testing\",\"Uniform Concentration Bounds toward a Unified  Framework for Robust Clustering\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"26_clustering_kmeans_points\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"26_clustering_kmeans_points\"],\"textfont\":{\"size\":12},\"x\":[6.57395601272583,6.470278263092041,6.539804935455322,6.51477575302124,6.442580699920654,6.595676898956299,6.615048408508301,6.659103870391846,6.619853496551514,6.6231584548950195,6.636537075042725,6.626739501953125,6.591334342956543,6.516396999359131,6.601009368896484,6.448639869689941,6.589911460876465,6.305300235748291,6.627371311187744,6.5577616691589355],\"y\":[3.291259288787842,3.1986167430877686,3.281532049179077,3.248652458190918,3.1750195026397705,3.322208881378174,3.3359155654907227,3.3214972019195557,3.3288378715515137,3.3940834999084473,3.326913595199585,3.3165292739868164,3.3454742431640625,3.412494659423828,3.364574432373047,3.221029281616211,3.2957963943481445,3.1685922145843506,3.3193747997283936,3.2983367443084717],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Fast Federated Learning in the Presence of Arbitrary Device Unavailability\",\"Federated Multi-Task Learning under a Mixture of Distributions\",\"Validation Free and Replication Robust Volume-based Data Valuation\",\"Breaking the centralized barrier for cross-device federated learning\",\"Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning\",\"Personalized Federated Learning With Gaussian Processes\",\"QuPeD: Quantized Personalization via Distillation with Applications to Federated Learning\",\"Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee\",\"PartialFed: Cross-Domain Personalized Federated Learning via Partial Initialization\",\"Addressing Algorithmic Disparity and Performance Inconsistency in Federated Learning\",\"Few-Round Learning for Federated Learning\",\"Test-time Collective Prediction\",\"Parameterized Knowledge Transfer for Personalized Federated Learning\",\"Distributed Deep Learning In Open Collaborations\",\"Federated Reconstruction: Partially Local Federated Learning\",\"On Large-Cohort Training for Federated Learning\",\"FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout\",\"Locality Sensitive Teaching\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"27_federated_federated learning_clients\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"27_federated_federated learning_clients\"],\"textfont\":{\"size\":12},\"x\":[8.787252426147461,8.80561637878418,8.810646057128906,8.711265563964844,8.797628402709961,8.868721961975098,8.853489875793457,8.839498519897461,8.991250991821289,8.78158187866211,8.787545204162598,8.81070613861084,8.847179412841797,8.73219108581543,8.839770317077637,8.796121597290039,8.787636756896973,8.766676902770996,8.811931610107422],\"y\":[4.117389678955078,4.084713459014893,4.061554908752441,4.153315544128418,4.071102142333984,3.9966742992401123,4.049344062805176,4.129249572753906,4.002670764923096,4.1103291511535645,4.112889766693115,4.07647180557251,4.0529069900512695,4.099018096923828,4.067631244659424,4.115513324737549,4.109513282775879,4.135382175445557,4.085870742797852],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Fine-Grained Neural Network Explanation by Identifying Input Features with Predictive Information\",\"Controlling Neural Networks with Rule Representations\",\"Using Random Effects to Account for High-Cardinality Categorical Features and Repeated Measures in Deep Neural Networks\",\"Discerning Decision-Making Process of Deep Neural Networks with Hierarchical Voting Transformation\",\"Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach\",\"The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations\",\"Self-Interpretable Model with Transformation Equivariant Interpretation\",\"Foundations of Symbolic Languages for Model Interpretability\",\"Shapley Residuals: Quantifying the limits of the Shapley value for explanations\",\"Reliable Post hoc Explanations: Modeling Uncertainty in Explainability\",\"On Locality of Local Explanation Models\",\"Open Rule Induction\",\"A Framework to Learn with Interpretation\",\"Provably efficient, succinct, and precise explanations\",\"Neural Additive Models: Interpretable Machine Learning with Neural Nets\",\"Scalable Rule-Based Representation Learning for Interpretable Classification\",\"From global to local MDI variable importances for random forests and when they are Shapley values\",\"The effectiveness of feature attribution methods and its correlation with automatic evaluation scores\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"28_rules_explanations_shapley\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"28_rules_explanations_shapley\"],\"textfont\":{\"size\":12},\"x\":[4.147654056549072,4.3451828956604,4.221569538116455,4.176037311553955,4.354535102844238,4.295960426330566,3.951770544052124,4.369049072265625,4.290690898895264,4.323302268981934,4.291586399078369,4.311152458190918,4.163650989532471,4.357591152191162,4.279886722564697,4.373933792114258,4.3042802810668945,4.021190166473389,4.254390239715576],\"y\":[3.9064791202545166,3.7310054302215576,3.9542088508605957,3.9047160148620605,3.7277722358703613,3.6414031982421875,4.0960187911987305,3.694913625717163,3.6356823444366455,3.6612296104431152,3.627197027206421,3.752155303955078,3.93127703666687,3.682222843170166,3.8383078575134277,3.7161293029785156,3.638843059539795,3.8814961910247803,3.778947114944458],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"On Riemannian Optimization over Positive Definite Matrices with the Bures-Wasserstein Geometry\",\"Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent\",\"Modified Frank Wolfe in Probability Space\",\"Generalization Bounds for (Wasserstein) Robust Optimization\",\"On Robust Optimal Transport: Computational Complexity and Barycenter Computation\",\"Optimal Rates for Nonparametric Density Estimation under Communication Constraints\",\"Optimal Underdamped Langevin MCMC Method\",\"Non-asymptotic convergence bounds for Wasserstein approximation using point clouds\",\"A novel notion of barycenter for probability distributions based on optimal weak mass transport\",\"The Unbalanced Gromov Wasserstein Distance: Conic Formulation and Relaxation\",\"No-regret Online Learning over Riemannian Manifolds\",\"Rates of Estimation of Optimal Transport Maps using Plug-in Estimators via  Barycentric Projections\",\"Optimizing Information-theoretical Generalization Bound via Anisotropic Noise of SGLD\",\"Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark\",\"Time-independent Generalization Bounds for SGLD in Non-convex Settings\",\"KALE Flow: A Relaxed KL Gradient Flow for Probabilities with Disjoint Support\",\"An analysis of Ermakov-Zolotukhin quadrature using kernels\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"29_transport_optimal_optimal transport\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"29_transport_optimal_optimal transport\"],\"textfont\":{\"size\":12},\"x\":[6.2986273765563965,6.209418773651123,6.090302467346191,6.118443012237549,6.157926082611084,6.1205058097839355,6.037491321563721,6.123278617858887,6.148805141448975,6.115907192230225,6.296574592590332,6.131018161773682,6.268112659454346,5.88347864151001,6.1343817710876465,6.055749893188477,5.991613864898682,6.128331184387207],\"y\":[5.003904342651367,5.077815055847168,5.268256187438965,5.156038284301758,5.151235103607178,5.184927940368652,5.783600330352783,5.124507904052734,5.107537746429443,5.150050163269043,5.019925594329834,5.156951904296875,5.584355354309082,5.312405586242676,5.6919426918029785,5.136268138885498,5.016541481018066,5.23095703125],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"RelaySum for Decentralized Deep Learning on Heterogeneous Data\",\"Moshpit SGD: Communication-Efficient Decentralized Training on Heterogeneous Unreliable Devices\",\"Asynchronous Decentralized Online Learning\",\"FedDR \\u2013 Randomized Douglas-Rachford Splitting Algorithms for Nonconvex Federated Composite Optimization\",\"DRIVE: One-bit Distributed Mean Estimation\",\"CANITA: Faster Rates for Distributed Convex Optimization with Communication Compression\",\"Fast Training  Method for  Stochastic Compositional Optimization Problems\",\"Communication-efficient SGD: From Local SGD to One-Shot Averaging\",\"Delayed Gradient Averaging: Tolerate the Communication Latency for Federated Learning\",\"Preserved central model for faster bidirectional compression in distributed settings\",\"Linear Convergence in Federated Learning: Tackling Client Heterogeneity and Sparse Gradients\",\"Collaborative Learning in the Jungle (Decentralized, Byzantine, Heterogeneous, Asynchronous and Nonconvex Learning)\",\"Asynchronous Decentralized SGD with Quantized and Local Updates\",\"Exponential Graph is Provably Efficient for Decentralized Deep Training\",\"STEM: A Stochastic Two-Sided Momentum Algorithm Achieving Near-Optimal Sample and Communication Complexities for Federated Learning\",\"Leveraging Spatial and Temporal Correlations in Sparsified Mean Estimation\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"30_communication_decentralized_averaging\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"30_communication_decentralized_averaging\"],\"textfont\":{\"size\":12},\"x\":[8.568106651306152,8.569511413574219,8.56281566619873,8.488886833190918,8.362639427185059,8.072245597839355,8.192296981811523,7.966909885406494,8.562104225158691,8.226375579833984,8.543177604675293,8.554349899291992,8.563203811645508,8.567155838012695,8.562225341796875,8.462124824523926,8.426507949829102],\"y\":[4.39186429977417,4.404978275299072,4.408596515655518,4.265305519104004,4.304244518280029,4.4944915771484375,4.496374607086182,4.546463966369629,4.296104907989502,4.396335124969482,4.258264541625977,4.422513008117676,4.403160095214844,4.405063152313232,4.2690863609313965,4.251709938049316,4.375909805297852],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Information-theoretic generalization bounds for black-box learning algorithms\",\"Tighter Expected Generalization Error Bounds via Wasserstein Distance\",\"Localization, Convexity, and Star Aggregation\",\"On Empirical Risk Minimization with Dependent and Heavy-Tailed Data\",\"How Tight Can PAC-Bayes be in the Small Data Regime?\",\"Risk Monotonicity in Statistical Learning\",\"Towards Sharper Generalization Bounds for Structured Prediction\",\"Sequential Algorithms for Testing Closeness of Distributions\",\"Dimension-free empirical entropy estimation\",\"Perturbation Theory for the Information Bottleneck\",\"A Surrogate Objective Framework for Prediction+Programming with Soft Constraints\",\"Risk Bounds and Calibration for a Smart Predict-then-Optimize Method\",\"Towards a Unified Information-Theoretic Framework for Generalization\",\"Unifying lower bounds on prediction dimension of convex surrogates\",\"Surrogate Regret Bounds for Polyhedral Losses\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"31_bounds_risk_cmi\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"31_bounds_risk_cmi\"],\"textfont\":{\"size\":12},\"x\":[6.486023902893066,6.455374240875244,6.868059158325195,6.934907913208008,6.554332733154297,6.909544944763184,6.659110069274902,7.651666164398193,6.500954627990723,6.7381110191345215,6.939208507537842,6.913772106170654,6.570589065551758,6.753900527954102,6.956846714019775,6.7928266525268555],\"y\":[5.16160249710083,5.13303279876709,4.95619535446167,4.956432819366455,5.303157806396484,5.043166637420654,5.131610870361328,5.946619987487793,5.1395769119262695,5.140657901763916,5.206524848937988,5.131392955780029,5.089956283569336,5.099569797515869,5.064293384552002,5.166919231414795],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Task-Adaptive Neural Network Search with Meta-Contrastive Learning\",\"NAS-Bench-x11 and the Power of Learning Curves\",\"Speedy Performance Estimation for Neural Architecture Search\",\"Federated Hyperparameter Tuning: Challenges, Baselines, and Connections to Weight-Sharing\",\"Stronger NAS with Weaker Predictors\",\"TNASP: A Transformer-based NAS Predictor with a Self-evolution Framework\",\"Neural Routing by Memory\",\"Hardware-adaptive Efficient Latency Prediction for NAS via Meta-Learning\",\"Evaluating Efficient Performance Estimators of Neural Architectures\",\"Reverse engineering learned optimizers reveals known and novel mechanisms\",\"How Powerful are Performance Predictors in Neural Architecture Search?\",\"SimiGrad: Fine-Grained Adaptive Batching for Large Scale Training using Gradient Similarity Measurement\",\"Graph Differentiable Architecture Search with Structure Learning\",\"Generic Neural Architecture Search via Regression\",\"L2ight: Enabling On-Chip Learning for Optical Neural Networks via Efficient in-situ Subspace Optimization\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"32_nas_search_architecture\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"32_nas_search_architecture\"],\"textfont\":{\"size\":12},\"x\":[3.4338717460632324,3.4414188861846924,3.4591012001037598,3.562654733657837,3.42435884475708,3.433006525039673,3.301563262939453,3.429575204849243,3.440138578414917,3.779557466506958,3.4479875564575195,3.664414167404175,3.3856217861175537,3.3790524005889893,3.509840726852417,3.4728105068206787],\"y\":[4.338493347167969,4.403834819793701,4.408400058746338,4.347921848297119,4.403714179992676,4.4101409912109375,4.473690509796143,4.398313522338867,4.402400970458984,4.436459064483643,4.40848445892334,4.183475017547607,4.366736888885498,4.420875549316406,4.861683368682861,4.417641639709473],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Online Active Learning with Surrogate Loss Functions\",\"Learning with Labeling Induced Abstentions\",\"Neural Active Learning with Performance Guarantees\",\"Diversity Enhanced Active Learning with Strictly Proper Scoring Rules\",\"Online Selective Classification with Limited Feedback\",\"Teaching an Active Learner with Contrastive Examples\",\"Active clustering for labeling training data\",\"Iterative Teaching by Label Synthesis\",\"LADA: Look-Ahead Data Acquisition via Augmentation for Deep Active Learning\",\"Efficient Active Learning for Gaussian Process Classification by Error Reduction\",\"Gone Fishing: Neural Active Learning with Fisher Embeddings\",\"Batch Active Learning at Scale\",\"Corruption Robust Active Learning\",\"SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"33_active learning_active_acquisition\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"33_active learning_active_acquisition\"],\"textfont\":{\"size\":12},\"x\":[5.862464427947998,5.831963539123535,5.8571248054504395,5.869414806365967,8.789843559265137,5.769258975982666,5.974503040313721,5.7555036544799805,5.877590656280518,5.872673511505127,5.885833740234375,5.863436698913574,5.538629531860352,5.868008613586426,6.044017791748047],\"y\":[2.896928548812866,2.9020912647247314,2.9509360790252686,2.905143976211548,6.510921478271484,2.846243143081665,2.95977783203125,2.9126193523406982,2.911088466644287,2.9297420978546143,2.9062018394470215,2.900919198989868,2.667389392852783,2.9082682132720947,3.1505908966064453],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Unfolding Taylor's Approximations for Image Restoration\",\"Robust Compressed Sensing MRI with Deep Generative Priors\",\"Adaptive Denoising via GainTuning\",\"A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image Restoration\",\"End-to-end reconstruction meets data-driven regularization for inverse problems\",\"SNIPS: Solving Noisy Inverse Problems Stochastically\",\"Finding Discriminative Filters for Specific Degradations in Blind Super-Resolution\",\"Noise2Score: Tweedie\\u2019s Approach to Self-Supervised Image Denoising without Clean Images\",\"DeepGEM: Generalized Expectation-Maximization for Blind Inversion\",\"Recovery Analysis for Plug-and-Play Priors using the Restricted Eigenvalue Condition\",\"Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser\",\"It Has Potential: Gradient-Driven Denoisers for Convergent Solutions to Inverse Problems\",\"Functional Neural Networks for Parametric Image Restoration Problems\",\"Inverse Problems Leveraging Pre-trained Contrastive Representations\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"34_restoration_denoising_image\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"34_restoration_denoising_image\"],\"textfont\":{\"size\":12},\"x\":[3.0327789783477783,3.145141124725342,3.0888991355895996,3.0666568279266357,3.1512675285339355,3.1259241104125977,2.8658268451690674,3.1400468349456787,3.1634206771850586,3.1210694313049316,3.1149990558624268,3.1080148220062256,2.873713493347168,3.086909532546997,3.0774765014648438],\"y\":[6.39177131652832,6.483595371246338,6.411635875701904,6.427972793579102,6.481076240539551,6.475640773773193,6.174881458282471,6.482334136962891,6.494801998138428,6.465960502624512,6.457248210906982,6.451070308685303,6.227280139923096,6.4461846351623535,6.419388771057129],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Optimizing Conditional Value-At-Risk of Black-Box Functions\",\"A Domain-Shrinking based Bayesian Optimization Algorithm with Order-Optimal Regret Performance\",\"Implicit Deep Adaptive Design: Policy-Based Experimental Design without Likelihoods\",\"USCO-Solver: Solving Undetermined Stochastic Combinatorial Optimization Problems\",\"Risk-averse Heteroscedastic Bayesian Optimization\",\"Bayesian Optimization with High-Dimensional Outputs\",\"Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks\",\"Bayesian Optimization of Function Networks\",\"Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement\",\"Regret Bounds for Gaussian-Process Optimization in Large Domains\",\"Reinforced Few-Shot Acquisition Function Learning for Bayesian Optimization\",\"Constrained Two-step Look-Ahead Bayesian Optimization\",\"Multi-Step Budgeted Bayesian Optimization with Unknown Evaluation Costs\",\"Scalable Thompson Sampling using Sparse Gaussian Process Models\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"35_bayesian optimization_optimization_bayesian\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"35_bayesian optimization_optimization_bayesian\"],\"textfont\":{\"size\":12},\"x\":[7.8745808601379395,7.892290115356445,7.46493673324585,6.8775248527526855,7.835089206695557,7.771152973175049,7.765036582946777,7.785084247589111,7.7748870849609375,7.857458591461182,7.751697063446045,7.767969608306885,7.7538018226623535,7.889799118041992,7.71866512298584],\"y\":[6.910506248474121,6.902739524841309,7.033237934112549,5.982903003692627,6.921180248260498,6.914709091186523,6.926811695098877,6.907171249389648,6.909947395324707,6.882503032684326,6.928565979003906,6.9041337966918945,6.920635223388672,6.879673004150391,6.851765155792236],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Slice Sampling Reparameterization Gradients\",\"Efficient Learning of Discrete-Continuous Computation Graphs\",\"Storchastic: A Framework for General Stochastic Automatic Differentiation\",\"Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds\",\"MCMC Variational Inference via Uncorrected Hamiltonian Annealing\",\"PSD Representations for Effective Probability Models\",\"Distributional Gradient Matching for Learning Uncertain Neural Dynamics Models\",\"Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions\",\"Equilibrium and non-Equilibrium regimes in the learning of Restricted Boltzmann Machines\",\"Entropy-based adaptive Hamiltonian Monte Carlo\",\"Differentiable Annealed Importance Sampling and the Perils of Gradient Noise\",\"Learning with Algorithmic Supervision via Continuous Relaxations\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"36_mcmc_gradients_computation graphs\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"36_mcmc_gradients_computation graphs\"],\"textfont\":{\"size\":12},\"x\":[5.5878400802612305,5.69384765625,5.623744010925293,5.604166507720947,5.453543663024902,5.555833339691162,5.667535781860352,5.720773696899414,5.416126728057861,5.588197231292725,5.570612907409668,5.752288341522217,5.602875232696533],\"y\":[6.200850009918213,6.229759693145752,6.111972808837891,6.28039026260376,6.330589771270752,6.183587551116943,6.212735176086426,6.299863815307617,6.315209865570068,6.273420810699463,6.219422340393066,6.299487590789795,6.246440410614014],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Learning to Combine Per-Example Solutions for Neural Program Synthesis\",\"PLUR: A Unifying, Graph-Based View of Program Learning, Understanding, and Repair\",\"Improving Compositionality of Neural Networks by Decoding Representations to Inputs\",\"Differentiable Synthesis of Program Architectures\",\"Neural Program Generation Modulo Static Analysis\",\"Neural Circuit Synthesis from Specification Patterns\",\"Pipeline Combinators for Gradual AutoML\",\"Latent Execution for Neural Program Synthesis Beyond Domain-Specific Languages\",\"Self-Supervised Bug Detection and Repair\",\"Terra: Imperative-Symbolic Co-Execution of Imperative Deep Learning Programs\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"37_program_programs_imperative\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"37_program_programs_imperative\"],\"textfont\":{\"size\":12},\"x\":[1.2081589698791504,1.0976262092590332,1.203484058380127,1.1629585027694702,1.1065757274627686,1.187295913696289,1.117526888847351,1.1659034490585327,1.1158404350280762,1.2139312028884888,1.1579301357269287],\"y\":[4.293191432952881,4.318419933319092,4.284657955169678,4.3149638175964355,4.349106788635254,4.285282135009766,4.262485980987549,4.292174816131592,4.333688735961914,4.277738094329834,4.301170825958252],\"type\":\"scattergl\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Can You Learn an Algorithm?  Generalizing from Easy to Hard Problems with Recurrent Networks\",\"Techniques for Symbol Grounding with SATNet\",\"Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning\",\"Supervising the Transfer of Reasoning Patterns in VQA\",\"Fast Abductive Learning by Similarity-based Consistency Optimization\",\"Baby Intuitions Benchmark (BIB):  Discerning the goals, preferences, and actions of others\",\"Scallop: From Probabilistic Deductive Databases to Scalable Differentiable Reasoning\",\"How to transfer algorithmic reasoning knowledge to learn new algorithms?\",\"Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning\",\"Attention over Learned Object Embeddings Enables Complex Visual Reasoning\",null],\"marker\":{\"opacity\":0.5,\"size\":5},\"mode\":\"markers+text\",\"name\":\"38_reasoning_satnet_symbolic\",\"text\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"38_reasoning_satnet_symbolic\"],\"textfont\":{\"size\":12},\"x\":[1.4125169515609741,1.3324480056762695,1.1510050296783447,1.343024730682373,1.3835363388061523,7.6110310554504395,1.265233039855957,1.1955186128616333,1.176982045173645,1.4231683015823364,1.9294464588165283],\"y\":[4.505613803863525,4.3301920890808105,4.504124641418457,4.5177812576293945,4.307228088378906,9.698515892028809,4.334073543548584,4.388761520385742,4.530664443969727,4.434512138366699,4.9551472663879395],\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"shapes\":[{\"line\":{\"color\":\"#CFD8DC\",\"width\":2},\"type\":\"line\",\"x0\":5.7523805240169175,\"x1\":5.7523805240169175,\"y0\":1.7077540159225464,\"y1\":11.69039044380188},{\"line\":{\"color\":\"#9E9E9E\",\"width\":2},\"type\":\"line\",\"x0\":-0.1184966366738081,\"x1\":11.623257684707642,\"y0\":6.699072229862213,\"y1\":6.699072229862213}],\"annotations\":[{\"showarrow\":false,\"text\":\"D1\",\"x\":-0.1184966366738081,\"y\":6.699072229862213,\"yshift\":10},{\"showarrow\":false,\"text\":\"D2\",\"x\":5.7523805240169175,\"xshift\":10,\"y\":11.69039044380188}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"<b>Documents and Topics\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"width\":1500,\"height\":900,\"xaxis\":{\"visible\":false},\"yaxis\":{\"visible\":false}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7f2c621b-4f86-4846-8384-b0431fda35f4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQWWq_RrvZYk"
      },
      "outputs": [],
      "source": [
        "fig.write_html(f\"neurips-{year}.html\") # export to HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRk4jVgiBqZC"
      },
      "source": [
        "EOF"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0168148cc5de41b29a769f39a7369664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e65d49efc2486f8150a9ea5a042304",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9b3aad1a100443578f28f597589e0799",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 226kB/s]"
          }
        },
        "01c5bad3423443b08c33974f6db87bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01fc4ab4aa764327bb2f1b869887e404": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0387575127234bdba519008e7b9ce298": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ebd3236e3545ac852402b1599338f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08cfdf7b551b46b68d2e27301ecc6957": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "095e1bd7ffc94b6793c084a79c860749": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cbb166bb81a4da9a2570511d28e0d71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cde5e7b475f400f8e9a74b033af3fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5867a598b98473285ec974d686ef4ba",
              "IPY_MODEL_352e2c526547428993c31684c77b1670",
              "IPY_MODEL_565d5fe2bec14f6aa97a34cc4967084c"
            ],
            "layout": "IPY_MODEL_45bf1d1a795d467cb07776861e3ec059"
          }
        },
        "0fd6d93c94144f30b8b4e08e7a393f48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "101fa866880b49bfb39e63326e90e245": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12328e8125d34598bc3123b2f76dc84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095e1bd7ffc94b6793c084a79c860749",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3e9267132204ac8be4c206fda329710",
            "value": 39265
          }
        },
        "1520c2151ef74184950365a6b8c57dab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1624a1e098654ff9826b64317d514655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ef4087d0c7d4ac3b8340b980e53129a",
              "IPY_MODEL_85427bb0771140d9a17e59faad5f7eed",
              "IPY_MODEL_0168148cc5de41b29a769f39a7369664"
            ],
            "layout": "IPY_MODEL_c5b55aacebdf4ad9a7fa9e0e5c10f74a"
          }
        },
        "1a3fcd7e1afe4e02a261f10381ea4e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a7203c5d10147d6a642074769103e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aaa1a470f8845b39ef089268af93d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b0e271c3e7a4ab28c9d2d26ff090eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fea2a1c8cc6418e851adc6cfa119670": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "220bfc57d89e453099494a30613520a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22e8596ffa314352a3fbb9ef1ac72791": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22eab73b52ee403699cb674cde2f915a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2406ffac09a348288076d12610d9b3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "241dd909958446dc8860a8db28db1e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64a7594ba9454b7ba2339c0a6b491bcd",
              "IPY_MODEL_3a452c5b13164100a51f60908756f0bf",
              "IPY_MODEL_9f039c951c3046f0bc80ed7f1185d8c8"
            ],
            "layout": "IPY_MODEL_687cb82bace54c938b86cd74344c5aae"
          }
        },
        "2981f37ee9164b9ba2d018e918fe7a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3391d26a495745a8b985734727ad4349",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_702b896f63694995b85e9e37c9bab67d",
            "value": " 350/350 [00:00&lt;00:00, 3.88kB/s]"
          }
        },
        "2b9e04cde9d64901aa4875eadd95648f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f411d75c0bb4e2791588bfc2023da12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5657445d495c4d779ec667130dff889c",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5cc7361c23b4d38acf6167e22d20d27",
            "value": 466247
          }
        },
        "316e0bcd04524a1bb2ef04fd68ca9ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3391d26a495745a8b985734727ad4349": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "344817c38316451a9d1e5c93b339646d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89e84c620d24595a7caf4c3e12a21b7",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a4986ad72064021a96ce0e7b4840454",
            "value": 116
          }
        },
        "346d018c68284064a0a47d96e6ae8df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b9e04cde9d64901aa4875eadd95648f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fe4e8faf666c497eacce58be370fada1",
            "value": " 190/190 [00:00&lt;00:00, 2.87kB/s]"
          }
        },
        "352e2c526547428993c31684c77b1670": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cbb166bb81a4da9a2570511d28e0d71",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc13a201dc15475ea339a330fd528c2f",
            "value": 90888945
          }
        },
        "36037ee9c1234421aef390b88431379f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36fd8ab4ba7c4ba38b64360b4ad59259": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a452c5b13164100a51f60908756f0bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebac3fa672894a9b915755b1f4661e03",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb23ab6ea6a04e0ebe07bfc862008638",
            "value": 612
          }
        },
        "3ab7a2e6bb5243c6909332d72f6eb822": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac1c67d060347c9bc7a8112ddffade9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc20dadd4c284a5282c19cb9c05bd977",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1a3fcd7e1afe4e02a261f10381ea4e61",
            "value": "Downloading: 100%"
          }
        },
        "3af1e7a50fa44199a7d2ec4b3a195d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb7a765c4024ba8b9a26aa8f57e1865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc366905ca443949b6bf38394d1ad9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f2267125cad4c0ab0aaefb7bc375fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e34932598d48718931e0bdf8d6d301": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "434d5a8c4cd540c48e063aece1f75b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f92ad7f24a374c14be5792d9a2341e1e",
            "max": 73,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb7681962c1a452f82a1334e471ffe28",
            "value": 73
          }
        },
        "441c6fcf3eda4775b2896f6f2cb2614a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775af11bc8d04f4aa1e58ac7598895bb",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_995e4d5b79ae4cb796fd92a8ff183a83",
            "value": 350
          }
        },
        "45bf1d1a795d467cb07776861e3ec059": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a7bf9b767b45f39de5cbffca3927a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c5313aeff2540ee984f6900af98fd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fbc901237c04299a1ba5fbba9235533",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08cfdf7b551b46b68d2e27301ecc6957",
            "value": 190
          }
        },
        "4d3372d3be6a40deb0904cb7c449191f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e8596ffa314352a3fbb9ef1ac72791",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_95d7838270ff4f9ea1fdbd5aca1ba3cc",
            "value": " 232k/232k [00:00&lt;00:00, 10.0kB/s]"
          }
        },
        "515fbdf177294a4fafbde1f2ae0d5ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f6908018294382914ab6da66f2d6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_800a9383deb445a4b8fcc5a06024920d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5b159b2fd42d4e65a074c62ef58198ff",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 174kB/s]"
          }
        },
        "5657445d495c4d779ec667130dff889c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565d5fe2bec14f6aa97a34cc4967084c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ed706395d894d02b0697d7e496e65f6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bd0fada771d04f44a4b20bf498849219",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 56.5MB/s]"
          }
        },
        "57ea38b9b1b0431c80b47d6a2dc521c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f64bceb57a504cc581ae17af0e2e25f6",
              "IPY_MODEL_2f411d75c0bb4e2791588bfc2023da12",
              "IPY_MODEL_a4b6f65c1ee644569c75679323d1a017"
            ],
            "layout": "IPY_MODEL_cb6917b69250475aaf0a43124f721ac8"
          }
        },
        "58504abdc59240d4918710e213fddc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1dcae6b1d7740ae995fdfdaef19ad98",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3af1e7a50fa44199a7d2ec4b3a195d5a",
            "value": "Downloading: 100%"
          }
        },
        "5a2a4f984e4d4637a3ddede5daacdb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ab7fdc279ae44a388954a854819ea77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b159b2fd42d4e65a074c62ef58198ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c99c984e2e845d987c1f5cab7b5a86e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ddd1db8676b44129a274703ca33a640": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "624743ed6c124cdd8d3762ad86d8c04b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a7594ba9454b7ba2339c0a6b491bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0387575127234bdba519008e7b9ce298",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6d5a50630d8a4f16b161289059775651",
            "value": "Downloading: 100%"
          }
        },
        "687cb82bace54c938b86cd74344c5aae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688c813998b9475c8ad92055f7f4fff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ca8da6f4b50496b9d6e1cb86f51efb6",
              "IPY_MODEL_441c6fcf3eda4775b2896f6f2cb2614a",
              "IPY_MODEL_2981f37ee9164b9ba2d018e918fe7a27"
            ],
            "layout": "IPY_MODEL_6a431a555b724a618e76e25954ed7c23"
          }
        },
        "6a431a555b724a618e76e25954ed7c23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3b27676f9f4160a4a2b010da429631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_764dfe3305744abeabe33684645cb923",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_220bfc57d89e453099494a30613520a7",
            "value": "Downloading: 100%"
          }
        },
        "6c73284c06e34ddbb792e2def62f17c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1520c2151ef74184950365a6b8c57dab",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b7c320b81274d43a9e7614c5f5a80dc",
            "value": 53
          }
        },
        "6d5a50630d8a4f16b161289059775651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ead2ec411514e0ca0695983fc3bb81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ac1c67d060347c9bc7a8112ddffade9",
              "IPY_MODEL_6c73284c06e34ddbb792e2def62f17c3",
              "IPY_MODEL_c0e4316985104388a56b8828f08e759e"
            ],
            "layout": "IPY_MODEL_7d00e548b7034dc68dfa6bb64506fed7"
          }
        },
        "6fa781ce55dc4250a0330e65855df652": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "702b896f63694995b85e9e37c9bab67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71345870190b4b58afa7307d26c69874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "764dfe3305744abeabe33684645cb923": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7744b4f072f74965bfbd6d197c1b0327": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "775af11bc8d04f4aa1e58ac7598895bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f5bed8099c409dbf6cf81e31c55ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77f7c8f231504edf973c21a8af827794": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b7c320b81274d43a9e7614c5f5a80dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bd0bdca2886472ebc1df745fd89077e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92f6f79f0c349f0a133a531377041b4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8394b5cbd4ec4e07aa2575060e3337d4",
            "value": "Downloading: 100%"
          }
        },
        "7c01e924d53343d4bff9c12202028661": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_101fa866880b49bfb39e63326e90e245",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5a2a4f984e4d4637a3ddede5daacdb6a",
            "value": " 116/116 [00:00&lt;00:00, 1.64kB/s]"
          }
        },
        "7d00e548b7034dc68dfa6bb64506fed7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f36bb0bcac0437f96f9ba10cdd715c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6ff3189bd04fdb931596788f572ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58504abdc59240d4918710e213fddc08",
              "IPY_MODEL_12328e8125d34598bc3123b2f76dc84c",
              "IPY_MODEL_da7ce8e1b7d246eb87a8524b0c6a2dd6"
            ],
            "layout": "IPY_MODEL_b2bee46fbebd406cb64b104f621367db"
          }
        },
        "8001b5b03c0b4993b2dcb79ba6001bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe081da593934f97a4f2ece04aeeecb8",
              "IPY_MODEL_434d5a8c4cd540c48e063aece1f75b20",
              "IPY_MODEL_9e0f2f11417c432a81d840d327289b4a"
            ],
            "layout": "IPY_MODEL_e460ad4374784f55ba9bbe05b755c603"
          }
        },
        "800a9383deb445a4b8fcc5a06024920d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83932dcebddb45788952924e91973e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8394b5cbd4ec4e07aa2575060e3337d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85427bb0771140d9a17e59faad5f7eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc238a1cb46648a3bc51298da963e357",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fa781ce55dc4250a0330e65855df652",
            "value": 10610
          }
        },
        "85dd5a41657a4105a3a1ff8a5e886e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883e567c7b0f48a39a4d576749a87510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ed706395d894d02b0697d7e496e65f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d7838270ff4f9ea1fdbd5aca1ba3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e8845db5d1497698aa56b0a5662625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "995e4d5b79ae4cb796fd92a8ff183a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a4986ad72064021a96ce0e7b4840454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b3aad1a100443578f28f597589e0799": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b63439bc87544a6942f5d69d5f1aad7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca8da6f4b50496b9d6e1cb86f51efb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36037ee9c1234421aef390b88431379f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_36fd8ab4ba7c4ba38b64360b4ad59259",
            "value": "Downloading: 100%"
          }
        },
        "9d02a10bd641488e808bc61109e3593d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d383c4146c44616b870ac8eb9fe7528",
              "IPY_MODEL_4c5313aeff2540ee984f6900af98fd61",
              "IPY_MODEL_346d018c68284064a0a47d96e6ae8df0"
            ],
            "layout": "IPY_MODEL_a4c10858a415477399f5be1af7ff77a6"
          }
        },
        "9d383c4146c44616b870ac8eb9fe7528": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85dd5a41657a4105a3a1ff8a5e886e8e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_77f5bed8099c409dbf6cf81e31c55ce3",
            "value": "Downloading: 100%"
          }
        },
        "9d769ef5bd044fc5980ad437f9fd64e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab7fdc279ae44a388954a854819ea77",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ddd1db8676b44129a274703ca33a640",
            "value": "Downloading: 100%"
          }
        },
        "9e0f05dd90f241c4a01989b5aa633245": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e0f2f11417c432a81d840d327289b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22eab73b52ee403699cb674cde2f915a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a49593a94f904fdb8b78218de071b612",
            "value": " 73/73 [00:07&lt;00:00, 12.02it/s]"
          }
        },
        "9ef4087d0c7d4ac3b8340b980e53129a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2406ffac09a348288076d12610d9b3d8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_de1af796a25042b5bece2313812aa9a0",
            "value": "Downloading: 100%"
          }
        },
        "9ef6947951ef45a599e3abf85211c2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cca9fb15337e437a8dbe553ce1030ad6",
              "IPY_MODEL_f03960b2ee7f49dc8646a474705e7b04",
              "IPY_MODEL_acabf630c0c94d23ab46b59f2c22db8c"
            ],
            "layout": "IPY_MODEL_c2d7fdedf355407daac6161eeb81678a"
          }
        },
        "9f039c951c3046f0bc80ed7f1185d8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd6d93c94144f30b8b4e08e7a393f48",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1a7203c5d10147d6a642074769103e91",
            "value": " 612/612 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "9fbc901237c04299a1ba5fbba9235533": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a39d92c8779a4148a4752974ae613c49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e541ff5d8545c0b4bef6672086b352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2267125cad4c0ab0aaefb7bc375fa6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3bb7a765c4024ba8b9a26aa8f57e1865",
            "value": "Downloading: 100%"
          }
        },
        "a3f4d89d71b8432295bd7286176ea321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f7c8f231504edf973c21a8af827794",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d4ce1e561046f783fdbec6245f21c3",
            "value": 13156
          }
        },
        "a49593a94f904fdb8b78218de071b612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4b6f65c1ee644569c75679323d1a017": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b63439bc87544a6942f5d69d5f1aad7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7744b4f072f74965bfbd6d197c1b0327",
            "value": " 466k/466k [00:00&lt;00:00, 748kB/s]"
          }
        },
        "a4c10858a415477399f5be1af7ff77a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5465d3f49e34f1a9b64cd7c51ac7ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b3b27676f9f4160a4a2b010da429631",
              "IPY_MODEL_344817c38316451a9d1e5c93b339646d",
              "IPY_MODEL_7c01e924d53343d4bff9c12202028661"
            ],
            "layout": "IPY_MODEL_624743ed6c124cdd8d3762ad86d8c04b"
          }
        },
        "a5cc7361c23b4d38acf6167e22d20d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8ea0ce184fc49d880beef3ff63b71d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a75984db764712b660ef6fb23e684c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_515fbdf177294a4fafbde1f2ae0d5ecb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b0e271c3e7a4ab28c9d2d26ff090eb7",
            "value": 231508
          }
        },
        "acabf630c0c94d23ab46b59f2c22db8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c99c984e2e845d987c1f5cab7b5a86e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d18914fa06704258a3eec1343f72cf26",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 6.89kB/s]"
          }
        },
        "ae0bd1ab40fc432897696b8e6fa87ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2bee46fbebd406cb64b104f621367db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2cc0e8f1ccb4d8b91fc1d6e9ae3fed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b791ca0db1c3476ea95787d734607ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb23ab6ea6a04e0ebe07bfc862008638": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc20dadd4c284a5282c19cb9c05bd977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc238a1cb46648a3bc51298da963e357": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0fada771d04f44a4b20bf498849219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0e4316985104388a56b8828f08e759e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a39d92c8779a4148a4752974ae613c49",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_01c5bad3423443b08c33974f6db87bb4",
            "value": " 53.0/53.0 [00:00&lt;00:00, 625B/s]"
          }
        },
        "c13015e8772c475abd9988080b76c61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71345870190b4b58afa7307d26c69874",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b2cc0e8f1ccb4d8b91fc1d6e9ae3fed3",
            "value": " 349/349 [00:00&lt;00:00, 3.62kB/s]"
          }
        },
        "c2d7fdedf355407daac6161eeb81678a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e9267132204ac8be4c206fda329710": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4e9d59d2ca44db8b419b777f7c38978": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b55aacebdf4ad9a7fa9e0e5c10f74a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d0daac4cef41a7ba9f0da041f460ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8c17f0c2a04497b4604acb471fb4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb6917b69250475aaf0a43124f721ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7681962c1a452f82a1334e471ffe28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cca9fb15337e437a8dbe553ce1030ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83932dcebddb45788952924e91973e0c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_42e34932598d48718931e0bdf8d6d301",
            "value": "Downloading: 100%"
          }
        },
        "cdd71f69a4d74d9c94f12973ce6f1622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf923275ae2f41e3b56ee316b66c230a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bd0bdca2886472ebc1df745fd89077e",
              "IPY_MODEL_a3f4d89d71b8432295bd7286176ea321",
              "IPY_MODEL_53f6908018294382914ab6da66f2d6f1"
            ],
            "layout": "IPY_MODEL_03ebd3236e3545ac852402b1599338f8"
          }
        },
        "d18914fa06704258a3eec1343f72cf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1cf85b21e8f45ea9e8a2e74a527de40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f36bb0bcac0437f96f9ba10cdd715c9",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdd71f69a4d74d9c94f12973ce6f1622",
            "value": 112
          }
        },
        "d1dcae6b1d7740ae995fdfdaef19ad98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d271466b464747cfbf9e39cd2f6d2479": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9137795d8ed497c96b064078e7ed0dc",
              "IPY_MODEL_d1cf85b21e8f45ea9e8a2e74a527de40",
              "IPY_MODEL_f785337a98cb4f2491b3fbcd3eeb7873"
            ],
            "layout": "IPY_MODEL_1fea2a1c8cc6418e851adc6cfa119670"
          }
        },
        "d9137795d8ed497c96b064078e7ed0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e9d59d2ca44db8b419b777f7c38978",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_883e567c7b0f48a39a4d576749a87510",
            "value": "Downloading: 100%"
          }
        },
        "d92f6f79f0c349f0a133a531377041b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7ce8e1b7d246eb87a8524b0c6a2dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68f703f80ad47a7b78c1abfb1d53050",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_49a7bf9b767b45f39de5cbffca3927a7",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 1.18MB/s]"
          }
        },
        "dc13a201dc15475ea339a330fd528c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de1af796a25042b5bece2313812aa9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dea5d9e7712e4f9eac3fb29e6cdd6c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab7a2e6bb5243c6909332d72f6eb822",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bc366905ca443949b6bf38394d1ad9f",
            "value": 349
          }
        },
        "df2f0e7626c74266a77d3c890123ad2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3e541ff5d8545c0b4bef6672086b352",
              "IPY_MODEL_a9a75984db764712b660ef6fb23e684c",
              "IPY_MODEL_4d3372d3be6a40deb0904cb7c449191f"
            ],
            "layout": "IPY_MODEL_a8ea0ce184fc49d880beef3ff63b71d1"
          }
        },
        "e3d4ce1e561046f783fdbec6245f21c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e460ad4374784f55ba9bbe05b755c603": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5867a598b98473285ec974d686ef4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_316e0bcd04524a1bb2ef04fd68ca9ed1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b791ca0db1c3476ea95787d734607ae4",
            "value": "Downloading: 100%"
          }
        },
        "e814f8d65cd84b19b0b3e20ec52c911c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebac3fa672894a9b915755b1f4661e03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efda07e8db2f4cfb95a2b0479b383b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d769ef5bd044fc5980ad437f9fd64e3",
              "IPY_MODEL_dea5d9e7712e4f9eac3fb29e6cdd6c81",
              "IPY_MODEL_c13015e8772c475abd9988080b76c61a"
            ],
            "layout": "IPY_MODEL_e814f8d65cd84b19b0b3e20ec52c911c"
          }
        },
        "f03960b2ee7f49dc8646a474705e7b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae0bd1ab40fc432897696b8e6fa87ba1",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e0f05dd90f241c4a01989b5aa633245",
            "value": 1175
          }
        },
        "f3e65d49efc2486f8150a9ea5a042304": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64bceb57a504cc581ae17af0e2e25f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aaa1a470f8845b39ef089268af93d8a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c8d0daac4cef41a7ba9f0da041f460ab",
            "value": "Downloading: 100%"
          }
        },
        "f68f703f80ad47a7b78c1abfb1d53050": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f785337a98cb4f2491b3fbcd3eeb7873": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01fc4ab4aa764327bb2f1b869887e404",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fcb8698410eb49e388f3c1e93917bfed",
            "value": " 112/112 [00:00&lt;00:00, 1.18kB/s]"
          }
        },
        "f89e84c620d24595a7caf4c3e12a21b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92ad7f24a374c14be5792d9a2341e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb8698410eb49e388f3c1e93917bfed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe081da593934f97a4f2ece04aeeecb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca8c17f0c2a04497b4604acb471fb4b0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_95e8845db5d1497698aa56b0a5662625",
            "value": "Batches: 100%"
          }
        },
        "fe4e8faf666c497eacce58be370fada1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
